{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced27f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2791f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies_ETL\\wikipedia-movies.json\n"
     ]
    }
   ],
   "source": [
    "# Retreive JSON file\n",
    "file_dir = os.path.join(\"Movies_ETL\", \"wikipedia-movies.json\")\n",
    "print(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee36940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open JSON file, save data as file: wiki_movies_raw\n",
    "with open ('wikipedia-movies.json', mode='r') as file:\n",
    "    wiki_movies_raw = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689ec14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasonability check, 7311 movies over 30 yrs.\n",
    "# Rount 7300/30=240/52=4\n",
    "# 4 movies per week is reasonable considering indie films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26207720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/The_Adventures_of_Ford_Fairlane',\n",
       "  'year': 1990,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0098987/',\n",
       "  'title': 'The Adventures of Ford Fairlane',\n",
       "  'Directed by': 'Renny Harlin',\n",
       "  'Produced by': ['Steve Perry', 'Joel Silver'],\n",
       "  'Screenplay by': ['David Arnott', 'James Cappe', 'Daniel Waters'],\n",
       "  'Story by': ['David Arnott', 'James Cappe'],\n",
       "  'Based on': ['Characters', 'by Rex Weiner'],\n",
       "  'Starring': ['Andrew Dice Clay',\n",
       "   'Wayne Newton',\n",
       "   'Priscilla Presley',\n",
       "   'Lauren Holly',\n",
       "   'Morris Day',\n",
       "   'Robert Englund',\n",
       "   \"Ed O'Neill\"],\n",
       "  'Narrated by': 'Andrew \"Dice\" Clay',\n",
       "  'Music by': ['Cliff Eidelman', 'Yello'],\n",
       "  'Cinematography': 'Oliver Wood',\n",
       "  'Edited by': 'Michael Tronick',\n",
       "  'Productioncompany ': 'Silver Pictures',\n",
       "  'Distributed by': '20th Century Fox',\n",
       "  'Release date': ['July 11, 1990', '(', '1990-07-11', ')'],\n",
       "  'Running time': '102 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$20 million',\n",
       "  'Box office': '$21.4 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/After_Dark,_My_Sweet',\n",
       "  'year': 1990,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0098994/',\n",
       "  'title': 'After Dark, My Sweet',\n",
       "  'Directed by': 'James Foley',\n",
       "  'Produced by': ['Ric Kidney', 'Robert Redlin'],\n",
       "  'Screenplay by': ['James Foley', 'Robert Redlin'],\n",
       "  'Based on': ['the novel', 'After Dark, My Sweet', 'by', 'Jim Thompson'],\n",
       "  'Starring': ['Jason Patric',\n",
       "   'Rachel Ward',\n",
       "   'Bruce Dern',\n",
       "   'George Dickerson'],\n",
       "  'Music by': 'Maurice Jarre',\n",
       "  'Cinematography': 'Mark Plummer',\n",
       "  'Edited by': 'Howard E. Smith',\n",
       "  'Productioncompany ': 'Avenue Pictures',\n",
       "  'Distributed by': 'Avenue Pictures',\n",
       "  'Release date': ['May 17, 1990',\n",
       "   '(',\n",
       "   '1990-05-17',\n",
       "   ')',\n",
       "   '(Cannes Film Market)',\n",
       "   'August 24, 1990',\n",
       "   '(',\n",
       "   '1990-08-24',\n",
       "   ')',\n",
       "   '(United States)'],\n",
       "  'Running time': '114 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$6 million',\n",
       "  'Box office': '$2.7 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Air_America_(film)',\n",
       "  'year': 1990,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0099005/',\n",
       "  'title': 'Air America',\n",
       "  'Directed by': 'Roger Spottiswoode',\n",
       "  'Produced by': 'Daniel Melnick',\n",
       "  'Screenplay by': ['John Eskow', 'Richard Rush'],\n",
       "  'Based on': ['Air America', 'by', 'Christopher Robbins'],\n",
       "  'Starring': ['Mel Gibson',\n",
       "   'Robert Downey Jr.',\n",
       "   'Nancy Travis',\n",
       "   'David Marshall Grant',\n",
       "   'Lane Smith'],\n",
       "  'Music by': 'Charles Gross',\n",
       "  'Cinematography': 'Roger Deakins',\n",
       "  'Edited by': ['John Bloom', 'Lois Freeman-Fox'],\n",
       "  'Productioncompany ': ['Carolco Pictures', 'IndieProd Company'],\n",
       "  'Distributed by': 'TriStar Pictures',\n",
       "  'Release date': ['August 10, 1990', '(', '1990-08-10', ')'],\n",
       "  'Running time': '113 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': ['English', 'Lao'],\n",
       "  'Budget': '$35 million',\n",
       "  'Box office': '$57,718,089'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Alice_(1990_film)',\n",
       "  'year': 1990,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0099012/',\n",
       "  'title': 'Alice',\n",
       "  'Directed by': 'Woody Allen',\n",
       "  'Produced by': 'Robert Greenhut',\n",
       "  'Written by': 'Woody Allen',\n",
       "  'Starring': ['Alec Baldwin',\n",
       "   'Blythe Danner',\n",
       "   'Judy Davis',\n",
       "   'Mia Farrow',\n",
       "   'William Hurt',\n",
       "   'Keye Luke',\n",
       "   'Joe Mantegna',\n",
       "   'Bernadette Peters'],\n",
       "  'Cinematography': 'Carlo Di Palma',\n",
       "  'Edited by': 'Susan E. Morse',\n",
       "  'Distributed by': 'Orion Pictures',\n",
       "  'Release date': ['December 25, 1990', '(', '1990-12-25', ')'],\n",
       "  'Running time': '106 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$12 million',\n",
       "  'Box office': '$7,331,647'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Almost_an_Angel',\n",
       "  'year': 1990,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0099018/',\n",
       "  'title': 'Almost an Angel',\n",
       "  'Directed by': 'John Cornell',\n",
       "  'Produced by': 'John Cornell',\n",
       "  'Written by': 'Paul Hogan',\n",
       "  'Starring': ['Paul Hogan', 'Elias Koteas', 'Linda Kozlowski'],\n",
       "  'Music by': 'Maurice Jarre',\n",
       "  'Cinematography': 'Russell Boyd',\n",
       "  'Edited by': 'David Stiven',\n",
       "  'Distributed by': 'Paramount Pictures',\n",
       "  'Release date': 'December 19, 1990',\n",
       "  'Running time': '95 minutes',\n",
       "  'Country': 'US',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$25 million',\n",
       "  'Box office': '$6,939,946 (USA)'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data in slices\n",
    "# First 5 records\n",
    "wiki_movies_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6746009d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/Holmes_%26_Watson',\n",
       "  'year': 2018,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt1255919/',\n",
       "  'title': 'Holmes & Watson',\n",
       "  'Directed by': 'Etan Cohen',\n",
       "  'Produced by': ['Will Ferrell',\n",
       "   'Adam McKay',\n",
       "   'Jimmy Miller',\n",
       "   'Clayton Townsend'],\n",
       "  'Screenplay by': 'Etan Cohen',\n",
       "  'Based on': ['Sherlock Holmes',\n",
       "   'and',\n",
       "   'Dr. Watson',\n",
       "   'by',\n",
       "   'Sir Arthur Conan Doyle'],\n",
       "  'Starring': ['Will Ferrell',\n",
       "   'John C. Reilly',\n",
       "   'Rebecca Hall',\n",
       "   'Rob Brydon',\n",
       "   'Steve Coogan',\n",
       "   'Ralph Fiennes'],\n",
       "  'Music by': 'Mark Mothersbaugh',\n",
       "  'Cinematography': 'Oliver Wood',\n",
       "  'Edited by': 'Dean Zimmerman',\n",
       "  'Productioncompanies ': ['Columbia Pictures',\n",
       "   'Gary Sanchez Productions',\n",
       "   'Mosaic Media Group',\n",
       "   'Mimran Schur Pictures'],\n",
       "  'Distributed by': 'Sony Pictures Releasing',\n",
       "  'Release date': ['December 25, 2018',\n",
       "   '(',\n",
       "   '2018-12-25',\n",
       "   ')',\n",
       "   '(United States)'],\n",
       "  'Running time': '90 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$42 million',\n",
       "  'Box office': '$41.9 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Vice_(2018_film)',\n",
       "  'year': 2018,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt6266538/',\n",
       "  'title': 'Vice',\n",
       "  'Directed by': 'Adam McKay',\n",
       "  'Produced by': ['Brad Pitt',\n",
       "   'Dede Gardner',\n",
       "   'Jeremy Kleiner',\n",
       "   'Kevin J. Messick',\n",
       "   'Will Ferrell',\n",
       "   'Adam McKay'],\n",
       "  'Written by': 'Adam McKay',\n",
       "  'Starring': ['Christian Bale',\n",
       "   'Amy Adams',\n",
       "   'Steve Carell',\n",
       "   'Sam Rockwell',\n",
       "   'Tyler Perry',\n",
       "   'Alison Pill',\n",
       "   'Lily Rabe',\n",
       "   'Jesse Plemons'],\n",
       "  'Music by': 'Nicholas Britell',\n",
       "  'Cinematography': 'Greig Fraser',\n",
       "  'Edited by': 'Hank Corwin',\n",
       "  'Productioncompany ': ['Plan B Entertainment',\n",
       "   'Gary Sanchez Productions',\n",
       "   'Annapurna Pictures'],\n",
       "  'Distributed by': 'Mirror Releasing',\n",
       "  'Release date': ['December 11, 2018',\n",
       "   '(',\n",
       "   '2018-12-11',\n",
       "   ')',\n",
       "   '(',\n",
       "   'Samuel Goldwyn Theater',\n",
       "   ')',\n",
       "   'December 25, 2018',\n",
       "   '(',\n",
       "   '2018-12-25',\n",
       "   ')',\n",
       "   '(United States)'],\n",
       "  'Running time': '132 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$60 million',\n",
       "  'Box office': '$76.1 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/On_the_Basis_of_Sex',\n",
       "  'year': 2018,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt4669788/',\n",
       "  'title': 'On the Basis of Sex',\n",
       "  'Directed by': 'Mimi Leder',\n",
       "  'Produced by': 'Robert W. Cort',\n",
       "  'Written by': 'Daniel Stiepleman',\n",
       "  'Starring': ['Felicity Jones',\n",
       "   'Armie Hammer',\n",
       "   'Justin Theroux',\n",
       "   'Sam Waterston',\n",
       "   'Kathy Bates'],\n",
       "  'Music by': 'Mychael Danna',\n",
       "  'Cinematography': 'Michael Grady',\n",
       "  'Edited by': 'Michelle Tesoro',\n",
       "  'Productioncompanies ': ['Focus Features',\n",
       "   '[1]',\n",
       "   'Participant Media',\n",
       "   '[1]',\n",
       "   'Robert Cort Productions',\n",
       "   '[1]',\n",
       "   'Alibaba Pictures',\n",
       "   '[2]'],\n",
       "  'Distributed by': 'Focus Features',\n",
       "  'Release date': ['November 8, 2018',\n",
       "   '(',\n",
       "   '2018-11-08',\n",
       "   ')',\n",
       "   '(',\n",
       "   'AFI Fest',\n",
       "   ')',\n",
       "   'December 25, 2018',\n",
       "   '(',\n",
       "   '2018-12-25',\n",
       "   ')',\n",
       "   '(United States)'],\n",
       "  'Running time': '120 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$20 million',\n",
       "  'Box office': '$38.4 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Destroyer_(2018_film)',\n",
       "  'year': 2018,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt7137380/',\n",
       "  'title': 'Destroyer',\n",
       "  'Directed by': 'Karyn Kusama',\n",
       "  'Produced by': ['Fred Berger', 'Phil Hay', 'Matt Manfredi'],\n",
       "  'Written by': ['Phil Hay', 'Matt Manfredi'],\n",
       "  'Starring': ['Nicole Kidman',\n",
       "   'Sebastian Stan',\n",
       "   'Toby Kebbell',\n",
       "   'Tatiana Maslany',\n",
       "   'Bradley Whitford',\n",
       "   'Jade Pettyjohn',\n",
       "   'Scoot McNairy'],\n",
       "  'Music by': 'Theodore Shapiro',\n",
       "  'Cinematography': 'Julie Kirkwood',\n",
       "  'Edited by': 'Plummy Tucker',\n",
       "  'Productioncompany ': ['30West',\n",
       "   'Automatik Entertainment',\n",
       "   'Annapurna Pictures'],\n",
       "  'Distributed by': 'Mirror Releasing',\n",
       "  'Release date': ['August 31, 2018',\n",
       "   '(',\n",
       "   '2018-08-31',\n",
       "   ')',\n",
       "   '(',\n",
       "   'Telluride',\n",
       "   ')',\n",
       "   'December 25, 2018',\n",
       "   '(',\n",
       "   '2018-12-25',\n",
       "   ')',\n",
       "   '(United States)'],\n",
       "  'Running time': '123 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$9 million',\n",
       "  'Box office': '$5.5 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Black_Mirror:_Bandersnatch',\n",
       "  'year': 2018,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt9495224/',\n",
       "  'title': 'Bandersnatch',\n",
       "  'Directed by': 'David Slade',\n",
       "  'Produced by': 'Russell McLean',\n",
       "  'Written by': 'Charlie Brooker',\n",
       "  'Starring': ['Fionn Whitehead',\n",
       "   'Will Poulter',\n",
       "   'Craig Parkinson',\n",
       "   'Alice Lowe',\n",
       "   'Asim Chaudhry'],\n",
       "  'Music by': 'Brian Reitzell',\n",
       "  'Cinematography': ['Aaron Morton', 'Jake Polonsky'],\n",
       "  'Edited by': 'Tony Kearns',\n",
       "  'Productioncompany ': ['House of Tomorrow', 'Netflix'],\n",
       "  'Distributed by': 'Netflix',\n",
       "  'Release date': ['28 December 2018', '(', '2018-12-28', ')'],\n",
       "  'Running time': 'Variable; 90 minutes for default path',\n",
       "  'Country': 'United Kingdom',\n",
       "  'Language': 'English'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data in slices\n",
    "# Last 5 records\n",
    "wiki_movies_raw[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0420d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/Benji:_Off_the_Leash!',\n",
       "  'year': 2004,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0315273/',\n",
       "  'title': 'Benji: Off the Leash!',\n",
       "  'Directed by': 'Joe Camp',\n",
       "  'Written by': 'Joe Camp',\n",
       "  'Starring': ['Benji', 'Nick Whitaker', 'Shaggy', 'Gypsy the Cockatoo'],\n",
       "  'Music by': 'Antonio di Lorenzo',\n",
       "  'Productioncompany ': 'Mulberry Square Productions',\n",
       "  'Distributed by': 'Mulberry Square Productions',\n",
       "  'Release date': ['March 26, 2004', '(', '2004-03-26', ')'],\n",
       "  'Running time': '97 min',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Box office': '$3,817,362'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/The_Best_Thief_in_the_World',\n",
       "  'year': 2004,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0389796/',\n",
       "  'title': 'The Best Thief in the World',\n",
       "  'Directed by': 'Jacob Kornbluth',\n",
       "  'Produced by': ['Tim Perrell', 'Nicola Usborne'],\n",
       "  'Written by': 'Jacob Kornbluth',\n",
       "  'Starring': ['Marc Rozendaal',\n",
       "   'Michael Silverman',\n",
       "   'David Warshofsky',\n",
       "   'Audra McDonald',\n",
       "   'Lois Smith'],\n",
       "  'Music by': ['Prince Paul', 'and', 'Don Newkirk'],\n",
       "  'Cinematography': 'Ben Kutchins',\n",
       "  'Edited by': 'Stephanie Sterner',\n",
       "  'Distributed by': 'Showtime Networks',\n",
       "  'Release date': ['January 16, 2004', '(', '2004-01-16', ')'],\n",
       "  'Running time': '93 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Beyond_the_Sea_(2004_film)',\n",
       "  'year': 2004,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0363473/',\n",
       "  'title': 'Beyond the Sea',\n",
       "  'Directed by': 'Kevin Spacey',\n",
       "  'Produced by': ['Kevin Spacey',\n",
       "   'Phillip Barry',\n",
       "   'Dana Brunetti',\n",
       "   'Arthur Friedman',\n",
       "   'Jan Fantl',\n",
       "   'Andy Paterson'],\n",
       "  'Written by': ['Lewis Colick', 'Kevin Spacey'],\n",
       "  'Starring': ['Kevin Spacey', 'Kate Bosworth', 'Bob Hoskins', 'John Goodman'],\n",
       "  'Music by': 'Bobby Darin',\n",
       "  'Cinematography': 'Eduardo Serra',\n",
       "  'Edited by': 'Trevor Waite',\n",
       "  'Productioncompany ': 'Trigger Street Productions',\n",
       "  'Distributed by': ['Lionsgate Films',\n",
       "   '(USA)',\n",
       "   'Entertainment Film Distributors',\n",
       "   '(UK)',\n",
       "   'GAGA',\n",
       "   '(Japan)',\n",
       "   'Maple Pictures',\n",
       "   '(Canada)'],\n",
       "  'Release date': ['December 17, 2004', '(', '2004-12-17', ')'],\n",
       "  'Running time': '118 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$25 million',\n",
       "  'Box office': '$8.4 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/The_Big_Bounce_(2004_film)',\n",
       "  'year': 2004,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0315824/',\n",
       "  'title': 'The Big Bounce',\n",
       "  'Directed by': 'George Armitage',\n",
       "  'Produced by': ['George Armitage', 'Steve Bing'],\n",
       "  'Screenplay by': 'Sebastian Gutierrez',\n",
       "  'Based on': ['The Big Bounce', 'by', 'Elmore Leonard'],\n",
       "  'Starring': ['Owen Wilson',\n",
       "   'Charlie Sheen',\n",
       "   'Morgan Freeman',\n",
       "   'Sara Foster',\n",
       "   'Gary Sinise'],\n",
       "  'Music by': 'George S. Clinton',\n",
       "  'Cinematography': 'Jeffrey L. Kimball',\n",
       "  'Edited by': 'Barry Malkin',\n",
       "  'Productioncompany ': 'Shangri-La Entertainment',\n",
       "  'Distributed by': 'Warner Bros. Pictures',\n",
       "  'Release date': ['January 30, 2004', '(', '2004-01-30', ')'],\n",
       "  'Running time': '88 minutes',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$50 million',\n",
       "  'Box office': '$6.8 million'},\n",
       " {'url': 'https://en.wikipedia.org/wiki/Birth_(film)',\n",
       "  'year': 2004,\n",
       "  'imdb_link': 'https://www.imdb.com/title/tt0337876/',\n",
       "  'title': 'Birth',\n",
       "  'Directed by': 'Jonathan Glazer',\n",
       "  'Produced by': ['Lizie Gower', 'Nick Morris', 'Jean-Louis Piel'],\n",
       "  'Written by': ['Jean-Claude Carrière', 'Milo Addica', 'Jonathan Glazer'],\n",
       "  'Starring': ['Nicole Kidman',\n",
       "   'Cameron Bright',\n",
       "   'Danny Huston',\n",
       "   'Lauren Bacall'],\n",
       "  'Music by': 'Alexandre Desplat',\n",
       "  'Cinematography': 'Harris Savides',\n",
       "  'Edited by': ['Sam Sneade', 'Claus Wehlisch'],\n",
       "  'Distributed by': 'New Line Cinema',\n",
       "  'Release date': ['November 8, 2004', '(', '2004-11-08', ')'],\n",
       "  'Running time': '96 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$20 million',\n",
       "  'Box office': '$23.9 million'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data in slices\n",
    "# Some records in the middle\n",
    "wiki_movies_raw[3600:3605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58a08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn wiki_movies_raw into a DataFrame\n",
    "wiki_movies_df = pd.DataFrame(wiki_movies_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f6d312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>title</th>\n",
       "      <th>Directed by</th>\n",
       "      <th>Produced by</th>\n",
       "      <th>Screenplay by</th>\n",
       "      <th>Story by</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Starring</th>\n",
       "      <th>...</th>\n",
       "      <th>Predecessor</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Area served</th>\n",
       "      <th>Products</th>\n",
       "      <th>Services</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Hebrew</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Operating income</th>\n",
       "      <th>Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>https://www.imdb.com/title/tt0098987/</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>Renny Harlin</td>\n",
       "      <td>[Steve Perry, Joel Silver]</td>\n",
       "      <td>[David Arnott, James Cappe, Daniel Waters]</td>\n",
       "      <td>[David Arnott, James Cappe]</td>\n",
       "      <td>[Characters, by Rex Weiner]</td>\n",
       "      <td>[Andrew Dice Clay, Wayne Newton, Priscilla Pre...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org/wiki/After_Dark,_My_S...</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>https://www.imdb.com/title/tt0098994/</td>\n",
       "      <td>After Dark, My Sweet</td>\n",
       "      <td>James Foley</td>\n",
       "      <td>[Ric Kidney, Robert Redlin]</td>\n",
       "      <td>[James Foley, Robert Redlin]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[the novel, After Dark, My Sweet, by, Jim Thom...</td>\n",
       "      <td>[Jason Patric, Rachel Ward, Bruce Dern, George...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Air_America_(film)</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>https://www.imdb.com/title/tt0099005/</td>\n",
       "      <td>Air America</td>\n",
       "      <td>Roger Spottiswoode</td>\n",
       "      <td>Daniel Melnick</td>\n",
       "      <td>[John Eskow, Richard Rush]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Air America, by, Christopher Robbins]</td>\n",
       "      <td>[Mel Gibson, Robert Downey Jr., Nancy Travis, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_(1990_film)</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>https://www.imdb.com/title/tt0099012/</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Woody Allen</td>\n",
       "      <td>Robert Greenhut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Alec Baldwin, Blythe Danner, Judy Davis, Mia ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Almost_an_Angel</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>https://www.imdb.com/title/tt0099018/</td>\n",
       "      <td>Almost an Angel</td>\n",
       "      <td>John Cornell</td>\n",
       "      <td>John Cornell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Paul Hogan, Elias Koteas, Linda Kozlowski]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url    year  \\\n",
       "0  https://en.wikipedia.org/wiki/The_Adventures_o...  1990.0   \n",
       "1  https://en.wikipedia.org/wiki/After_Dark,_My_S...  1990.0   \n",
       "2   https://en.wikipedia.org/wiki/Air_America_(film)  1990.0   \n",
       "3    https://en.wikipedia.org/wiki/Alice_(1990_film)  1990.0   \n",
       "4      https://en.wikipedia.org/wiki/Almost_an_Angel  1990.0   \n",
       "\n",
       "                               imdb_link                            title  \\\n",
       "0  https://www.imdb.com/title/tt0098987/  The Adventures of Ford Fairlane   \n",
       "1  https://www.imdb.com/title/tt0098994/             After Dark, My Sweet   \n",
       "2  https://www.imdb.com/title/tt0099005/                      Air America   \n",
       "3  https://www.imdb.com/title/tt0099012/                            Alice   \n",
       "4  https://www.imdb.com/title/tt0099018/                  Almost an Angel   \n",
       "\n",
       "          Directed by                  Produced by  \\\n",
       "0        Renny Harlin   [Steve Perry, Joel Silver]   \n",
       "1         James Foley  [Ric Kidney, Robert Redlin]   \n",
       "2  Roger Spottiswoode               Daniel Melnick   \n",
       "3         Woody Allen              Robert Greenhut   \n",
       "4        John Cornell                 John Cornell   \n",
       "\n",
       "                                Screenplay by                     Story by  \\\n",
       "0  [David Arnott, James Cappe, Daniel Waters]  [David Arnott, James Cappe]   \n",
       "1                [James Foley, Robert Redlin]                          NaN   \n",
       "2                  [John Eskow, Richard Rush]                          NaN   \n",
       "3                                         NaN                          NaN   \n",
       "4                                         NaN                          NaN   \n",
       "\n",
       "                                            Based on  \\\n",
       "0                        [Characters, by Rex Weiner]   \n",
       "1  [the novel, After Dark, My Sweet, by, Jim Thom...   \n",
       "2             [Air America, by, Christopher Robbins]   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Starring  ... Predecessor  \\\n",
       "0  [Andrew Dice Clay, Wayne Newton, Priscilla Pre...  ...         NaN   \n",
       "1  [Jason Patric, Rachel Ward, Bruce Dern, George...  ...         NaN   \n",
       "2  [Mel Gibson, Robert Downey Jr., Nancy Travis, ...  ...         NaN   \n",
       "3  [Alec Baldwin, Blythe Danner, Judy Davis, Mia ...  ...         NaN   \n",
       "4        [Paul Hogan, Elias Koteas, Linda Kozlowski]  ...         NaN   \n",
       "\n",
       "  Founders Area served Products Services Russian Hebrew Revenue  \\\n",
       "0      NaN         NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "1      NaN         NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "2      NaN         NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "3      NaN         NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "4      NaN         NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "\n",
       "  Operating income Polish  \n",
       "0              NaN    NaN  \n",
       "1              NaN    NaN  \n",
       "2              NaN    NaN  \n",
       "3              NaN    NaN  \n",
       "4              NaN    NaN  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View _df\n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9fe3104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'year',\n",
       " 'imdb_link',\n",
       " 'title',\n",
       " 'Directed by',\n",
       " 'Produced by',\n",
       " 'Screenplay by',\n",
       " 'Story by',\n",
       " 'Based on',\n",
       " 'Starring',\n",
       " 'Narrated by',\n",
       " 'Music by',\n",
       " 'Cinematography',\n",
       " 'Edited by',\n",
       " 'Productioncompany ',\n",
       " 'Distributed by',\n",
       " 'Release date',\n",
       " 'Running time',\n",
       " 'Country',\n",
       " 'Language',\n",
       " 'Budget',\n",
       " 'Box office',\n",
       " 'Written by',\n",
       " 'Genre',\n",
       " 'Theme music composer',\n",
       " 'Country of origin',\n",
       " 'Original language(s)',\n",
       " 'Producer(s)',\n",
       " 'Editor(s)',\n",
       " 'Production company(s)',\n",
       " 'Original network',\n",
       " 'Original release',\n",
       " 'Productioncompanies ',\n",
       " 'Executive producer(s)',\n",
       " 'Production location(s)',\n",
       " 'Distributor',\n",
       " 'Picture format',\n",
       " 'Audio format',\n",
       " 'Voices of',\n",
       " 'Followed by',\n",
       " 'Composer(s)',\n",
       " 'Created by',\n",
       " 'Also known as',\n",
       " 'Opening theme',\n",
       " 'No. of episodes',\n",
       " 'Preceded by',\n",
       " 'Author',\n",
       " 'Publisher',\n",
       " 'Publication date',\n",
       " 'Media type',\n",
       " 'Pages',\n",
       " 'ISBN',\n",
       " 'OCLC',\n",
       " 'LC Class',\n",
       " 'Cover artist',\n",
       " 'Series',\n",
       " 'Set in',\n",
       " 'Adaptation by',\n",
       " 'Suggested by',\n",
       " 'Biographical data',\n",
       " 'Born',\n",
       " 'Died',\n",
       " 'Resting place',\n",
       " 'Occupation',\n",
       " 'Years active',\n",
       " 'Spouse(s)',\n",
       " 'Children',\n",
       " 'Parent(s)',\n",
       " 'Genres',\n",
       " 'Instruments',\n",
       " 'Labels',\n",
       " 'Website',\n",
       " 'Traditional',\n",
       " 'Mandarin',\n",
       " 'Type',\n",
       " 'Industry',\n",
       " 'Fate',\n",
       " 'Founded',\n",
       " 'Founder',\n",
       " 'Headquarters',\n",
       " 'Parent',\n",
       " 'Released',\n",
       " 'Recorded',\n",
       " 'Venue',\n",
       " 'Length',\n",
       " 'Label',\n",
       " 'Director',\n",
       " 'Producer',\n",
       " 'Area',\n",
       " 'Coordinates',\n",
       " 'Status',\n",
       " 'Opening date',\n",
       " 'Closing date',\n",
       " 'Replaced',\n",
       " 'Replaced by',\n",
       " 'Name',\n",
       " 'Attraction type',\n",
       " 'Music',\n",
       " 'Duration',\n",
       " 'Simplified Chinese',\n",
       " 'Traditional Chinese',\n",
       " 'Hanyu Pinyin',\n",
       " 'Literal meaning',\n",
       " 'Transcriptions',\n",
       " 'Bopomofo',\n",
       " 'Gwoyeu Romatzyh',\n",
       " 'Wade–Giles',\n",
       " 'IPA',\n",
       " 'Yale Romanization',\n",
       " 'Jyutping',\n",
       " 'Hokkien POJ',\n",
       " 'Animation by',\n",
       " 'Color process',\n",
       " 'Engine(s)',\n",
       " 'Genre(s)',\n",
       " 'Actor control',\n",
       " 'Production company',\n",
       " 'Release(s)',\n",
       " 'Format(s)',\n",
       " 'Simplified',\n",
       " 'Characters',\n",
       " 'Date premiered',\n",
       " 'Place premiered',\n",
       " 'Setting',\n",
       " 'Original language',\n",
       " 'Subject',\n",
       " 'Published',\n",
       " 'Dewey Decimal',\n",
       " 'Text',\n",
       " 'Illustrator',\n",
       " 'Original title',\n",
       " 'Published in English',\n",
       " 'French',\n",
       " 'Developed by',\n",
       " 'Ending theme',\n",
       " 'No. of seasons',\n",
       " 'Nationality',\n",
       " 'Portrayed by',\n",
       " 'Alias',\n",
       " 'Species',\n",
       " 'Gender',\n",
       " 'Family',\n",
       " 'Alma mater',\n",
       " 'Camera setup',\n",
       " 'Novel(s)',\n",
       " 'Comics',\n",
       " 'Film(s)',\n",
       " 'Screen story by',\n",
       " 'Hangul',\n",
       " 'Revised Romanization',\n",
       " 'McCune–Reischauer',\n",
       " 'Developer(s)',\n",
       " 'Publisher(s)',\n",
       " 'Designer(s)',\n",
       " 'Programmer(s)',\n",
       " 'Artist(s)',\n",
       " 'Writer(s)',\n",
       " 'Engine',\n",
       " 'Platform(s)',\n",
       " 'Release',\n",
       " 'Mode(s)',\n",
       " 'Original work',\n",
       " 'Television series',\n",
       " 'Japanese',\n",
       " 'Hepburn',\n",
       " 'Literally',\n",
       " 'Cantonese',\n",
       " 'Full name',\n",
       " 'Height',\n",
       " 'Seasons',\n",
       " 'Chinese',\n",
       " 'Other names',\n",
       " 'Relatives',\n",
       " 'Yiddish',\n",
       " 'Formerly',\n",
       " 'Key people',\n",
       " 'Total assets',\n",
       " 'Owner',\n",
       " 'Number of employees',\n",
       " 'Divisions',\n",
       " 'Subsidiaries',\n",
       " 'Arabic',\n",
       " 'Romanized',\n",
       " 'Predecessor',\n",
       " 'Founders',\n",
       " 'Area served',\n",
       " 'Products',\n",
       " 'Services',\n",
       " 'Russian',\n",
       " 'Hebrew',\n",
       " 'Revenue',\n",
       " 'Operating income',\n",
       " 'Polish']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View list of columns\n",
    "wiki_movies_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e3787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use List Comprehensions to Filter Data\n",
    "# Expected outcome: resulting list will only have elements where filter expressions are True.\n",
    "# List comprenhension with filter expression\n",
    "wiki_movies=[movie for movie in wiki_movies_raw\n",
    "             if ('Director' in movie or 'Directed by' in movie)\n",
    "             and 'imdb_link' in movie\n",
    "             # add additional elements as needed\n",
    "             and 'No. of episodes' not in movie]\n",
    "             # ^Exludes TV shows\n",
    "len(wiki_movies)\n",
    "# Intermediate variable used: wiki_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1bbbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nondestructive edits: keep raw data intact, create new variable for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8977fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>title</th>\n",
       "      <th>Directed by</th>\n",
       "      <th>Produced by</th>\n",
       "      <th>Screenplay by</th>\n",
       "      <th>Story by</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Starring</th>\n",
       "      <th>...</th>\n",
       "      <th>Hepburn</th>\n",
       "      <th>Literally</th>\n",
       "      <th>Cantonese</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Yiddish</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>Romanized</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Hebrew</th>\n",
       "      <th>Polish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0098987/</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>Renny Harlin</td>\n",
       "      <td>[Steve Perry, Joel Silver]</td>\n",
       "      <td>[David Arnott, James Cappe, Daniel Waters]</td>\n",
       "      <td>[David Arnott, James Cappe]</td>\n",
       "      <td>[Characters, by Rex Weiner]</td>\n",
       "      <td>[Andrew Dice Clay, Wayne Newton, Priscilla Pre...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org/wiki/After_Dark,_My_S...</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0098994/</td>\n",
       "      <td>After Dark, My Sweet</td>\n",
       "      <td>James Foley</td>\n",
       "      <td>[Ric Kidney, Robert Redlin]</td>\n",
       "      <td>[James Foley, Robert Redlin]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[the novel, After Dark, My Sweet, by, Jim Thom...</td>\n",
       "      <td>[Jason Patric, Rachel Ward, Bruce Dern, George...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Air_America_(film)</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099005/</td>\n",
       "      <td>Air America</td>\n",
       "      <td>Roger Spottiswoode</td>\n",
       "      <td>Daniel Melnick</td>\n",
       "      <td>[John Eskow, Richard Rush]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Air America, by, Christopher Robbins]</td>\n",
       "      <td>[Mel Gibson, Robert Downey Jr., Nancy Travis, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_(1990_film)</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099012/</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Woody Allen</td>\n",
       "      <td>Robert Greenhut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Alec Baldwin, Blythe Danner, Judy Davis, Mia ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Almost_an_Angel</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099018/</td>\n",
       "      <td>Almost an Angel</td>\n",
       "      <td>John Cornell</td>\n",
       "      <td>John Cornell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Paul Hogan, Elias Koteas, Linda Kozlowski]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  year  \\\n",
       "0  https://en.wikipedia.org/wiki/The_Adventures_o...  1990   \n",
       "1  https://en.wikipedia.org/wiki/After_Dark,_My_S...  1990   \n",
       "2   https://en.wikipedia.org/wiki/Air_America_(film)  1990   \n",
       "3    https://en.wikipedia.org/wiki/Alice_(1990_film)  1990   \n",
       "4      https://en.wikipedia.org/wiki/Almost_an_Angel  1990   \n",
       "\n",
       "                               imdb_link                            title  \\\n",
       "0  https://www.imdb.com/title/tt0098987/  The Adventures of Ford Fairlane   \n",
       "1  https://www.imdb.com/title/tt0098994/             After Dark, My Sweet   \n",
       "2  https://www.imdb.com/title/tt0099005/                      Air America   \n",
       "3  https://www.imdb.com/title/tt0099012/                            Alice   \n",
       "4  https://www.imdb.com/title/tt0099018/                  Almost an Angel   \n",
       "\n",
       "          Directed by                  Produced by  \\\n",
       "0        Renny Harlin   [Steve Perry, Joel Silver]   \n",
       "1         James Foley  [Ric Kidney, Robert Redlin]   \n",
       "2  Roger Spottiswoode               Daniel Melnick   \n",
       "3         Woody Allen              Robert Greenhut   \n",
       "4        John Cornell                 John Cornell   \n",
       "\n",
       "                                Screenplay by                     Story by  \\\n",
       "0  [David Arnott, James Cappe, Daniel Waters]  [David Arnott, James Cappe]   \n",
       "1                [James Foley, Robert Redlin]                          NaN   \n",
       "2                  [John Eskow, Richard Rush]                          NaN   \n",
       "3                                         NaN                          NaN   \n",
       "4                                         NaN                          NaN   \n",
       "\n",
       "                                            Based on  \\\n",
       "0                        [Characters, by Rex Weiner]   \n",
       "1  [the novel, After Dark, My Sweet, by, Jim Thom...   \n",
       "2             [Air America, by, Christopher Robbins]   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Starring  ... Hepburn Literally  \\\n",
       "0  [Andrew Dice Clay, Wayne Newton, Priscilla Pre...  ...     NaN       NaN   \n",
       "1  [Jason Patric, Rachel Ward, Bruce Dern, George...  ...     NaN       NaN   \n",
       "2  [Mel Gibson, Robert Downey Jr., Nancy Travis, ...  ...     NaN       NaN   \n",
       "3  [Alec Baldwin, Blythe Danner, Judy Davis, Mia ...  ...     NaN       NaN   \n",
       "4        [Paul Hogan, Elias Koteas, Linda Kozlowski]  ...     NaN       NaN   \n",
       "\n",
       "  Cantonese Chinese Yiddish Arabic Romanized Russian Hebrew Polish  \n",
       "0       NaN     NaN     NaN    NaN       NaN     NaN    NaN    NaN  \n",
       "1       NaN     NaN     NaN    NaN       NaN     NaN    NaN    NaN  \n",
       "2       NaN     NaN     NaN    NaN       NaN     NaN    NaN    NaN  \n",
       "3       NaN     NaN     NaN    NaN       NaN     NaN    NaN    NaN  \n",
       "4       NaN     NaN     NaN    NaN       NaN     NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create _df from wiki_movies\n",
    "only_movies_df = pd.DataFrame(wiki_movies)\n",
    "only_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62e3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c555ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"scope\" of variables:\n",
    "    # Variables created outside the function are called global variables.\n",
    "    # New variables created inside the function are local variables.\n",
    "    # The hierarchy of variables is called the scope.\n",
    "    # Local variables only work inside the function in which they are created.\n",
    "    # ^ifelse NameError\n",
    "# Do not mutate objects without creating new variables for new objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2bae780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda Functions: most stripped-down \n",
    "    # also known as \"anonymous functions\"\n",
    "    # can be used as one-time-use functions\n",
    "    # Syntax: lambda arguments: expression\n",
    "    # Ex: lambda x: x * x\n",
    "    # square = lambda x: x * x\n",
    "    # square(5)   \n",
    "    # output: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "475d2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Create and define the function\n",
    "# Assign variable: clean_movie, parameter: movie\n",
    "def clean_movie(movie):\n",
    "    # create a non-destructive copy of original movie object\n",
    "    movie = dict(movie)\n",
    "    # Add in code to combine alternate titles into one list\n",
    "    # 1st Make empty dict{} to hold alternative titles\n",
    "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
    "    alt_titles = {}\n",
    "    # 2nd Loop through list of alternative title keys\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
    "            # 2nd.a Check if the current keys exist in the movie\n",
    "            if key in movie:\n",
    "                alt_titles[key] = movie[key]\n",
    "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
    "                movie.pop(key)\n",
    "    # 3rd After looping through every key\n",
    "    if len(alt_titles) > 0:\n",
    "            # 3rd Add the alternative titles dict to the movie object\n",
    "            movie['alt_titles'] = alt_titles\n",
    "# Part 2\n",
    "    # Make an inner function to find and change irregularities\n",
    "    # ^In this case merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "            if old_name in movie:\n",
    "                movie[new_name] = movie.pop(old_name)\n",
    "    # Go through each column name and decide if there's a better name for it\n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "    \n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75ab5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop() returns the value from the removed key-value pair\n",
    "# Therefore, check if the key exists in a given object first\n",
    "# i.e.        #C heck if the current keys exist in the movie\n",
    "#             if key in movie:\n",
    "#                 alt_titles[key] = movie[key]\n",
    "#                 # Remove the key-value pair/bond, Syntax: .pop()\n",
    "#                 movie.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aa78dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of cleaned movies with list comprehension:\n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54246260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation by',\n",
       " 'Audio format',\n",
       " 'Based on',\n",
       " 'Box office',\n",
       " 'Budget',\n",
       " 'Cinematography',\n",
       " 'Color process',\n",
       " 'Composer(s)',\n",
       " 'Country',\n",
       " 'Created by',\n",
       " 'Director',\n",
       " 'Distributor',\n",
       " 'Editor(s)',\n",
       " 'Executive producer(s)',\n",
       " 'Followed by',\n",
       " 'Genre',\n",
       " 'Label',\n",
       " 'Language',\n",
       " 'Narrated by',\n",
       " 'Original language(s)',\n",
       " 'Original network',\n",
       " 'Picture format',\n",
       " 'Preceded by',\n",
       " 'Producer(s)',\n",
       " 'Production company(s)',\n",
       " 'Production location(s)',\n",
       " 'Recorded',\n",
       " 'Release date',\n",
       " 'Running time',\n",
       " 'Starring',\n",
       " 'Suggested by',\n",
       " 'Venue',\n",
       " 'Voices of',\n",
       " 'Writer(s)',\n",
       " 'alt_titles',\n",
       " 'imdb_link',\n",
       " 'title',\n",
       " 'url',\n",
       " 'year']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set wiki_movies_df to be the DataFrame created from clean_movies \n",
    "wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "# print out list of the columns in alphabetical order\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc3ca22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a movie by searching through a column (i.e. languages)\n",
    "# Inclue ['url'] in output\n",
    "#wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2961436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicate Rows with .str.extract() and regex\n",
    "\n",
    "# Regular expressions, also known as regex, are strings of characters that define a search pattern\n",
    "# ^A more formal way of defining these kinds of patterns so that our code can find them\n",
    "# Regex are easily recognizable because they follow well-defined patterns\n",
    "\n",
    "# In this case we're searching for the IMDb id, ex: tt1234567\n",
    "# Regex for the IMDb ID object is: start with \"tt\" and has seven digits\n",
    "# When searching for the object use syntax: \"(tt\\d{7})\"\n",
    "# \"()\": look for one group of text.\n",
    "# \"tt\": match two lowercase Ts.\n",
    "# \"\\d\":match a numerical digit.\n",
    "# \"{7}\":match the last thing (numerical digits) exactly seven times.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbbfe27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7076\n"
     ]
    }
   ],
   "source": [
    "# Extract the IMDb ID\n",
    "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "print(len(wiki_movies_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8502123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7033\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates of IMDb IDs by using drop_duplicates(), subset=, and inplace=\n",
    "# To specify that we only want the IMDb ID, use the subset argument, set inplace equal to True so that the operation is performed on the selected dataframe.\n",
    "wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "print(len(wiki_movies_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87cfd54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>title</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Starring</th>\n",
       "      <th>Narrated by</th>\n",
       "      <th>Cinematography</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Running time</th>\n",
       "      <th>...</th>\n",
       "      <th>Created by</th>\n",
       "      <th>Preceded by</th>\n",
       "      <th>Suggested by</th>\n",
       "      <th>alt_titles</th>\n",
       "      <th>Recorded</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Label</th>\n",
       "      <th>Animation by</th>\n",
       "      <th>Color process</th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0098987/</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>[Characters, by Rex Weiner]</td>\n",
       "      <td>[Andrew Dice Clay, Wayne Newton, Priscilla Pre...</td>\n",
       "      <td>Andrew \"Dice\" Clay</td>\n",
       "      <td>Oliver Wood</td>\n",
       "      <td>[July 11, 1990, (, 1990-07-11, )]</td>\n",
       "      <td>102 minutes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0098987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org/wiki/After_Dark,_My_S...</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0098994/</td>\n",
       "      <td>After Dark, My Sweet</td>\n",
       "      <td>[the novel, After Dark, My Sweet, by, Jim Thom...</td>\n",
       "      <td>[Jason Patric, Rachel Ward, Bruce Dern, George...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mark Plummer</td>\n",
       "      <td>[May 17, 1990, (, 1990-05-17, ), (Cannes Film ...</td>\n",
       "      <td>114 minutes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0098994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Air_America_(film)</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099005/</td>\n",
       "      <td>Air America</td>\n",
       "      <td>[Air America, by, Christopher Robbins]</td>\n",
       "      <td>[Mel Gibson, Robert Downey Jr., Nancy Travis, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Deakins</td>\n",
       "      <td>[August 10, 1990, (, 1990-08-10, )]</td>\n",
       "      <td>113 minutes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0099005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_(1990_film)</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099012/</td>\n",
       "      <td>Alice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Alec Baldwin, Blythe Danner, Judy Davis, Mia ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carlo Di Palma</td>\n",
       "      <td>[December 25, 1990, (, 1990-12-25, )]</td>\n",
       "      <td>106 minutes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0099012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Almost_an_Angel</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099018/</td>\n",
       "      <td>Almost an Angel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Paul Hogan, Elias Koteas, Linda Kozlowski]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russell Boyd</td>\n",
       "      <td>December 19, 1990</td>\n",
       "      <td>95 minutes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0099018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  year  \\\n",
       "0  https://en.wikipedia.org/wiki/The_Adventures_o...  1990   \n",
       "1  https://en.wikipedia.org/wiki/After_Dark,_My_S...  1990   \n",
       "2   https://en.wikipedia.org/wiki/Air_America_(film)  1990   \n",
       "3    https://en.wikipedia.org/wiki/Alice_(1990_film)  1990   \n",
       "4      https://en.wikipedia.org/wiki/Almost_an_Angel  1990   \n",
       "\n",
       "                               imdb_link                            title  \\\n",
       "0  https://www.imdb.com/title/tt0098987/  The Adventures of Ford Fairlane   \n",
       "1  https://www.imdb.com/title/tt0098994/             After Dark, My Sweet   \n",
       "2  https://www.imdb.com/title/tt0099005/                      Air America   \n",
       "3  https://www.imdb.com/title/tt0099012/                            Alice   \n",
       "4  https://www.imdb.com/title/tt0099018/                  Almost an Angel   \n",
       "\n",
       "                                            Based on  \\\n",
       "0                        [Characters, by Rex Weiner]   \n",
       "1  [the novel, After Dark, My Sweet, by, Jim Thom...   \n",
       "2             [Air America, by, Christopher Robbins]   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Starring         Narrated by  \\\n",
       "0  [Andrew Dice Clay, Wayne Newton, Priscilla Pre...  Andrew \"Dice\" Clay   \n",
       "1  [Jason Patric, Rachel Ward, Bruce Dern, George...                 NaN   \n",
       "2  [Mel Gibson, Robert Downey Jr., Nancy Travis, ...                 NaN   \n",
       "3  [Alec Baldwin, Blythe Danner, Judy Davis, Mia ...                 NaN   \n",
       "4        [Paul Hogan, Elias Koteas, Linda Kozlowski]                 NaN   \n",
       "\n",
       "   Cinematography                                       Release date  \\\n",
       "0     Oliver Wood                  [July 11, 1990, (, 1990-07-11, )]   \n",
       "1    Mark Plummer  [May 17, 1990, (, 1990-05-17, ), (Cannes Film ...   \n",
       "2   Roger Deakins                [August 10, 1990, (, 1990-08-10, )]   \n",
       "3  Carlo Di Palma              [December 25, 1990, (, 1990-12-25, )]   \n",
       "4    Russell Boyd                                  December 19, 1990   \n",
       "\n",
       "  Running time  ... Created by Preceded by Suggested by alt_titles Recorded  \\\n",
       "0  102 minutes  ...        NaN         NaN          NaN        NaN      NaN   \n",
       "1  114 minutes  ...        NaN         NaN          NaN        NaN      NaN   \n",
       "2  113 minutes  ...        NaN         NaN          NaN        NaN      NaN   \n",
       "3  106 minutes  ...        NaN         NaN          NaN        NaN      NaN   \n",
       "4   95 minutes  ...        NaN         NaN          NaN        NaN      NaN   \n",
       "\n",
       "  Venue Label Animation by Color process    imdb_id  \n",
       "0   NaN   NaN          NaN           NaN  tt0098987  \n",
       "1   NaN   NaN          NaN           NaN  tt0098994  \n",
       "2   NaN   NaN          NaN           NaN  tt0099005  \n",
       "3   NaN   NaN          NaN           NaN  tt0099012  \n",
       "4   NaN   NaN          NaN           NaN  tt0099018  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4efc6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Mostly Null Columns with list comprehension \n",
    "# Make a list of columns that have less than 90% null values, use those to trim down our dataset.\n",
    "# Use the list comprehension to produce only the wanted columns\n",
    "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "# Update  _df\n",
    "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e837c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>title</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Starring</th>\n",
       "      <th>Cinematography</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Running time</th>\n",
       "      <th>Country</th>\n",
       "      <th>...</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Box office</th>\n",
       "      <th>Director</th>\n",
       "      <th>Distributor</th>\n",
       "      <th>Editor(s)</th>\n",
       "      <th>Composer(s)</th>\n",
       "      <th>Producer(s)</th>\n",
       "      <th>Production company(s)</th>\n",
       "      <th>Writer(s)</th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0098987/</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>[Characters, by Rex Weiner]</td>\n",
       "      <td>[Andrew Dice Clay, Wayne Newton, Priscilla Pre...</td>\n",
       "      <td>Oliver Wood</td>\n",
       "      <td>[July 11, 1990, (, 1990-07-11, )]</td>\n",
       "      <td>102 minutes</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>$20 million</td>\n",
       "      <td>$21.4 million</td>\n",
       "      <td>Renny Harlin</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>Michael Tronick</td>\n",
       "      <td>[Cliff Eidelman, Yello]</td>\n",
       "      <td>[Steve Perry, Joel Silver]</td>\n",
       "      <td>Silver Pictures</td>\n",
       "      <td>[David Arnott, James Cappe]</td>\n",
       "      <td>tt0098987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org/wiki/After_Dark,_My_S...</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0098994/</td>\n",
       "      <td>After Dark, My Sweet</td>\n",
       "      <td>[the novel, After Dark, My Sweet, by, Jim Thom...</td>\n",
       "      <td>[Jason Patric, Rachel Ward, Bruce Dern, George...</td>\n",
       "      <td>Mark Plummer</td>\n",
       "      <td>[May 17, 1990, (, 1990-05-17, ), (Cannes Film ...</td>\n",
       "      <td>114 minutes</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>$6 million</td>\n",
       "      <td>$2.7 million</td>\n",
       "      <td>James Foley</td>\n",
       "      <td>Avenue Pictures</td>\n",
       "      <td>Howard E. Smith</td>\n",
       "      <td>Maurice Jarre</td>\n",
       "      <td>[Ric Kidney, Robert Redlin]</td>\n",
       "      <td>Avenue Pictures</td>\n",
       "      <td>[James Foley, Robert Redlin]</td>\n",
       "      <td>tt0098994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Air_America_(film)</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099005/</td>\n",
       "      <td>Air America</td>\n",
       "      <td>[Air America, by, Christopher Robbins]</td>\n",
       "      <td>[Mel Gibson, Robert Downey Jr., Nancy Travis, ...</td>\n",
       "      <td>Roger Deakins</td>\n",
       "      <td>[August 10, 1990, (, 1990-08-10, )]</td>\n",
       "      <td>113 minutes</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>$35 million</td>\n",
       "      <td>$57,718,089</td>\n",
       "      <td>Roger Spottiswoode</td>\n",
       "      <td>TriStar Pictures</td>\n",
       "      <td>[John Bloom, Lois Freeman-Fox]</td>\n",
       "      <td>Charles Gross</td>\n",
       "      <td>Daniel Melnick</td>\n",
       "      <td>[Carolco Pictures, IndieProd Company]</td>\n",
       "      <td>[John Eskow, Richard Rush]</td>\n",
       "      <td>tt0099005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_(1990_film)</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099012/</td>\n",
       "      <td>Alice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Alec Baldwin, Blythe Danner, Judy Davis, Mia ...</td>\n",
       "      <td>Carlo Di Palma</td>\n",
       "      <td>[December 25, 1990, (, 1990-12-25, )]</td>\n",
       "      <td>106 minutes</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>$12 million</td>\n",
       "      <td>$7,331,647</td>\n",
       "      <td>Woody Allen</td>\n",
       "      <td>Orion Pictures</td>\n",
       "      <td>Susan E. Morse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert Greenhut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Woody Allen</td>\n",
       "      <td>tt0099012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Almost_an_Angel</td>\n",
       "      <td>1990</td>\n",
       "      <td>https://www.imdb.com/title/tt0099018/</td>\n",
       "      <td>Almost an Angel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Paul Hogan, Elias Koteas, Linda Kozlowski]</td>\n",
       "      <td>Russell Boyd</td>\n",
       "      <td>December 19, 1990</td>\n",
       "      <td>95 minutes</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>$25 million</td>\n",
       "      <td>$6,939,946 (USA)</td>\n",
       "      <td>John Cornell</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>David Stiven</td>\n",
       "      <td>Maurice Jarre</td>\n",
       "      <td>John Cornell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paul Hogan</td>\n",
       "      <td>tt0099018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  year  \\\n",
       "0  https://en.wikipedia.org/wiki/The_Adventures_o...  1990   \n",
       "1  https://en.wikipedia.org/wiki/After_Dark,_My_S...  1990   \n",
       "2   https://en.wikipedia.org/wiki/Air_America_(film)  1990   \n",
       "3    https://en.wikipedia.org/wiki/Alice_(1990_film)  1990   \n",
       "4      https://en.wikipedia.org/wiki/Almost_an_Angel  1990   \n",
       "\n",
       "                               imdb_link                            title  \\\n",
       "0  https://www.imdb.com/title/tt0098987/  The Adventures of Ford Fairlane   \n",
       "1  https://www.imdb.com/title/tt0098994/             After Dark, My Sweet   \n",
       "2  https://www.imdb.com/title/tt0099005/                      Air America   \n",
       "3  https://www.imdb.com/title/tt0099012/                            Alice   \n",
       "4  https://www.imdb.com/title/tt0099018/                  Almost an Angel   \n",
       "\n",
       "                                            Based on  \\\n",
       "0                        [Characters, by Rex Weiner]   \n",
       "1  [the novel, After Dark, My Sweet, by, Jim Thom...   \n",
       "2             [Air America, by, Christopher Robbins]   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            Starring  Cinematography  \\\n",
       "0  [Andrew Dice Clay, Wayne Newton, Priscilla Pre...     Oliver Wood   \n",
       "1  [Jason Patric, Rachel Ward, Bruce Dern, George...    Mark Plummer   \n",
       "2  [Mel Gibson, Robert Downey Jr., Nancy Travis, ...   Roger Deakins   \n",
       "3  [Alec Baldwin, Blythe Danner, Judy Davis, Mia ...  Carlo Di Palma   \n",
       "4        [Paul Hogan, Elias Koteas, Linda Kozlowski]    Russell Boyd   \n",
       "\n",
       "                                        Release date Running time  \\\n",
       "0                  [July 11, 1990, (, 1990-07-11, )]  102 minutes   \n",
       "1  [May 17, 1990, (, 1990-05-17, ), (Cannes Film ...  114 minutes   \n",
       "2                [August 10, 1990, (, 1990-08-10, )]  113 minutes   \n",
       "3              [December 25, 1990, (, 1990-12-25, )]  106 minutes   \n",
       "4                                  December 19, 1990   95 minutes   \n",
       "\n",
       "         Country  ...       Budget        Box office            Director  \\\n",
       "0  United States  ...  $20 million     $21.4 million        Renny Harlin   \n",
       "1  United States  ...   $6 million      $2.7 million         James Foley   \n",
       "2  United States  ...  $35 million       $57,718,089  Roger Spottiswoode   \n",
       "3  United States  ...  $12 million        $7,331,647         Woody Allen   \n",
       "4             US  ...  $25 million  $6,939,946 (USA)        John Cornell   \n",
       "\n",
       "          Distributor                       Editor(s)  \\\n",
       "0    20th Century Fox                 Michael Tronick   \n",
       "1     Avenue Pictures                 Howard E. Smith   \n",
       "2    TriStar Pictures  [John Bloom, Lois Freeman-Fox]   \n",
       "3      Orion Pictures                  Susan E. Morse   \n",
       "4  Paramount Pictures                    David Stiven   \n",
       "\n",
       "               Composer(s)                  Producer(s)  \\\n",
       "0  [Cliff Eidelman, Yello]   [Steve Perry, Joel Silver]   \n",
       "1            Maurice Jarre  [Ric Kidney, Robert Redlin]   \n",
       "2            Charles Gross               Daniel Melnick   \n",
       "3                      NaN              Robert Greenhut   \n",
       "4            Maurice Jarre                 John Cornell   \n",
       "\n",
       "                   Production company(s)                     Writer(s)  \\\n",
       "0                        Silver Pictures   [David Arnott, James Cappe]   \n",
       "1                        Avenue Pictures  [James Foley, Robert Redlin]   \n",
       "2  [Carolco Pictures, IndieProd Company]    [John Eskow, Richard Rush]   \n",
       "3                                    NaN                   Woody Allen   \n",
       "4                                    NaN                    Paul Hogan   \n",
       "\n",
       "     imdb_id  \n",
       "0  tt0098987  \n",
       "1  tt0098994  \n",
       "2  tt0099005  \n",
       "3  tt0099012  \n",
       "4  tt0099018  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7983786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                      object\n",
       "year                      int64\n",
       "imdb_link                object\n",
       "title                    object\n",
       "Based on                 object\n",
       "Starring                 object\n",
       "Cinematography           object\n",
       "Release date             object\n",
       "Running time             object\n",
       "Country                  object\n",
       "Language                 object\n",
       "Budget                   object\n",
       "Box office               object\n",
       "Director                 object\n",
       "Distributor              object\n",
       "Editor(s)                object\n",
       "Composer(s)              object\n",
       "Producer(s)              object\n",
       "Production company(s)    object\n",
       "Writer(s)                object\n",
       "imdb_id                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a Plan to Convert and Parse the Data\n",
    "\n",
    "# 1st Identify which columns need to be converted.\n",
    "wiki_movies_df.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46b18251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data series that drops missing values\n",
    "box_office = wiki_movies_df['Box office'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d20ef8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34                           [US$, 4,212,828]\n",
       "54      [$6,698,361 (, United States, ), [2]]\n",
       "74                    [$6,488,144, (US), [1]]\n",
       "126                [US$1,531,489, (domestic)]\n",
       "130                          [US$, 4,803,039]\n",
       "                        ...                  \n",
       "6980               [$99.6, million, [4], [5]]\n",
       "6994                   [$365.6, million, [1]]\n",
       "6995                         [$53.8, million]\n",
       "7015                     [$435, million, [7]]\n",
       "7048                   [$529.3, million, [4]]\n",
       "Name: Box office, Length: 135, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a function to be able to filter out non string values.\n",
    "# ^This needs to be done because regex only work on strings\n",
    "# SyntaX is_not_a_string() \n",
    "def is_not_a_string(x):\n",
    "    return type(x) != str\n",
    "# Show values that are not strings\n",
    "box_office[box_office.map(is_not_a_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba1aa008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34                           [US$, 4,212,828]\n",
       "54      [$6,698,361 (, United States, ), [2]]\n",
       "74                    [$6,488,144, (US), [1]]\n",
       "126                [US$1,531,489, (domestic)]\n",
       "130                          [US$, 4,803,039]\n",
       "                        ...                  \n",
       "6980               [$99.6, million, [4], [5]]\n",
       "6994                   [$365.6, million, [1]]\n",
       "6995                         [$53.8, million]\n",
       "7015                     [$435, million, [7]]\n",
       "7048                   [$529.3, million, [4]]\n",
       "Name: Box office, Length: 135, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use lambda to make a stripped-down, one-line function which won't be used ever again outside of map()\n",
    "box_office[box_office.map(lambda x: type(x) != str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01f6274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^The out put shows data points stored as lists\n",
    "# Import re for regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee766361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          $21.4 million\n",
       "1           $2.7 million\n",
       "2            $57,718,089\n",
       "3             $7,331,647\n",
       "4       $6,939,946 (USA)\n",
       "              ...       \n",
       "7070       $19.4 million\n",
       "7071       $41.9 million\n",
       "7072       $76.1 million\n",
       "7073       $38.4 million\n",
       "7074        $5.5 million\n",
       "Name: Box office, Length: 5485, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use ' ' as the joining character and apply the join() function only when data points are lists\n",
    "# Use join() method to concatenate list items into one string\n",
    "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "box_office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de2d38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the Box Office Data\n",
    "\n",
    "# Build regex for each form the data is written in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f36842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for form $123.4 million/billion\n",
    "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
    "# ^Assign variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff26dda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3896"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count entires for form $123.4 million/billion\n",
    "box_office.str.contains(form_one, flags=re.IGNORECASE).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7dca3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for form $123,456,789 \n",
    "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "# ^Assign variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9205e285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1544"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count entires for form $123,456,789\n",
    "box_office.str.contains(form_two, flags=re.IGNORECASE).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7eb918ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Boolean Series for each form to find values not defined by either one.\n",
    "matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
    "matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5afe2cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34                         US$ 4,212,828\n",
       "79                              $335.000\n",
       "110                   $4.35-4.37 million\n",
       "130                        US$ 4,803,039\n",
       "600                           $5000 (US)\n",
       "731                         $ 11,146,270\n",
       "957                             $ 50,004\n",
       "1070                          35,254,617\n",
       "1147    $ 407,618 (U.S.) (sub-total) [1]\n",
       "1446                        $ 11,829,959\n",
       "1480                          £3 million\n",
       "1611                            $520.000\n",
       "1865                        ¥1.1 billion\n",
       "2032                                 N/A\n",
       "2091                                $309\n",
       "2130               US$ 171.8 million [9]\n",
       "2257                   US$ 3,395,581 [1]\n",
       "2263            $ 1,223,034 ( domestic )\n",
       "2347                            $282.175\n",
       "2638            $ 104,883 (US sub-total)\n",
       "2665         926,423 admissions (France)\n",
       "2697      $ 1.7 million (US) (sub-total)\n",
       "2823                            $414.000\n",
       "2924                            $621.000\n",
       "3088           $32 [2] –33.1 million [1]\n",
       "3631                                 TBA\n",
       "3859                  $38.9–40.3 million\n",
       "3879            CN¥3.650 million (China)\n",
       "4116                          £7,385,434\n",
       "4123                            $161.000\n",
       "4261                  $20.7–23.9 million\n",
       "4306                              $20-30\n",
       "4492                        $47.7 millon\n",
       "4561             $45.2k (only in Turkey)\n",
       "4662                USD$ 8.2 million [2]\n",
       "5362                   $ 142 million [3]\n",
       "5447                               £2.56\n",
       "5784                            413 733$\n",
       "6013                             Unknown\n",
       "6145                  $17.5–18.4 million\n",
       "6234                  $41.8–41.9 million\n",
       "6369                               $111k\n",
       "6370                                $588\n",
       "6593                      less than $372\n",
       "6829                    $ 41 million [3]\n",
       "6843                             8 crore\n",
       "6904                         $6.9 millon\n",
       "Name: Box office, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find values not defined by forms 1 and 2\n",
    "box_office[~matches_form_one & ~matches_form_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30272585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Pattern Matches\n",
    "\n",
    "# Correct values with spaces between $ and the number\n",
    "# ^Add \\s* after the dollar sign\n",
    "# Correct mispelled \"millon\", make i optional i?\n",
    "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4599295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct values that use a period as a thousands separator, not a comma\n",
    "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8333213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct values that are given as a range\n",
    "box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de428406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and Convert the Box Office Values\n",
    "# Create/define function\n",
    "def parse_dollars(s):\n",
    "    # if s is not a string, return NaN\n",
    "    if type(s) != str:\n",
    "        return np.nan\n",
    "\n",
    "    # if input is of the form $###.# million\n",
    "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" million\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a million\n",
    "        value = float(s) * 10**6\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###.# billion\n",
    "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" billion\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a billion\n",
    "        value = float(s) * 10**9\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###,###,###\n",
    "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and commas\n",
    "        s = re.sub('\\$|,','', s)\n",
    "\n",
    "        # convert to float\n",
    "        value = float(s)\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # otherwise, return NaN\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fa4ddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       21400000.0\n",
       "1        2700000.0\n",
       "2       57718089.0\n",
       "3        7331647.0\n",
       "4        6939946.0\n",
       "           ...    \n",
       "7071    41900000.0\n",
       "7072    76100000.0\n",
       "7073    38400000.0\n",
       "7074     5500000.0\n",
       "7075           NaN\n",
       "Name: box_office, Length: 7033, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the values from box_office\n",
    "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "wiki_movies_df['box_office'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "158bddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Box Office column since it's no longer needed\n",
    "wiki_movies_df.drop('Box office', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fd4c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Budget Data\n",
    "\n",
    "# Create a budget variable with the following code\n",
    "budget = wiki_movies_df['Budget'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efd493d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to strings\n",
    "budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "276850be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove values between a dollar sign and a hyphen (for budgets given in ranges)\n",
    "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c2c4b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136                         Unknown\n",
       "204     60 million Norwegian Kroner\n",
       "478                         Unknown\n",
       "1226                        Unknown\n",
       "1278                            HBO\n",
       "1374                     £6,000,000\n",
       "1397                     13 million\n",
       "1480                   £2.8 million\n",
       "1734                   CAD2,000,000\n",
       "1913     PHP 85 million (estimated)\n",
       "1948                    102,888,900\n",
       "1953                   3,500,000 DM\n",
       "1973                     ₤2,300,874\n",
       "2281                     $14 milion\n",
       "2451                     ₤6,350,000\n",
       "3144                   € 40 million\n",
       "3418                        $218.32\n",
       "3802                   £4.2 million\n",
       "3906                            N/A\n",
       "3959                    760,000 USD\n",
       "4470                       19 crore\n",
       "4641                    £17 million\n",
       "5424                            N/A\n",
       "5447                     £4 million\n",
       "5671                    €14 million\n",
       "5687                   $ dead link]\n",
       "6385                  £ 12 million \n",
       "6593                     £3 million\n",
       "6821                  £12.9 million\n",
       "6843                      3.5 crore\n",
       "6895                        919,000\n",
       "7070                   €4.3 million\n",
       "Name: Budget, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Boolean Series for each form to find values not defined by either one\n",
    "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
    "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
    "# Find the values from budget\n",
    "budget[~matches_form_one & ~matches_form_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e010df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove citation references\n",
    "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "budget[~matches_form_one & ~matches_form_two].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f67a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the values from budget\n",
    "wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fc31eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original Budget column\n",
    "wiki_movies_df.drop('Budget', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "224712db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Release Date\n",
    "\n",
    "\n",
    "# Assign variable for Release date column's non-null values in the DataFrame, convert lists to strings\n",
    "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3914c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forms to extract\n",
    "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]?\\d,\\s\\d{4}'\n",
    "date_form_two = r'\\d{4}.[01]\\d.[0123]\\d'\n",
    "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "date_form_four = r'\\d{4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6b60be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 11, 1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 17, 1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>August 10, 1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December 25, 1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>December 19, 1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>December 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7072</th>\n",
       "      <td>December 11, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073</th>\n",
       "      <td>November 8, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074</th>\n",
       "      <td>August 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>December 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "0         July 11, 1990\n",
       "1          May 17, 1990\n",
       "2       August 10, 1990\n",
       "3     December 25, 1990\n",
       "4     December 19, 1990\n",
       "...                 ...\n",
       "7071  December 25, 2018\n",
       "7072  December 11, 2018\n",
       "7073   November 8, 2018\n",
       "7074    August 31, 2018\n",
       "7075      December 2018\n",
       "\n",
       "[7001 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Dates\n",
    "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fac2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates\n",
    "wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da210468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 102 minutes\n",
       "1                                 114 minutes\n",
       "2                                 113 minutes\n",
       "3                                 106 minutes\n",
       "4                                  95 minutes\n",
       "                        ...                  \n",
       "7071                               90 minutes\n",
       "7072                              132 minutes\n",
       "7073                              120 minutes\n",
       "7074                              123 minutes\n",
       "7075    Variable; 90 minutes for default path\n",
       "Name: Running time, Length: 6894, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign variable for Running time column's non-null values in the DataFrame, convert lists to strings\n",
    "running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f917e384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6528"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for all \"100 minutes\" form\n",
    "running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d9b5dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9                                                 102 min\n",
       "26                                                 93 min\n",
       "28                                                32 min.\n",
       "34                                                101 min\n",
       "35                                                 97 min\n",
       "                              ...                        \n",
       "6500       114 minutes [1] 120 minutes (extended edition)\n",
       "6643                                             104 mins\n",
       "6709    90 minutes (theatrical) [1] 91 minutes (unrate...\n",
       "7057    108 minutes (Original cut) 98 minutes (UK cut)...\n",
       "7075                Variable; 90 minutes for default path\n",
       "Name: Running time, Length: 366, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find values not defined by \"100 minutes\" form\n",
    "running_time[running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ef4f7d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6877"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all values with other abbreviations of \"minutes\"\n",
    "running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90377a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668                     UK:84 min (DVD version) US:86 min\n",
       "727                         78-102 min (depending on cut)\n",
       "840                       Varies (79 [3] –84 [1] minutes)\n",
       "1347                                              25 : 03\n",
       "1443    United States: 77 minutes Argentina: 94 minute...\n",
       "1499                                            1hr 35min\n",
       "1551                                               varies\n",
       "1774                    Netherlands:96 min, Canada:95 min\n",
       "1777                                       approx. 14 min\n",
       "2273                                           1 h 43 min\n",
       "2993                                               1h 48m\n",
       "3925                                              4 hours\n",
       "4425    US domestic version: 86 minutes Original versi...\n",
       "4967    Theatrical cut: 97 minutes Unrated cut: 107 mi...\n",
       "5424                    115 [1] /123 [2] /128 [3] minutes\n",
       "5447                                    1 hour 32 minutes\n",
       "7075                Variable; 90 minutes for default path\n",
       "Name: Running time, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find remaining 17 values\n",
    "running_time[running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cf40d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7072</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6894 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2\n",
       "0     NaN  NaN  102\n",
       "1     NaN  NaN  114\n",
       "2     NaN  NaN  113\n",
       "3     NaN  NaN  106\n",
       "4     NaN  NaN   95\n",
       "...   ...  ...  ...\n",
       "7071  NaN  NaN   90\n",
       "7072  NaN  NaN  132\n",
       "7073  NaN  NaN  120\n",
       "7074  NaN  NaN  123\n",
       "7075  NaN  NaN   90\n",
       "\n",
       "[6894 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only values with digits with both patterns\n",
    "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "running_time_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7022b230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7072</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6894 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1      2\n",
       "0     0.0  0.0  102.0\n",
       "1     0.0  0.0  114.0\n",
       "2     0.0  0.0  113.0\n",
       "3     0.0  0.0  106.0\n",
       "4     0.0  0.0   95.0\n",
       "...   ...  ...    ...\n",
       "7071  0.0  0.0   90.0\n",
       "7072  0.0  0.0  132.0\n",
       "7073  0.0  0.0  120.0\n",
       "7074  0.0  0.0  123.0\n",
       "7075  0.0  0.0   90.0\n",
       "\n",
       "[6894 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert strings to numeric values\n",
    "running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "running_time_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f52cf8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hour capture groups and minute capture groups to minutes IF pure minutes capture group is zero, save the output to wiki_movies_df\n",
    "wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62760123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Running time from dataset \n",
    "wiki_movies_df.drop('Running time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11216a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6904262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "332e1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
    "movies_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
    "rating_csvs= os.path.join(\"Movies_ETL\", \"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "57c86f31",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Movies_ETL\\\\movies_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17316\\1009879405.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read data and store it in Pandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# No _df variable until data is satisfactory, then store in DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mkaggle_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Movies_ETL\\\\movies_metadata.csv'"
     ]
    }
   ],
   "source": [
    "# Read data and store it in Pandas\n",
    "# No _df variable until data is satisfactory, then store in DataFrame\n",
    "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
    "ratings = pd.read_csv(ratings_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "80fe1866",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Movies_ETL\\\\movies_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17316\\3561655658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkaggle_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Movies_ETL\\\\movies_metadata.csv'"
     ]
    }
   ],
   "source": [
    "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
    "ratings = pd.read_csv(ratings_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9958ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "16afa445",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17316\\3844098494.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkaggle_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "kaggle_metadata.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bab9dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/1:\n",
      "# List of high schools\n",
      "hi_schools=[\"Hernandez High School\", \"Figueroa High School\", \"Wilson High School\"]\n",
      " 3/2:\n",
      "# List of high schools\n",
      "high_schools=[\"Hernandez High School\", \"Figueroa High School\", \"Wilson High School\", \"Wright High School\"]\n",
      "# Iterate through list and print out each high school name\n",
      "for school in high_schools:\n",
      "    print(school)\n",
      " 4/1:\n",
      "# Dictionary of high schools and the type of school.\n",
      "high_school_types=[{\"High School\": \"Griffin\", \"Type\":\"District\"},\n",
      "                  {\"High School\": \"Figueroa\", \"Type\": \"District\"},\n",
      "                  {\"High School\": \"Wilson\", \"Type\": \"Charter\"},\n",
      "                  {\"High School\": \"Wright\", \"Type\": \"Carter\"}]\n",
      "# Iterate through list and print out each high school name and their types.\n",
      "for school in high_school_types:\n",
      "    print (school)\n",
      " 5/1:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      " 5/2:\n",
      "# Declare a list of high schools.\n",
      "high_school_list: [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      " 5/3:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      " 5/4:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      " 6/1:\n",
      "# Declare a list of high schools.\n",
      "high_school_list= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      " 6/2:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      " 6/3:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      " 6/4:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      " 6/5:\n",
      "# Declare a list of high schools.\n",
      "high_schools=[\"Hernandez High School\", \"Figueroa High School\", \"Wilson High School\", \"Wright High School\"]\n",
      "# Iterate through list and print out each high school name.\n",
      "for school in high_schools:\n",
      "    print(school)\n",
      " 6/6:\n",
      "# Declare s dictionary of high schools and the type of school.\n",
      "high_school_types=[{\"High School\": \"Griffin\", \"Type\":\"District\"},\n",
      "                  {\"High School\": \"Figueroa\", \"Type\": \"District\"},\n",
      "                  {\"High School\": \"Wilson\", \"Type\": \"Charter\"},\n",
      "                  {\"High School\": \"Wright\", \"Type\": \"Carter\"}]\n",
      "# Iterate through list and print out each high school name and their types.\n",
      "for school in high_school_types:\n",
      "    print (school)\n",
      " 6/7:\n",
      "# Declare a list of high schools.\n",
      "high_school_list= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      " 6/8:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      " 6/9:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      "6/10:\n",
      "# Declare a list of high schools.\n",
      "high_school_list= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "6/11:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      "6/12:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      "6/13:\n",
      "# Declare a list of high schools.\n",
      "#high_schools=[\"Hernandez High School\", \"Figueroa High School\", \"Wilson High School\", \"Wright High School\"]\n",
      "# Iterate through list and print out each high school name.\n",
      "#for school in high_schools:\n",
      "    #print(school)\n",
      "6/14:\n",
      "# Declare s dictionary of high schools and the type of school.\n",
      "#high_school_types=[{\"High School\": \"Griffin\", \"Type\":\"District\"},\n",
      "                  {\"High School\": \"Figueroa\", \"Type\": \"District\"},\n",
      "                  {\"High School\": \"Wilson\", \"Type\": \"Charter\"},\n",
      "                  {\"High School\": \"Wright\", \"Type\": \"Carter\"}]\n",
      "# Iterate through list and print out each high school name and their types.\n",
      "#for school in high_school_types:\n",
      "    #print (school)\n",
      "6/15:\n",
      "# Declare s dictionary of high schools and the type of school.\n",
      "#high_school_types=[{\"High School\": \"Griffin\", \"Type\":\"District\"},\n",
      "                 # {\"High School\": \"Figueroa\", \"Type\": \"District\"},\n",
      "                  #{\"High School\": \"Wilson\", \"Type\": \"Charter\"},\n",
      "                  #{\"High School\": \"Wright\", \"Type\": \"Carter\"}]\n",
      "# Iterate through list and print out each high school name and their types.\n",
      "#for school in high_school_types:\n",
      "    #print (school)\n",
      "6/16:\n",
      "# Declare a list of high schools.\n",
      "high_school_list= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "6/17:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      "6/18:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      "6/19:\n",
      "# Declare a list of high schools.\n",
      "high_schools= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "6/20:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      "6/21:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      "6/22:\n",
      "# Iterate through school series and print each high school.\n",
      "for school in school_series:\n",
      "    print(school)\n",
      "6/23:\n",
      "# Declare a list of high schools.\n",
      "#high_schools= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "6/24:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "#school_series=pd.Series(high_schools)\n",
      "#school_series\n",
      "6/25:\n",
      "# Iterate through school series and print each high school.\n",
      "#for school in school_series:\n",
      "    #print(school)\n",
      "6/26:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  {\"School ID\": 1, \"school_name\": \"Figeroa High School\", \"type\": \"District\"},\n",
      "                  {\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  {\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  {\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "6/27:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "school_df=pd.DataFrame(high_school_dicts)\n",
      "high_school_dicts\n",
      "6/28:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "school_df=pd.DataFrame(high_school_dicts)\n",
      "school_df\n",
      "6/29:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  {\"School ID\": 1, \"school_name\": \"Figueroa High School\", \"type\": \"District\"},\n",
      "                  {\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  {\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  {\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "6/30:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "school_df=pd.DataFrame(high_school_dicts)\n",
      "school_df\n",
      "6/31:\n",
      "# Iterate through school series and print each high school.\n",
      "#for school in school_series:\n",
      "    #print(school)\n",
      "6/32:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "#high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 1, \"school_name\": \"Figueroa High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  #{\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "6/33:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "#school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "6/34:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"Distrit\", \"Charter\"]\n",
      "6/35:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      "6/36:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "6/37:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "school_df\n",
      "6/38:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "#school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "6/39:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"Distrit\", \"Charter\"]\n",
      "6/40:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      "6/41:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "school_df\n",
      "6/42:\n",
      "# Declare a list of high schools.\n",
      "#high_schools=[\"Hernandez High School\", \"Figueroa High School\", \"Wilson High School\", \"Wright High School\"]\n",
      "# Iterate through list and print out each high school name.\n",
      "#for school in high_schools:\n",
      "    #print(school)\n",
      "6/43:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "#high_school_types=[{\"High School\": \"Griffin\", \"Type\":\"District\"},\n",
      "                 # {\"High School\": \"Figueroa\", \"Type\": \"District\"},\n",
      "                  #{\"High School\": \"Wilson\", \"Type\": \"Charter\"},\n",
      "                  #{\"High School\": \"Wright\", \"Type\": \"Carter\"}]\n",
      "# Iterate through list and print out each high school name and their types.\n",
      "#for school in high_school_types:\n",
      "    #print (school)\n",
      "6/44:\n",
      "# Declare a list of high schools.\n",
      "#high_schools= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "6/45:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      "6/46:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "#school_series=pd.Series(high_schools)\n",
      "#school_series\n",
      "6/47:\n",
      "# Iterate through school series and print each high school.\n",
      "#for school in school_series:\n",
      "    #print(school)\n",
      "6/48:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "#high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 1, \"school_name\": \"Figueroa High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  #{\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "6/49:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "#school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "6/50:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"Distrit\", \"Charter\"]\n",
      "6/51:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      "6/52:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "school_df\n",
      " 7/1:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "school_df\n",
      " 7/2:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"Distrit\", \"Charter\"]\n",
      " 7/3:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      " 7/4:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      " 7/5:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"Distrit\", \"Charter\"]\n",
      " 7/6:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      " 7/7:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "school_df\n",
      " 7/8:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      " 7/9:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "school_df\n",
      "7/10:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"Distrit\", \"Charter\"]\n",
      "7/11:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      "7/12:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "school_df[\"School Name\"]=school_name\n",
      "school_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "school_df\n",
      "7/13:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "schools_df\n",
      "7/14:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"District\", \"Charter\"]\n",
      "7/15:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "schools_df\n",
      "7/16:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "#school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "7/17:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "#school_id=[0, 1, 2, 3, 4]\n",
      "#school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\"]\n",
      "#type_of_school=[\"District\", \"District\", \"Charter\", \"District\", \"Charter\"]\n",
      "7/18:\n",
      "# Initialize a new DataFrame.\n",
      "#schools_df=pd.DataFrame()\n",
      "7/19:\n",
      "# Add the Series to schools_df.\n",
      "#schools_df[\"school ID\"]=school_id\n",
      "#schools_df[\"School Name\"]=school_name\n",
      "#schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "#schools_df\n",
      "7/20:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame(high_schools_dict)\n",
      "schools_dict_df\n",
      "7/21: schools_df.columns\n",
      "7/22: schools_df.index\n",
      "7/23: schools_df.value\n",
      "7/24: schools_df.values\n",
      "7/25:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "#school_id=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "#school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Wilson High School\" \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Wright High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "#type_of_school=[\"District\", \"District\", \"Charter\", \"District\", \"Charter\", \"Charter\", \"Charter\", \"Distcrict\", \"Charter\", \"charter\", \"Charter\", \"District\", \"District\", \"District\", \"Charter\"]\n",
      "7/26:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame(high_schools_dict)\n",
      "schools_dict_df\n",
      "7/27:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Wilson High School\" \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Wright High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"District\", \"Charter\", \"Charter\", \"Charter\", \"Distcrict\", \"Charter\", \"charter\", \"Charter\", \"District\", \"District\", \"District\", \"Charter\"]\n",
      "7/28:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame(high_schools_dict)\n",
      "schools_dict_df\n",
      "7/29:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      "7/30:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "#schools_df\n",
      "7/31:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "7/32:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 1, \"school_name\": \"Figueroa High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  #{\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "7/33:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      "7/34:\n",
      "# Declare a list of high schools.\n",
      "high_schools= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "7/35:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      "7/36:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      "7/37:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 1, \"school_name\": \"Figueroa High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  #{\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "7/38:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "#high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 1, \"school_name\": \"Figueroa High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  #{\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "7/39:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "7/40:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "#school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "7/41:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "#schools_df\n",
      "7/42:\n",
      "# Declare a list of high schools.\n",
      "#high_schools= [\"Huang High School\", \"Figeroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "7/43:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      "7/44:\n",
      "# Assign a variable and create a Pandas Series form list of high schools.\n",
      "school_series=pd.Series(high_schools)\n",
      "school_series\n",
      "7/45:\n",
      "# Iterate through school series and print each high school.\n",
      "#for school in school_series:\n",
      "    #print(school)\n",
      "7/46:\n",
      "# Declare a dictionary of high schools and the type of school.\n",
      "#high_school_dicts=[{\"School ID\": 0, \"school_name\": \"Huang High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 1, \"school_name\": \"Figueroa High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 2, \"school_name\": \"Shelton High School\", \"type\": \"Charter\"},\n",
      "                  #{\"School ID\": 3, \"school_name\": \"Hernandez High School\", \"type\": \"District\"},\n",
      "                  #{\"School ID\": 4, \"school_name\": \"Griffin High School\", \"type\": \"Charter\"}]\n",
      "7/47:\n",
      "# Assign a variable and create a Pandas DataFrame from high_school_dicts.\n",
      "#school_df=pd.DataFrame(high_school_dicts)\n",
      "#school_df\n",
      "7/48:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Wilson High School\" \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Wright High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"District\", \"Charter\", \"Charter\", \"Charter\", \"Distcrict\", \"Charter\", \"charter\", \"Charter\", \"District\", \"District\", \"District\", \"Charter\"]\n",
      "7/49:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      "7/50:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "#schools_df\n",
      "7/51:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School_Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "#schools_df\n",
      "7/52:\n",
      "# Converting a Series to a DataFrame.\n",
      "# Declare three seperate lists/Series of information on high schools.\n",
      "school_id=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "school_name=[\"Huang High School\", \"Figueroa High School\", \"Shelton High School\", \"Hernandez High School\", \"Griffin High School\", \"Wilson High School\", \"Cabrera High School\", \"Bailey High School\", \"Holden High School\", \"Pena High School\", \"Wright High School\", \"Rodriguuez High School\", \"Johnson High School\", \"Ford High School\", \"Thomas High School\"]\n",
      "type_of_school=[\"District\", \"District\", \"Charter\", \"District\", \"Charter\", \"Charter\", \"Charter\", \"Distcrict\", \"Charter\", \"charter\", \"Charter\", \"District\", \"District\", \"District\", \"Charter\"]\n",
      "7/53:\n",
      "# Initialize a new DataFrame.\n",
      "schools_df=pd.DataFrame()\n",
      "7/54:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "#schools_df\n",
      "7/55:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "schools_df\n",
      "7/56:\n",
      "# Add the Series to schools_df.\n",
      "schools_df[\"school ID\"]=school_id\n",
      "schools_df[\"School Name\"]=school_name\n",
      "schools_df[\"Type\"]=type_of_school\n",
      "# Print the DataFrame.\n",
      "#schools_df\n",
      "7/57:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame(high_school_dict)\n",
      "schools_dict_df\n",
      "7/58:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame(high_school_dicts)\n",
      "schools_dict_df\n",
      "7/59:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame(high_school_dicts)\n",
      "schools_dict_df\n",
      "7/60:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame()\n",
      "schools_dict_df\n",
      "7/61:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame()\n",
      "# Add DataFrame to schools_dict_df\n",
      "#school_dict_df=\n",
      "schools_dict_df\n",
      "7/62:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame()\n",
      "# Add DataFrame to schools_dict_df\n",
      "schools_dict_df=pd.DataFrame(high_schools_dict)\n",
      "schools_dict_df\n",
      "7/63:\n",
      "# Aletrnative metod.\n",
      "# Declare a dictionary of information on high schools.\n",
      "high_schools_dict={'School ID':school_id, 'School Name':school_name, 'Type':type_of_school}\n",
      "# Initialize new DataFrame.\n",
      "schools_dict_df=pd.DataFrame()\n",
      "# Add dictionary to schools_dict_df\n",
      "schools_dict_df=pd.DataFrame(high_schools_dict)\n",
      "schools_dict_df\n",
      "7/64: schools_df.columns\n",
      "7/65: schools_df.index\n",
      "7/66: schools_df.values\n",
      " 9/1:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      " 9/2:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      " 9/3:\n",
      "# Declare variables for files to load.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load+os.path.join(\"Resources\", \"students_complete.csv\")\n",
      " 9/4:\n",
      "# Declare variables for files to load.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      " 9/5:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df\n",
      " 9/6:\n",
      "# Declare variables for files to load via path.\n",
      "#school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "#student_data_to_load = \"Resources/students_complete.csv\"\n",
      " 9/7:\n",
      "# Declare variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      " 9/8:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df\n",
      "10/1:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.coumt()\n",
      "10/2:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.count()\n",
      "10/3:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "10/4:\n",
      "# Declare variables for files to load via path.\n",
      "#school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "#student_data_to_load = \"Resources/students_complete.csv\"\n",
      "10/5:\n",
      "# Declare variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "10/6:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df\n",
      "10/7:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df\n",
      "10/8:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.count()\n",
      "10/9:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.count()\n",
      "10/10:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.insull()\n",
      "10/11:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.isnull()\n",
      "10/12:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.isnull()\n",
      "10/13:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.isnull().sum()\n",
      "10/14:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.notnull().sum()\n",
      "11/1:\n",
      "# Import Pandas dependency.\n",
      "import pandas as pd\n",
      "11/2:\n",
      "# Import os for indirect path.\n",
      "import os\n",
      "11/3:\n",
      "# Declare variable for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"missing_grades.csv\")\n",
      "11/4:\n",
      "# Read and store CSV in a Pandas DataFrame.\n",
      "missing_grades_df=pd.read_csv(file_to_load)\n",
      "missing_grades_df\n",
      "11/5:\n",
      "# Assign variable for file to load via indirect path.\n",
      "file_to_load=os.path.join(\"Resources\", \"missing_grades.csv\")\n",
      "11/6:\n",
      "# Read and store CSV in a Pandas DataFrame.\n",
      "missing_grades_df=pd.read_csv(file_to_load)\n",
      "missing_grades_df\n",
      "11/7:\n",
      "# Fill in empty rows with 85.\n",
      "missing_grades_df.fillna(85)\n",
      "10/15:\n",
      "# Determine data types for the school DataFrame.\n",
      "school_data_dt.dtypes\n",
      "10/16:\n",
      "# Determine data types for the school DataFrame.\n",
      "school_data_df.dtypes\n",
      "10/17:\n",
      "# Determine data types for the student DataFrame.\n",
      "student_data_df.dtypes\n",
      "12/1:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "12/2:\n",
      "# Assign variable for file to load via indirect path.\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df\n",
      "12/3:\n",
      "# Assign variable for file to load via indirect path.\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.(head)\n",
      "12/4:\n",
      "# Assign variable for file to load via indirect path.\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "12/5:\n",
      "# Place student names in seperate file and print.\n",
      "student_names=student_data_df[\"student_name\"].tolist()\n",
      "student_names\n",
      "12/6:\n",
      "# Iterate through student_names, split each name, print name and lenght thereof.\n",
      "for name in student_names:\n",
      "    print(name.split(), len(name.split()))\n",
      "12/7:\n",
      "# Declare new list for if statement.\n",
      "students_to_fix=[]\n",
      "# Iterate through all names in student_names.\n",
      "for name in in student_names:\n",
      "    # If name split is greater than or equal to 3...\n",
      "    if len(name.split())>=3:\n",
      "        # Add name to students_to_fix.\n",
      "        students_to_fix.append(name)\n",
      "# How many students' names are greater than or eaqual to 3?\n",
      "len(students_to_fix)\n",
      "12/8:\n",
      "# Declare new list for if statement.\n",
      "students_to_fix=[]\n",
      "# Iterate through all names in student_names.\n",
      "for name in student_names:\n",
      "    # If name split is greater than or equal to 3...\n",
      "    if len(name.split())>=3:\n",
      "        # Add name to students_to_fix.\n",
      "        students_to_fix.append(name)\n",
      "# How many students' names are greater than or eaqual to 3?\n",
      "len(students_to_fix)\n",
      "12/9:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If name is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4\n",
      "    # Add the first item to prefixes.\n",
      "    prefixes.append(name.split(0))\n",
      "print((prefixes), len(prefixes))\n",
      "12/10:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If name is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "    # Add the first item to prefixes.\n",
      "    prefixes.append(name.split(0))\n",
      "print((prefixes), len(prefixes))\n",
      "12/11:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If name is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "    # Add the first item to prefixes.\n",
      "    prefixes.append(name.split()[0])\n",
      "print((prefixes), len(prefixes))\n",
      "12/12:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If name is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "print((prefixes), len(prefixes))\n",
      "12/13:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If name is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "print((prefixes)\n",
      "12/14:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If name is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "print(prefixes)\n",
      "12/15:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If name is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "#print(prefixes)\n",
      "12/16:\n",
      "# Add the suffixes less than or equal to  to a new list.\n",
      "# Declare new list.\n",
      "suffixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If last item on list is less than or equal to 3...\n",
      "    if len(name.split()[-1])<=3:\n",
      "        # Add the first item to suffixes.\n",
      "        suffixes.append(name.split()[0])\n",
      "print(suffixes)\n",
      "12/17:\n",
      "# Add the suffixes less than or equal to  to a new list.\n",
      "# Declare new list.\n",
      "suffixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If last item on list is less than or equal to 3...\n",
      "    if len(name.split()[-1])<=3:\n",
      "        # Add the first item to suffixes.\n",
      "        suffixes.append(name.split()[-1])\n",
      "print(suffixes)\n",
      "12/18:\n",
      "# Add the suffixes less than or equal to  to a new list.\n",
      "# Declare new list.\n",
      "suffixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If last item on list is less than or equal to 3...\n",
      "    if len(name.split()[-1])<=3:\n",
      "        # Add the first item to suffixes.\n",
      "        suffixes.append(name.split()[-1])\n",
      "#print(suffixes)\n",
      "12/19:\n",
      "# Get unique items in prefixes list.\n",
      "set(prefixes)\n",
      "12/20:\n",
      "# Get unique items in suffixes list.\n",
      "set(suffixes)\n",
      "12/21:\n",
      "# Remove/Strip Mrs. from students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    print(name.strip(\"Mrs.\"))\n",
      "12/22:\n",
      "# Remove/Strip Mrs. from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.strip(\"Mrs.\"))\n",
      "12/23:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    print(name.replace(Dr, \"\"))\n",
      "12/24:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    print(name.replace(\"Dr\", \"\"))\n",
      "12/25:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    print(name.replace(\"Dr.\", \"\"))\n",
      "12/26:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.replace(\"Dr.\", \"\"))\n",
      "14/1:\n",
      "# Get unique items in suffixes list.\n",
      "#set(suffixes)\n",
      "14/2:\n",
      "# Get unique items in prefixes list.\n",
      "#set(prefixes)\n",
      "14/3:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for name in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "14/4:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for name in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_names\"]=student_data_df[\"student_names\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "14/5:\n",
      "# Assign variable for file to load via indirect path.\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "14/6:\n",
      "# Place student names in seperate file and print.\n",
      "student_names=student_data_df[\"student_name\"].tolist()\n",
      "student_names\n",
      "14/7:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv file via inderect path.\n",
      "import os\n",
      "14/8:\n",
      "# Assign variable for file to load via indirect path.\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "14/9:\n",
      "# Place student names in seperate file and print.\n",
      "student_names=student_data_df[\"student_name\"].tolist()\n",
      "student_names\n",
      "14/10:\n",
      "# Iterate through student_names, split each name, print name and lenght thereof.\n",
      "for name in student_names:\n",
      "    print(name.split(), len(name.split()))\n",
      "14/11:\n",
      "# Declare new list for if statement.\n",
      "students_to_fix=[]\n",
      "# Iterate through all names in student_names.\n",
      "for name in student_names:\n",
      "    # If name split is greater than or equal to 3...\n",
      "    if len(name.split())>=3:\n",
      "        # Add name to students_to_fix.\n",
      "        students_to_fix.append(name)\n",
      "# How many students' names are greater than or eaqual to 3?\n",
      "len(students_to_fix)\n",
      "14/12:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If first item on list is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "#print(prefixes)\n",
      "14/13:\n",
      "# Add the suffixes less than or equal to  to a new list.\n",
      "# Declare new list.\n",
      "suffixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If last item on list is less than or equal to 3...\n",
      "    if len(name.split()[-1])<=3:\n",
      "        # Add the first item to suffixes.\n",
      "        suffixes.append(name.split()[-1])\n",
      "#print(suffixes)\n",
      "14/14:\n",
      "# Get unique items in prefixes list.\n",
      "#set(prefixes)\n",
      "14/15:\n",
      "# Get unique items in suffixes list.\n",
      "#set(suffixes)\n",
      "14/16:\n",
      "# Remove/Strip Mrs. from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.strip(\"Mrs.\"))\n",
      "14/17:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.replace(\"Dr.\", \"\"))\n",
      "14/18:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for name in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_names\"]=student_data_df[\"student_names\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "14/19:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_names\"]=student_data_df[\"student_names\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "14/20:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_names\"]=student_data_df[\"student_names\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "14/21:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "14/22:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv file via inderect path.\n",
      "import os\n",
      "14/23:\n",
      "# Assign variable for file to load via indirect path.\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "14/24:\n",
      "# Place student names in seperate file and print.\n",
      "student_name=student_data_df[\"student_name\"].tolist()\n",
      "student_name\n",
      "14/25:\n",
      "# Iterate through student_names, split each name, print name and lenght thereof.\n",
      "for name in student_name:\n",
      "    print(name.split(), len(name.split()))\n",
      "14/26:\n",
      "# Declare new list for if statement.\n",
      "students_to_fix=[]\n",
      "# Iterate through all names in student_names.\n",
      "for name in student_name:\n",
      "    # If name split is greater than or equal to 3...\n",
      "    if len(name.split())>=3:\n",
      "        # Add name to students_to_fix.\n",
      "        students_to_fix.append(name)\n",
      "# How many students' names are greater than or eaqual to 3?\n",
      "len(students_to_fix)\n",
      "14/27:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If first item on list is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "#print(prefixes)\n",
      "14/28:\n",
      "# Add the suffixes less than or equal to  to a new list.\n",
      "# Declare new list.\n",
      "suffixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If last item on list is less than or equal to 3...\n",
      "    if len(name.split()[-1])<=3:\n",
      "        # Add the first item to suffixes.\n",
      "        suffixes.append(name.split()[-1])\n",
      "#print(suffixes)\n",
      "14/29:\n",
      "# Get unique items in prefixes list.\n",
      "#set(prefixes)\n",
      "14/30:\n",
      "# Get unique items in suffixes list.\n",
      "#set(suffixes)\n",
      "14/31:\n",
      "# Remove/Strip Mrs. from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.strip(\"Mrs.\"))\n",
      "14/32:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.replace(\"Dr.\", \"\"))\n",
      "14/33:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "16/1:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "16/2:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv file via inderect path.\n",
      "import os\n",
      "16/3:\n",
      "# Assign variable for file to load via indirect path.\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "16/4:\n",
      "# Place student names in seperate file and print.\n",
      "student_name=student_data_df[\"student_name\"].tolist()\n",
      "student_name\n",
      "16/5:\n",
      "# Iterate through student_names, split each name, print name and lenght thereof.\n",
      "for name in student_name:\n",
      "    print(name.split(), len(name.split()))\n",
      "16/6:\n",
      "# Declare new list for if statement.\n",
      "students_to_fix=[]\n",
      "# Iterate through all names in student_names.\n",
      "for name in student_name:\n",
      "    # If name split is greater than or equal to 3...\n",
      "    if len(name.split())>=3:\n",
      "        # Add name to students_to_fix.\n",
      "        students_to_fix.append(name)\n",
      "# How many students' names are greater than or eaqual to 3?\n",
      "len(students_to_fix)\n",
      "16/7:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If first item on list is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "#print(prefixes)\n",
      "16/8:\n",
      "# Add the suffixes less than or equal to  to a new list.\n",
      "# Declare new list.\n",
      "suffixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If last item on list is less than or equal to 3...\n",
      "    if len(name.split()[-1])<=3:\n",
      "        # Add the first item to suffixes.\n",
      "        suffixes.append(name.split()[-1])\n",
      "#print(suffixes)\n",
      "16/9:\n",
      "# Get unique items in prefixes list.\n",
      "#set(prefixes)\n",
      "16/10:\n",
      "# Get unique items in suffixes list.\n",
      "#set(suffixes)\n",
      "16/11:\n",
      "# Remove/Strip Mrs. from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.strip(\"Mrs.\"))\n",
      "16/12:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.replace(\"Dr.\", \"\"))\n",
      "16/13:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "16/14:\n",
      "# Place student names in seperate file and print.\n",
      "student_names=student_data_df[\"student_name\"].tolist()\n",
      "student_names\n",
      "16/15:\n",
      "# Iterate through student_names, split each name, print name and lenght thereof.\n",
      "for name in student_name:\n",
      "    print(name.split(), len(name.split()))\n",
      "16/16:\n",
      "# Declare new list for if statement.\n",
      "students_to_fix=[]\n",
      "# Iterate through all names in student_names.\n",
      "for name in student_name:\n",
      "    # If name split is greater than or equal to 3...\n",
      "    if len(name.split())>=3:\n",
      "        # Add name to students_to_fix.\n",
      "        students_to_fix.append(name)\n",
      "# How many students' names are greater than or eaqual to 3?\n",
      "len(students_to_fix)\n",
      "16/17:\n",
      "# Add the prefixes less than or equal to 4 to a new list.\n",
      "# Declare new list.\n",
      "prefixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If first item on list is less than or equal to 4...\n",
      "    if len(name.split()[0])<=4:\n",
      "        # Add the first item to prefixes.\n",
      "        prefixes.append(name.split()[0])\n",
      "#print(prefixes)\n",
      "16/18:\n",
      "# Add the suffixes less than or equal to  to a new list.\n",
      "# Declare new list.\n",
      "suffixes=[]\n",
      "# Iterate through names in students_to_fix.\n",
      "for name in students_to_fix:\n",
      "    # If last item on list is less than or equal to 3...\n",
      "    if len(name.split()[-1])<=3:\n",
      "        # Add the first item to suffixes.\n",
      "        suffixes.append(name.split()[-1])\n",
      "#print(suffixes)\n",
      "16/19:\n",
      "# Get unique items in prefixes list.\n",
      "#set(prefixes)\n",
      "16/20:\n",
      "# Get unique items in suffixes list.\n",
      "#set(suffixes)\n",
      "16/21:\n",
      "# Remove/Strip Mrs. from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.strip(\"Mrs.\"))\n",
      "16/22:\n",
      "# Replace Dr with \"\" from students_to_fix.\n",
      "#for name in students_to_fix:\n",
      "    #print(name.replace(\"Dr.\", \"\"))\n",
      "16/23:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "16/24:\n",
      "# Confirm that all prefixes and suffixes were corrected.\n",
      "# Declare new variable for student_data_df[\"student_name\"].\n",
      "student_names = student_data_df[\"student_name\"]\n",
      "# Convert student_data_df[\"student_name\"] to a list.\n",
      "student_names = student_data_df[\"student_name\"].tolist()\n",
      "student_names\n",
      "16/25:\n",
      "# Declate new list.\n",
      "students_fixed = []\n",
      "# Iterate through student_names to check the length of each name.\n",
      "for name in student_names:\n",
      "    # If the name is greater than or equal to 3...\n",
      "    if len(name.split()) >= 3:\n",
      "        #add the name to the list.\n",
      "        students_fixed.append(name)\n",
      "# Get the length of the students' names that are greater than or equal to 3.\n",
      "len(students_fixed)\n",
      "17/1:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "17/2:\n",
      "# Assign variables for files to load via path.\n",
      "#school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "#student_data_to_load = \"Resources/students_complete.csv\"\n",
      "17/3:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "17/4:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df\n",
      "17/5:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df\n",
      "17/6:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.count()\n",
      "17/7:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.count()\n",
      "17/8:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.isnull()\n",
      "17/9:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.notnull().sum()\n",
      "17/10:\n",
      "# Determine data types for the school DataFrame.\n",
      "school_data_df.dtypes\n",
      "17/11:\n",
      "# Determine data types for the student DataFrame.\n",
      "student_data_df.dtypes\n",
      "17/12:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "17/13:\n",
      "# Merge DataFrames\n",
      "#  Assign a variable and combine student_data_df and school_data_df into a single dataset.\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "17/14:\n",
      "# Count all the items in each row for each column that is not null.\n",
      "# Assign variable for student count.\n",
      "student_count = school_data_complete_df.count()\n",
      "student_count\n",
      "17/15:\n",
      "# Assign student_count to a column that identifies with students.\n",
      "school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "17/16:\n",
      "# Assign student_count to a column that identifies with students.\n",
      "student_count=school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "17/17:\n",
      "# Count number of schools, option one.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "# Assign variable for school_count.\n",
      "school_count = school_data_df[\"school_name\"].count()\n",
      "school_count\n",
      "17/18:\n",
      "# Count number of schools, option two, .unique().\n",
      "# Assign variable for school_count_2.\n",
      "school_count_2 = school_data_complete_df[\"school_name\"].unique()\n",
      "school_count_2\n",
      "17/19:\n",
      "# Assign variable for and calculate total_budget.\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "total_budget\n",
      "17/20:\n",
      "# Assign variable for and calculate average_reading_score.\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_reading_score\n",
      "17/21:\n",
      "# Assign variable for and calculate average_math_score.\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "average_math_score\n",
      "17/22:\n",
      "# Determine Passing Grade\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "17/23:\n",
      "# Determine Passing Grade.\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "passing_math\n",
      "17/24:\n",
      "# Determine Number of Students Who Passed Math and Reading.\n",
      "# Retreive the students who are passing math in a new DataFrame.\n",
      "passing_math = school_data_complete_df[school_data_complete_df[\"math_score\"] >= 70]\n",
      "passing_math.head()\n",
      "17/25:\n",
      "# Determine Number of Students Who Passed Reading.\n",
      "# Retreive the students who are passing reading in a new DataFrame.\n",
      "passing_reading = school_data_complete_df[school_data_complete_df[\"reading_score\"] >= 70]\n",
      "passing_reading.head()\n",
      "17/26:\n",
      "# Determine the number of students who passed math and reading.\n",
      "# Calculate number of students passing math.\n",
      "passing_math_count = passing_math[\"student_name\"].count()\n",
      "# Calculate number of students passing reading.\n",
      "passing_reading_count = passing_reading[\"student_name\"].count()\n",
      "print(passing_math_count)\n",
      "print(passing_reading_count)\n",
      "17/27:\n",
      "# Convert student_count to a floating-point decimal.\n",
      "# Calculate percent that passed math.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "# Calculate percent that passed reading.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "print(passing_reading_percentage)\n",
      "16/26:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "16/27:\n",
      "# Confirm that all prefixes and suffixes were corrected.\n",
      "# Declare new variable for student_data_df[\"student_name\"].\n",
      "student_names = student_data_df[\"student_name\"]\n",
      "# Convert student_data_df[\"student_name\"] to a list.\n",
      "student_names = student_data_df[\"student_name\"].tolist()\n",
      "student_names\n",
      "16/28:\n",
      "# Declate new list.\n",
      "students_fixed = []\n",
      "# Iterate through student_names to check the length of each name.\n",
      "for name in student_names:\n",
      "    # If the name is greater than or equal to 3...\n",
      "    if len(name.split()) >= 3:\n",
      "        #add the name to the list.\n",
      "        students_fixed.append(name)\n",
      "# Get the length of the students' names that are greater than or equal to 3.\n",
      "len(students_fixed)\n",
      "17/28:\n",
      "# Calculate the Overall Passing Percentage.\n",
      "# Calculate students who passed both math and reading.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "passing_math_reading.head()\n",
      "17/29:\n",
      "# Get  total number of students who passed both math and reading.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "overall_passing_math_reading_count\n",
      "17/30:\n",
      "# Calculate percentage of students who passed both math and reading.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / student_count * 100\n",
      "overall_passing_percentage\n",
      "17/31:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count,\n",
      "          \"Total Students\": student_count,\n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score,\n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/32:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/33:\n",
      "# Format Columns.\n",
      "# Write Functions for the School District Data.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/34:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "18/1:\n",
      "# Define \"say_hello\" function.\n",
      "def say_hello():\n",
      "    # Print \"Hello!\" when called\n",
      "    print(\"Hello!\")\n",
      "# Call say_hello().\n",
      "say_hello()\n",
      "18/2:\n",
      "# Define  \"say_something\" function.\n",
      "    # Print whatever is passed as the variable when called.\n",
      "def say_something(something):\n",
      "    print(something)\n",
      "# Call say_something() to print \"Hello World\".\n",
      "say_something(\"Hello World\")\n",
      "18/3:\n",
      "# Define Jane_says().\n",
      "Jane_says = \"Hi, my name is Jane. I'm learning Python!\"\n",
      "say_something(Jane_says)\n",
      "18/4:\n",
      "# Assign list of my grades.\n",
      "my_grades = ['B', 'C', 'B' , 'D']\n",
      "18/5:\n",
      "# Assign list of my grades.\n",
      "my_grades = ['B', 'C', 'B' , 'D'\n",
      "# Import pandas.\n",
      "import pandas as pd\n",
      "# Convert the my_grades to a Series\n",
      "my_grades = pd.Series(my_grades)\n",
      "my_grades\n",
      "18/6:\n",
      "# Assign list of my grades.\n",
      "my_grades = ['B', 'C', 'B' , 'D'\n",
      "# Import pandas.\n",
      "import pandas as pd\n",
      "# Convert the my_grades to a Series\n",
      "my_grades = pd.Series(my_grades)\n",
      "my_grades\n",
      "18/7:\n",
      "# Assign list of my grades.\n",
      "my_grades = ['B', 'C', 'B' , 'D']\n",
      "# Import pandas.\n",
      "import pandas as pd\n",
      "# Convert the my_grades to a Series\n",
      "my_grades = pd.Series(my_grades)\n",
      "my_grades\n",
      "18/8:\n",
      "# Change my_grades by one letter grade using map().\n",
      "my_grades.map({'B': 'A', 'C': 'B', 'D': 'C'})\n",
      "18/9:\n",
      "# Using the format() function.\n",
      "my_grades = [92.34, 84.56, 86.78, 98.32]\n",
      "\n",
      "for grade in my_grades:\n",
      "    print(\"{:.0f}\".format(grade))\n",
      "18/10:\n",
      "# Chaining map() and format() Functions.\n",
      "# Convert numerical grades to a Series.\n",
      "my_grades = pd.Series([92.34, 84.56, 86.78, 78.32])\n",
      "my_grades\n",
      "# Format the grades to the nearest whole number percent.\n",
      "my_grades.map(\"{:.0f}\".format)\n",
      "17/35:\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/36:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "17/37:\n",
      "# Format and print\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "17/38:\n",
      "# Format and print\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "# Display district_summary_df.\n",
      "district_summary_df\n",
      "17/39:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "17/40:\n",
      "# Assign variables for files to load via path.\n",
      "#school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "#student_data_to_load = \"Resources/students_complete.csv\"\n",
      "17/41:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "17/42:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df\n",
      "17/43:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df\n",
      "17/44:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.count()\n",
      "17/45:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.count()\n",
      "17/46:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.isnull()\n",
      "17/47:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.notnull().sum()\n",
      "17/48:\n",
      "# Determine data types for the school DataFrame.\n",
      "school_data_df.dtypes\n",
      "17/49:\n",
      "# Determine data types for the student DataFrame.\n",
      "student_data_df.dtypes\n",
      "17/50:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "17/51:\n",
      "# Merge DataFrames\n",
      "# Assign a variable and combine student_data_df and school_data_df into a single dataset.\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "17/52:\n",
      "# Count all the items in each row for each column that is not null.\n",
      "# Code to use: school_data_complete_df.count()\n",
      "# Assign variable for student_count.\n",
      "student_count = school_data_complete_df.count()\n",
      "student_count\n",
      "17/53:\n",
      "# Assign student_count to a column that identifies with students.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "student_count=school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "17/54:\n",
      "# Count number of schools, option one.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "# Assign variable for school_count.\n",
      "school_count = school_data_df[\"school_name\"].count()\n",
      "school_count\n",
      "17/55:\n",
      "# Count number of schools, option two, .unique().\n",
      "# Assign variable for school_count_2.\n",
      "school_count_2 = school_data_complete_df[\"school_name\"].unique()\n",
      "school_count_2\n",
      "17/56:\n",
      "# Assign variable for and calculate total_budget.\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "total_budget\n",
      "17/57:\n",
      "# Assign variable for and calculate average_reading_score.\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_reading_score\n",
      "17/58:\n",
      "# Assign variable for and calculate average_math_score.\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "average_math_score\n",
      "17/59:\n",
      "# Determine Passing Grade.\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "passing_math\n",
      "17/60:\n",
      "# Determine Number of Students Who Passed Math.\n",
      "# Retreive the students who are passing math in a new DataFrame.\n",
      "passing_math = school_data_complete_df[school_data_complete_df[\"math_score\"] >= 70]\n",
      "passing_math.head()\n",
      "17/61:\n",
      "# Determine Number of Students Who Passed Reading.\n",
      "# Retreive the students who are passing reading in a new DataFrame.\n",
      "passing_reading = school_data_complete_df[school_data_complete_df[\"reading_score\"] >= 70]\n",
      "passing_reading.head()\n",
      "17/62:\n",
      "# Determine the number of students who passed math and reading.\n",
      "# Calculate number of students passing math.\n",
      "passing_math_count = passing_math[\"student_name\"].count()\n",
      "# Calculate number of students passing reading.\n",
      "passing_reading_count = passing_reading[\"student_name\"].count()\n",
      "print(passing_math_count)\n",
      "print(passing_reading_count)\n",
      "17/63:\n",
      "# Convert student_count to a floating-point decimal.\n",
      "# Calculate percent that passed math.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "# Calculate percent that passed reading.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "print(passing_reading_percentage)\n",
      "17/64:\n",
      "# Calculate the Overall Passing Percentage.\n",
      "# Calculate students who passed both math and reading.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "passing_math_reading.head()\n",
      "17/65:\n",
      "# Get  total number of students who passed both math and reading.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "overall_passing_math_reading_count\n",
      "17/66:\n",
      "# Calculate percentage of students who passed both math and reading.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / student_count * 100\n",
      "overall_passing_percentage\n",
      "17/67:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count,\n",
      "          \"Total Students\": student_count,\n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score,\n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/68:\n",
      "# Format Columns.\n",
      "# Write Functions for the School District Data.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/69:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/70:\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/71:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "17/72:\n",
      "# Format and print\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "# Display district_summary_df.\n",
      "district_summary_df\n",
      "17/73:\n",
      "## Reorder Columns.\n",
      "## Reorder the columns in the order you want them to appear.\n",
      "#new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "## Assign a new or the same DataFrame the new column order.\n",
      "#df = df[new_column_order]\n",
      "17/74:\n",
      "## Filter out columns that aren't needed and select columns in the the desired order.\n",
      "## Reorder columns in the desired order.\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign district summary df the new column order.\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "#district_summary_df\n",
      "17/75:\n",
      "# Indexing school_name column.\n",
      "# Index school_name column and follow by school type.\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "per_school_types\n",
      "17/76:\n",
      "# Convert per_school_types to a DataFrame for testing.\n",
      "df = pd.DataFrame(per_school_types)\n",
      "df\n",
      "17/77:\n",
      "# Calculate the total student count in the school_data_df.\n",
      "per_school_counts = school_data_df[\"size\"]\n",
      "per_school_counts\n",
      "17/78:\n",
      "# Index school_name column and calculate student count in school_data_df.\n",
      "per_school_counts = school_data_df.set_index([\"school_name\"])[\"size\"]\n",
      "per_school_counts\n",
      "17/79:\n",
      "# Calculate student count from school_data_complete_df.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "per_school_counts\n",
      "17/80:\n",
      "# Budget Per Student.\n",
      "# Calculate the total school budget from school_data_df.\n",
      "per_school_budget = school_data_df.set_index([\"school_name\"])[\"budget\"]\n",
      "per_school_budget\n",
      "17/81:\n",
      "# Calculate per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "per_school_capita\n",
      "17/82:\n",
      "# Score Averages Per School.\n",
      "# Index school_name column and calculate math scores.\n",
      "student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "17/83:\n",
      "# Score Averages Per School.\n",
      "# Index school_name column and calculate math scores.\n",
      "student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "student_school_math\n",
      "17/84:\n",
      "# Calculate average math scores using groupby() and mean().\n",
      "per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "per_school_averages\n",
      "17/85:\n",
      "# Calculate average math scores using groupby() and mean() and reference each Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/86:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/87:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "17/88:\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/89:\n",
      "# Passing Percentages Per School.\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "17/90:\n",
      "# Passing Percentages Per School.\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.(head)\n",
      "17/91:\n",
      "# Passing Percentages Per School.\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/92:\n",
      "# Calculate students passing math using groupby() and count().\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/93:\n",
      "# Calculate students passing reading using groupby() and count().\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading\n",
      "17/94:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_school_passing_reading.head()\n",
      "17/95:\n",
      "# Calculate students passing reading using groupby() and count().\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading\n",
      "17/96:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "17/97:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "17/98:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)] 70)]\n",
      "per_school_passing_reading.head()\n",
      "17/99:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_school_passing_reading.head()\n",
      "17/100:\n",
      "## Passing Percentages Per School.\n",
      "## Calculate math passing score by creating a filtered DataFrame.\n",
      "#per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "#per_school_passing_math.head()\n",
      "17/101:\n",
      "## Calculate reading passing score by creating a filtered DataFrame.\n",
      "#per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/102:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/103:\n",
      "# Passing Percentages Per School.\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "#per_school_passing_math.head()\n",
      "17/104:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/105:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/106:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading\n",
      "17/107:\n",
      "# To get the overall passing percentage, divide students who passed both math and reading by the total number of students.\n",
      "# Calculate overall math and reading passing percentage.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_passing_math_reading.head()\n",
      "17/108:\n",
      "# Place total number of students who passed  math and reading in per_passing_math_reading DataFrame.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "17/109:\n",
      "# Calculate percentage of students who passed math and reading by dividing them by the total number of students and multiplying by 100.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "per_overall_passing_percentage\n",
      "17/110:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "             \"School Type\": per_school_types,\n",
      "             \"Total Students\": per_school_counts,\n",
      "             \"Total School Budget\": per_school_budget,\n",
      "             \"Per Student Budget\": per_school_capita,\n",
      "             \"Average Math Score\": per_school_math,\n",
      "           \"Average Reading Score\": per_school_reading,\n",
      "           \"% Passing Math\": per_school_passing_math,\n",
      "           \"% Passing Reading\": per_school_passing_reading,\n",
      "           \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df.head()\n",
      "17/111:\n",
      "# Format Total School Budget column.\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format Student School Budget column.\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df.head()\n",
      "17/112:\n",
      "# Find Highest Performing Schools.\n",
      "# Assign, sort, and print top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "17/113:\n",
      "# Assign, sort, and print top five worse performing schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "17/114:\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive class' grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "school_data_complete_df[\"grade\"]\n",
      "17/115:\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive class' grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "school_data_complete_df\n",
      "17/116:\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive class' grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "#school_data_complete_df\n",
      "17/117:\n",
      "# Score Averages Grouped by School Name.\n",
      "## Assign variables, groupby() school_name column, and retreive each grade levels' average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores\n",
      "17/118:\n",
      "# Score Averages Grouped by School Name.\n",
      "## Assign variables, groupby() school_name column, and retreive each grade levels' average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "17/119:\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive grade levels' grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "ninth_graders\n",
      "17/120:\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive grade levels' grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "17/121:\n",
      "## Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "ninth_grade_reading_scores\n",
      "17/122:\n",
      "## Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "17/123:\n",
      "## Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "ninth_grade_reading_scores\n",
      "17/124:\n",
      "## Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores\n",
      "17/125:\n",
      "## Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "17/126:\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Create a DataFrame for the average scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade.head()\n",
      "17/127:\n",
      "# Create a DataFrame for the average reading scores by grade level for each school.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "reading_scores_by_grade.head()\n",
      "17/128:\n",
      "# Format Averages and Remove Index Name.\n",
      "# Format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "# Place columns are in correct order.\n",
      "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove index name.\n",
      "math_scores_by_grade.index.name = None\n",
      "math_scores_by_grade.head()\n",
      "17/129:\n",
      "# Format Averages and Remove Index Name.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "# Place columns are in correct order.\n",
      "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove index name.\n",
      "math_scores_by_grade.index.name = None\n",
      "math_scores_by_grade.head()\n",
      "17/130:\n",
      "# Create a DataFrame for the average reading scores by grade level for each school.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "reading_scores_by_grade.head()\n",
      "17/131:\n",
      "# Format Averages and Remove Index Name.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "# Place columns are in correct order.\n",
      "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove index name.\n",
      "math_scores_by_grade.index.name = None\n",
      "math_scores_by_grade.head()\n",
      "17/132:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "17/133:\n",
      "# Assign variables for files to load via path.\n",
      "#school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "#student_data_to_load = \"Resources/students_complete.csv\"\n",
      "17/134:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "17/135:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df\n",
      "17/136:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df\n",
      "17/137:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.count()\n",
      "17/138:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.count()\n",
      "17/139:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.isnull()\n",
      "17/140:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.notnull().sum()\n",
      "17/141:\n",
      "# Determine data types for the school DataFrame.\n",
      "school_data_df.dtypes\n",
      "17/142:\n",
      "# Determine data types for the student DataFrame.\n",
      "student_data_df.dtypes\n",
      "17/143:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "print(student_data_df)\n",
      "17/144:\n",
      "# Merge DataFrames\n",
      "# Assign a variable and combine student_data_df and school_data_df into a single dataset.\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "17/145:\n",
      "# Count all the items in each row for each column that is not null.\n",
      "# Code to use: school_data_complete_df.count()\n",
      "# Assign variable for student_count.\n",
      "student_count = school_data_complete_df.count()\n",
      "student_count\n",
      "17/146:\n",
      "# Assign student_count to a column that identifies with students.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "student_count=school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "17/147:\n",
      "# Count number of schools, option one.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "# Assign variable for school_count.\n",
      "school_count = school_data_df[\"school_name\"].count()\n",
      "school_count\n",
      "17/148:\n",
      "# Count number of schools, option two, .unique().\n",
      "# Assign variable for school_count_2.\n",
      "school_count_2 = school_data_complete_df[\"school_name\"].unique()\n",
      "school_count_2\n",
      "17/149:\n",
      "# Assign variable for and calculate total_budget.\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "total_budget\n",
      "17/150:\n",
      "# Assign variable for and calculate average_reading_score.\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_reading_score\n",
      "17/151:\n",
      "# Assign variable for and calculate average_math_score.\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "average_math_score\n",
      "17/152:\n",
      "# Determine Passing Grade.\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "passing_math\n",
      "17/153:\n",
      "# Determine Number of Students Who Passed Math.\n",
      "# Retreive the students who are passing math in a new DataFrame.\n",
      "passing_math = school_data_complete_df[school_data_complete_df[\"math_score\"] >= 70]\n",
      "passing_math.head()\n",
      "17/154:\n",
      "# Determine Number of Students Who Passed Reading.\n",
      "# Retreive the students who are passing reading in a new DataFrame.\n",
      "passing_reading = school_data_complete_df[school_data_complete_df[\"reading_score\"] >= 70]\n",
      "passing_reading.head()\n",
      "17/155:\n",
      "# Determine the number of students who passed math and reading.\n",
      "# Calculate number of students passing math.\n",
      "passing_math_count = passing_math[\"student_name\"].count()\n",
      "# Calculate number of students passing reading.\n",
      "passing_reading_count = passing_reading[\"student_name\"].count()\n",
      "print(passing_math_count)\n",
      "print(passing_reading_count)\n",
      "17/156:\n",
      "# Convert student_count to a floating-point decimal.\n",
      "# Calculate percent that passed math.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "# Calculate percent that passed reading.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "print(passing_reading_percentage)\n",
      "17/157:\n",
      "# Calculate the Overall Passing Percentage.\n",
      "# Calculate students who passed both math and reading.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "passing_math_reading.head()\n",
      "17/158:\n",
      "# Get  total number of students who passed both math and reading.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "overall_passing_math_reading_count\n",
      "17/159:\n",
      "# Calculate percentage of students who passed both math and reading.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / student_count * 100\n",
      "overall_passing_percentage\n",
      "17/160:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count,\n",
      "          \"Total Students\": student_count,\n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score,\n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/161:\n",
      "# Format Columns.\n",
      "# Write Functions for the School District Data.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/162:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/163:\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/164:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "17/165:\n",
      "# Format and print\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "# Display district_summary_df.\n",
      "district_summary_df\n",
      "17/166:\n",
      "## Reorder Columns.\n",
      "## Reorder columns in the order you want them to appear.\n",
      "#new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "## Assign a new or the same DataFrame the new column order.\n",
      "#df = df[new_column_order]\n",
      "17/167:\n",
      "## Filter out columns that aren't needed and select columns in the the desired order.\n",
      "## Reorder columns in the desired order.\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign district summary df the new column order.\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "#district_summary_df\n",
      "17/168:\n",
      "# Indexing school_name column.\n",
      "# Index school_name column and follow by school type.\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "per_school_types\n",
      "17/169:\n",
      "# Convert per_school_types to a DataFrame.\n",
      "df = pd.DataFrame(per_school_types)\n",
      "df\n",
      "17/170:\n",
      "# Calculate student count in school_data_df.\n",
      "per_school_counts = school_data_df[\"size\"]\n",
      "per_school_counts\n",
      "17/171:\n",
      "# Index school_name column and calculate student count in school_data_df.\n",
      "per_school_counts = school_data_df.set_index([\"school_name\"])[\"size\"]\n",
      "per_school_counts\n",
      "17/172:\n",
      "# Index school_name column and calculate student count from school_data_complete_df.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "per_school_counts\n",
      "17/173:\n",
      "# Budget Per Student.\n",
      "# Index school_name column and calculate the total school budget from school_data_df.\n",
      "per_school_budget = school_data_df.set_index([\"school_name\"])[\"budget\"]\n",
      "per_school_budget\n",
      "17/174:\n",
      "# Calculate per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "per_school_capita\n",
      "17/175:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "17/176:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "17/177:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "17/178:\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/179:\n",
      "# Passing Percentages Per School.\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "#per_school_passing_math.head()\n",
      "17/180:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/181:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/182:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading\n",
      "17/183:\n",
      "# To get the overall passing percentage, divide students who passed both math and reading by the total number of students.\n",
      "# Calculate overall math and reading passing percentage.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_passing_math_reading.head()\n",
      "17/184:\n",
      "# Place total number of students who passed  math and reading in per_passing_math_reading DataFrame.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "17/185:\n",
      "# Calculate percentage of students who passed math and reading by dividing them by the total number of students and multiplying by 100.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "per_overall_passing_percentage\n",
      "17/186:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "             \"School Type\": per_school_types,\n",
      "             \"Total Students\": per_school_counts,\n",
      "             \"Total School Budget\": per_school_budget,\n",
      "             \"Per Student Budget\": per_school_capita,\n",
      "             \"Average Math Score\": per_school_math,\n",
      "           \"Average Reading Score\": per_school_reading,\n",
      "           \"% Passing Math\": per_school_passing_math,\n",
      "           \"% Passing Reading\": per_school_passing_reading,\n",
      "           \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df.head()\n",
      "17/187:\n",
      "# Format Total School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format Student School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df.head()\n",
      "17/188:\n",
      "## IF NEEDED... Reorder columns desired in order.\n",
      "#new_column_order = [\"School Type\", \"Total Students\", \"Total School Budget\", \"Per Student Budget\", \"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign district summary df the new column order.\n",
      "#per_school_summary_df = per_school_summary_df[new_column_order]\n",
      "#per_school_summary_df.head()\n",
      "17/189:\n",
      "# Find Highest Performing Schools.\n",
      "# Assign, sort, and print top five best performing schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "17/190:\n",
      "# Assign, sort, and print top five worse performing schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "17/191:\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive each grade level student's grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "17/192:\n",
      "# Score Averages Grouped by School Name.\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "17/193:\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "17/194:\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Create a DataFrame for the average math scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade.head()\n",
      "17/195:\n",
      "# Create a DataFrame for the average reading scores by grade level for each school.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "reading_scores_by_grade.head()\n",
      "17/196:\n",
      "# Format Averages and Remove Index Name.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "# Place columns are in correct order.\n",
      "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove index name.\n",
      "math_scores_by_grade.index.name = None\n",
      "math_scores_by_grade.head()\n",
      "17/197:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Place columns in correct order.\n",
      "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove  index name.\n",
      "reading_scores_by_grade.index.name = None\n",
      "reading_scores_by_grade.head()\n",
      "17/198:\n",
      "# School spending per student's affect average scores and passing percentages.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "17/199:\n",
      "# Group Series by Spending Ranges.\n",
      "# Assign variable for ranges.\n",
      "spending_bins = [0, 585, 615, 645, 675]\n",
      "# Cut DataFrame into ranges.\n",
      "pd.cut(per_school_capita, spending_bins)\n",
      "17/200:\n",
      "## Group Series by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 615, 645, 675]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "17/201:\n",
      "## Group Series by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 615, 645, 675]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "17/202:\n",
      "## Group Series by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "17/203:\n",
      "## Group Series by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "17/204:\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df\n",
      "17/205:\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "17/206:\n",
      "# Group by Spending Ranges.\n",
      "# Create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "17/207:\n",
      "# Group by Spending Ranges.\n",
      "# Create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "17/208:\n",
      "# Group by Spending Ranges.\n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "#overall_passing_spending\n",
      "17/209:\n",
      "# Create a DataFrame for Scores by School Spending.\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "17/210:\n",
      "# Format\n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "17/211:\n",
      "# Group by Spending Ranges.\n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "17/212:\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "17/213:\n",
      "# Passing Percentages Per School.\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/214:\n",
      "# Passing Percentages Per School.\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "#per_school_passing_math.head()\n",
      "17/215:\n",
      "# Passing Percentages Per School.\n",
      "# Assign passing_math variable to determine passing score parameters.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "#per_school_passing_math.head()\n",
      "17/216:\n",
      "# Assign passing_reading variable to determine passing score parameters.\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/217:\n",
      "# Add students who passed math: passing_math to school_data_complete_df as math_score column.\n",
      "passing_math = school_data_complete_df[school_data_complete_df[\"math_score\"] >= 70]\n",
      "passing_math.head()\n",
      "17/218:\n",
      "# Add students who passed reading: passing_reading to school_data_complete_df as reading_score column.\n",
      "passing_reading = school_data_complete_df[school_data_complete_df[\"reading_score\"] >= 70]\n",
      "17/219:\n",
      "# Assign variable, calulate number of students who passed math, print.\n",
      "passing_math_count = passing_math[\"student_name\"].count()\n",
      "print(passing_math_count)\n",
      "# Assign variable, calulate number of students who passed reading, print.\n",
      "passing_reading_count = passing_reading[\"student_name\"].count()\n",
      "print(passing_reading_count)\n",
      "17/220:\n",
      "# Get Percentage of Students Who Passed Math and Reading.\n",
      "# Divide passing_math_count by student_count, and multiply by 100, print.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "# Divide passing_reading_count by student_count, and multiply by 100, print.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_reading_percentage)\n",
      "17/221:\n",
      "# Calculate Overall Passing Percentage.\n",
      "# Assign variable: passing_math_reading, add/gather students who passed both math and reading from school_data_complete_df.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "17/222:\n",
      "# Calculate Overall Passing Percentage.\n",
      "# Assign variable: passing_math_reading, add/gather students who passed both math and reading from school_data_complete_df.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "passing_math_reading.head()\n",
      "17/223:\n",
      "# Assign variable and get number of students who passed  math and reading.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "overall_passing_math_reading_count\n",
      "17/224:\n",
      "# Assign Variable, calculate overall percentage of students who passed math and reading by dividing  total number of students: overall_passing_math_reading_count by student_count and multiplying by 100.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / student_count * 100\n",
      "overall_passing_percentage\n",
      "17/225:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/226:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading\n",
      "17/227:\n",
      "# To get the overall passing percentage, divide students who passed both math and reading by the total number of students.\n",
      "# Calculate overall math and reading passing percentage.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_passing_math_reading.head()\n",
      "17/228:\n",
      "# Place total number of students who passed  math and reading in per_passing_math_reading DataFrame.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "17/229:\n",
      "# Calculate percentage of students who passed math and reading by dividing them by the total number of students and multiplying by 100.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "per_overall_passing_percentage\n",
      "17/230:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "             \"School Type\": per_school_types,\n",
      "             \"Total Students\": per_school_counts,\n",
      "             \"Total School Budget\": per_school_budget,\n",
      "             \"Per Student Budget\": per_school_capita,\n",
      "             \"Average Math Score\": per_school_math,\n",
      "           \"Average Reading Score\": per_school_reading,\n",
      "           \"% Passing Math\": per_school_passing_math,\n",
      "           \"% Passing Reading\": per_school_passing_reading,\n",
      "           \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df.head()\n",
      "17/231:\n",
      "# Format Total School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format Student School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df.head()\n",
      "17/232:\n",
      "## IF NEEDED... Reorder columns desired in order.\n",
      "#new_column_order = [\"School Type\", \"Total Students\", \"Total School Budget\", \"Per Student Budget\", \"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign district summary df the new column order.\n",
      "#per_school_summary_df = per_school_summary_df[new_column_order]\n",
      "#per_school_summary_df.head()\n",
      "17/233:\n",
      "# Find Highest Performing Schools.\n",
      "# Assign, sort, and print top five best performing schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "17/234:\n",
      "# Assign, sort, and print top five worse performing schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "17/235:\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive each grade level student's grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "17/236:\n",
      "# Score Averages Grouped by School Name.\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "17/237:\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "17/238:\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Create a DataFrame for the average math scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade.head()\n",
      "17/239:\n",
      "# Create a DataFrame for the average reading scores by grade level for each school.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "reading_scores_by_grade.head()\n",
      "17/240:\n",
      "# Format Averages and Remove Index Name.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "# Place columns in correct order.\n",
      "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove index name.\n",
      "math_scores_by_grade.index.name = None\n",
      "math_scores_by_grade.head()\n",
      "17/241:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Place columns in correct order.\n",
      "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove  index name.\n",
      "reading_scores_by_grade.index.name = None\n",
      "reading_scores_by_grade.head()\n",
      "17/242:\n",
      "# School spending per student's affect average scores and passing percentages.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "17/243:\n",
      "## Group Series by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "17/244:\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "17/245:\n",
      "# Group by Spending Ranges.\n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "17/246:\n",
      "# Create a DataFrame for Scores by School Spending.\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "17/247:\n",
      "# Format\n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "17/248:\n",
      "# Create District Summary DataFrame.\n",
      "# Assign variable and add list of values and keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count,\n",
      "          \"Total Students\": student_count,\n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score,\n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/249:\n",
      "# Format colums by writing funtions.\n",
      "# Define function that calculates percentage of students who passed math. \n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    #return passing percentage as function is called.\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "# Define function that calculates percentage of students who passed reading.\n",
      "def passing_reading_percent(pass_reading_count, student_count):\n",
      "    return pass_reading_count / float(student_count) * 100\n",
      "17/250:\n",
      "# Format colums by writing funtions.\n",
      "# Define function that calculates percentage of students who passed math. \n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    #return passing percentage as function is called.\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/251:\n",
      "# Format colums by writing funtions.\n",
      "# Define function that calculates percentage of students who passed math. \n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "# Define function that calculates percentage of students who passed reading.\n",
      "def passing_reading_percent(pass_reading_count, student_count):\n",
      "    return pass_reading_count / float(student_count) * 100\n",
      "17/252:\n",
      "# Format colums by writing funtions.\n",
      "# Define function that calculates percentage of students who passed math. \n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/253:\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "17/254:\n",
      "# Create District Summary DataFrame.\n",
      "# Assign variable and add list of values and keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "        [{\"Total Schools\": school_count,\n",
      "        \"Total Students\": student_count,\n",
      "        \"Total Budget\": total_budget,\n",
      "        \"Average Math Score\": average_math_score,\n",
      "        \"Average Reading Score\": average_reading_score,\n",
      "        \"% Passing Math\": passing_math_percentage,\n",
      "        \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/255:\n",
      "# Format colums by writing funtions.\n",
      "# Define function that calculates percentage of students who passed math. \n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/256:\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "17/257:\n",
      " # Define function that calculates percentage of students who passed reading.\n",
      "def passing_reading_percent(pass_reading_count, student_count):\n",
      "    return pass_reading_count / float(student_count) * 100\n",
      "    #return passing percentage as function is called.\n",
      "17/258:\n",
      "# Call passing_math_percent()\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/259:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "17/260:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.isnull()\n",
      "17/261:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.isnull().sum()\n",
      "17/262:\n",
      "# Determine if there are not any missing values in the school data.\n",
      "school_data_df.notnull()\n",
      "16/29:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "student_data_df\n",
      "16/30:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "student_data_df.head(10)\n",
      "16/31:\n",
      "# Confirm that all prefixes and suffixes were corrected.\n",
      "# Declare new variable: student_names for cleaned student data: student_data_df[\"student_name\"].\n",
      "student_names = student_data_df[\"student_name\"]\n",
      "# Convert DataFrame: student_data_df[\"student_name\"] to a list.\n",
      "student_names = student_data_df[\"student_name\"].tolist()\n",
      "#student_names\n",
      "16/32:\n",
      "# Declate new list.\n",
      "students_fixed = []\n",
      "# Iterate through student_names to check the length of each name.\n",
      "for name in student_names:\n",
      "    # If the name is greater than or equal to 3...\n",
      "    if len(name.split()) >= 3:\n",
      "        #add the name to the list.\n",
      "        students_fixed.append(name)\n",
      "# Get the length of the students' names that are greater than or equal to 3.\n",
      "len(students_fixed)\n",
      "students_fixed\n",
      "16/33:\n",
      "# Declate new list.\n",
      "students_fixed = []\n",
      "# Iterate through student_names to check the length of each name.\n",
      "for name in student_names:\n",
      "    # If the name is greater than or equal to 3...\n",
      "    if len(name.split()) >= 3:\n",
      "        #add the name to the list.\n",
      "        students_fixed.append(name)\n",
      "# Get the length of the students' names that are greater than or equal to 3.\n",
      "len(students_fixed)\n",
      "Print(students_fixed)\n",
      "16/34:\n",
      "# Declate new list.\n",
      "students_fixed = []\n",
      "# Iterate through student_names to check the length of each name.\n",
      "for name in student_names:\n",
      "    # If the name is greater than or equal to 3...\n",
      "    if len(name.split()) >= 3:\n",
      "        #add the name to the list.\n",
      "        students_fixed.append(name)\n",
      "# Get the length of the students' names that are greater than or equal to 3.\n",
      "len(students_fixed)\n",
      "print(students_fixed)\n",
      "17/263:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "student_data_df.head(10)\n",
      "17/264:\n",
      "# Determine passing Percentages\n",
      "# Determine Passing Grade.\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "passing_math.head(5)\n",
      "17/265:\n",
      "# Determine passing Percentages\n",
      "# Determine Passing Grade.\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "passing_math.head(7)\n",
      "17/266:\n",
      "# Determine Percentage of Students Who Passed Math and Reading and convert student_count to a floating-point decimal.\n",
      "# Calculate percent that passed math and convert student_count to a floating-point decimal.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "# Calculate percent that passed reading and convert student_count to a floating-point decimal.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "print(passing_reading_percentage)\n",
      "17/267:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "        [{\"Total Schools\": school_count,\n",
      "        \"Total Students\": student_count,\n",
      "        \"Total Budget\": total_budget,\n",
      "        \"Average Math Score\": average_math_score,\n",
      "        \"Average Reading Score\": average_reading_score,\n",
      "        \"% Passing Math\": passing_math_percentage,\n",
      "        \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/268:\n",
      "# Format Columns by writing functions.\n",
      "# Write Functions for the School District Data.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/269:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/270:\n",
      "# Format Columns by writing functions.\n",
      "# Write Functions for the School District Data.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/271:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/272:\n",
      "# Format Columns by writing functions.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/273:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/274:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/275:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "17/276:\n",
      "# Format and print colums as requested.\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "# Display district_summary_df.\n",
      "district_summary_df\n",
      "17/277:\n",
      "## Reorder Columns IF/WHEN NEEDED.\n",
      "## Reorder columns in the order you want them to appear.\n",
      "#new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "## Assign a new or the same DataFrame the new column order.\n",
      "#df = df[new_column_order]\n",
      "17/278:\n",
      "## Reorder Columns IF/WHEN NEEDED.\n",
      "## Reorder columns in the order you want them to appear:\n",
      "##new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign a new or the same DataFrame the new column order:\n",
      "##df = df[new_column_order]\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "#district_summary_df\n",
      "17/279:\n",
      "## Reorder Columns IF/WHEN NEEDED.\n",
      "## Can also be used to filter out columns that aren't needed by leaving unwanted columns out of brackets.\n",
      "## Reorder columns in the desired order:\n",
      "##new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign a new or use same DataFrame for the new_column_order object:\n",
      "##df = df[new_column_order]\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "#district_summary_df\n",
      "17/280:\n",
      "## Reorder Columns IF/WHEN NEEDED.\n",
      "## Can also be used to filter out columns that aren't needed by leaving unwanted columns out of brackets.\n",
      "## Reorder columns in the desired order:\n",
      "## new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign a new or use same DataFrame for the new_column_order object:\n",
      "## df = df[new_column_order]\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "## Print.\n",
      "#district_summary_df\n",
      "17/281:\n",
      "# Indexing school_name column.\n",
      "# Index school_name column and follow by school type.\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "per_school_types\n",
      "17/282:\n",
      "# Convert per_school_types to a DataFrame.\n",
      "df = pd.DataFrame(per_school_types)\n",
      "df\n",
      "17/283:\n",
      "# Calculate student count per school in school_data_df.\n",
      "per_school_counts = school_data_df[\"size\"]\n",
      "per_school_counts\n",
      "#Unfortunately, this Series doesn't have an index with \"school_name.\" Therefore, we can't use the \"size\" column from school_data_df to get the count of the student population.\n",
      "17/284:\n",
      "# Calculate student count per school in school_data_df.\n",
      "per_school_counts = school_data_df[\"size\"]\n",
      "per_school_counts\n",
      "# This Series doesn't have an index with \"school_name.\" Therefore, we can't use the \"size\" column from school_data_df to get the count of the student population.\n",
      "# See fix in next cell.\n",
      "17/285:\n",
      "# Index school_name column and calculate student count in school_data_df.\n",
      "per_school_counts = school_data_df.set_index([\"school_name\"])[\"size\"]\n",
      "per_school_counts\n",
      "17/286:\n",
      "# Index school_name column and calculate student count from school_data_complete_df.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "per_school_counts\n",
      "17/287:\n",
      "# Budget Per Student.\n",
      "# Index school_name column and calculate the total school budget from school_data_df.\n",
      "per_school_budget = school_data_df.set_index([\"school_name\"])[\"budget\"]\n",
      "per_school_budget\n",
      "17/288:\n",
      "# Calculate per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "per_school_capita\n",
      "17/289:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "student_school_math\n",
      "17/290:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "## Unable to use school_data_df DataFrame, as there aren't any columns containing grades. We also can't use the set_index() method on the school_name column in student_data_df because there are too many occurrences of the school_name column.\n",
      "## See next cell for fix.\n",
      "17/291:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "per_school_averages\n",
      "17/292:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "## There is unnecessary data in the school summary DataFrame, only the reading and math scores are needed. To get the average math score and reading score for each school, we can add the math_score and reading_score columns at the end. Add the following code to a new cell and run the cell.\n",
      "## See next cell for fix.\n",
      "17/293:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "17/294:\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/295:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Assign passing_math variable to determine passing score parameters.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "# Calculate math passing score by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/296:\n",
      "# Get all of Students Who Passed Reading.\n",
      "# Retreive the students who are passing reading in a new DataFrame.\n",
      "passing_reading = school_data_complete_df[school_data_complete_df[\"reading_score\"] >= 70]\n",
      "#passing_reading.head()\n",
      "17/297:\n",
      "# Determine Percentage of Students Who Passed Math and Reading and convert student_count to a floating-point decimal.\n",
      "# Calculate percent that passed math and convert student_count to a floating-point decimal.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "# Calculate percent that passed reading and convert student_count to a floating-point decimal.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "print(passing_reading_percentage)\n",
      "17/298:\n",
      "# Calculate the Overall Passing Percentage.\n",
      "# Calculate students who passed both math and reading.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "passing_math_reading.head()\n",
      "17/299:\n",
      "# Calculate total number of students who passed both math and reading.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "overall_passing_math_reading_count\n",
      "17/300:\n",
      "# Calculate percentage of students who passed both math and reading.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / student_count * 100\n",
      "overall_passing_percentage\n",
      "17/301:\n",
      "# Format Columns by writing functions.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/302:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/303:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/304:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/305:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/306:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/307:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "17/308:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "        [{\"Total Schools\": school_count,\n",
      "        \"Total Students\": student_count,\n",
      "        \"Total Budget\": total_budget,\n",
      "        \"Average Math Score\": average_math_score,\n",
      "        \"Average Reading Score\": average_reading_score,\n",
      "        \"% Passing Math\": passing_math_percentage,\n",
      "        \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/309:\n",
      "# Format Columns by writing functions.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    return pass_math_count / float(student_count) * 100\n",
      "17/310:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "passing_math_count = 29370\n",
      "total_student_count = 39170\n",
      "# Call the function.\n",
      "passing_math_percent(passing_math_count, total_student_count)\n",
      "17/311:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/312:\n",
      "# Format Columns by writing functions.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "#def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    #return pass_math_count / float(student_count) * 100\n",
      "17/313:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "#passing_math_count = 29370\n",
      "#total_student_count = 39170\n",
      "# Call the function.\n",
      "#passing_math_percent(passing_math_count, total_student_count)\n",
      "17/314:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/315:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "        [{\"Total Schools\": school_count,\n",
      "        \"Total Students\": student_count,\n",
      "        \"Total Budget\": total_budget,\n",
      "        \"Average Math Score\": average_math_score,\n",
      "        \"Average Reading Score\": average_reading_score,\n",
      "        \"% Passing Math\": passing_math_percentage,\n",
      "        \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "17/316:\n",
      "# Format Columns by writing functions.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "#def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    #return pass_math_count / float(student_count) * 100\n",
      "17/317:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "#passing_math_count = 29370\n",
      "#total_student_count = 39170\n",
      "# Call the function.\n",
      "#passing_math_percent(passing_math_count, total_student_count)\n",
      "17/318:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "17/319:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "17/320:\n",
      "# Format and print colums as requested.\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "# Display district_summary_df.\n",
      "district_summary_df\n",
      "17/321:\n",
      "## Reorder Columns IF/WHEN NEEDED.\n",
      "## Can also be used to filter out columns that aren't needed by leaving unwanted columns out of brackets.\n",
      "## Reorder columns in the desired order:\n",
      "## new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign a new or use same DataFrame for the new_column_order object:\n",
      "## df = df[new_column_order]\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "## Print.\n",
      "#district_summary_df\n",
      "17/322:\n",
      "# Indexing school_name column.\n",
      "# Index school_name column and follow by school type.\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "per_school_types\n",
      "17/323:\n",
      "# Convert per_school_types Series to a DataFrame.\n",
      "df = pd.DataFrame(per_school_types)\n",
      "df\n",
      "17/324:\n",
      "# Get the Student Count Per School.\n",
      "# Calculate student count per school in school_data_df.\n",
      "per_school_counts = school_data_df[\"size\"]\n",
      "per_school_counts\n",
      "# This Series doesn't have an index with \"school_name.\" Therefore, we can't use the \"size\" column from school_data_df to get the count of the student population.\n",
      "# See fix in next cell.\n",
      "17/325:\n",
      "# Get the Student Count Per School.\n",
      "# Calculate student count per school in school_data_df.\n",
      "#per_school_counts = school_data_df[\"size\"]\n",
      "#per_school_counts\n",
      "# This Series doesn't have an index with \"school_name.\" Therefore, we can't use the \"size\" column from school_data_df to get the count of the student population.\n",
      "# See fix in next cell.\n",
      "17/326:\n",
      "# Index school_name column and calculate student count in school_data_df.\n",
      "per_school_counts = school_data_df.set_index([\"school_name\"])[\"size\"]\n",
      "per_school_counts\n",
      "17/327:\n",
      "# Index school_name column and calculate student count from school_data_complete_df.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "per_school_counts\n",
      "17/328:\n",
      "# Budget Per Student.\n",
      "# Index school_name column and calculate the total school budget from school_data_df.\n",
      "per_school_budget = school_data_df.set_index([\"school_name\"])[\"budget\"]\n",
      "per_school_budget\n",
      "17/329:\n",
      "# Calculate per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "per_school_capita\n",
      "17/330:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "## Unable to use school_data_df DataFrame, as there aren't any columns containing grades. We also can't use the set_index() method on the school_name column in student_data_df because there are too many occurrences of the school_name column.\n",
      "## See next cell for fix.\n",
      "17/331:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "## There is unnecessary data in the school summary DataFrame, only the reading and math scores are needed. To get the average math score and reading score for each school, we can add the math_score and reading_score columns at the end. Add the following code to a new cell and run the cell.\n",
      "## See next cell for fix.\n",
      "17/332:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "17/333:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "17/334:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "## UNSURE: Assign passing_math variable to determine passing score parameters.\n",
      "# UNSURE: passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "## UNSURE: Calculate math passing score by creating a filtered DataFrame.\n",
      "# UNSURE: per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "# UNSURE: per_school_passing_math.head()\n",
      "17/335:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "## UNSURE: Assign passing_math variable to determine passing score parameters.\n",
      "# UNSURE: passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "## UNSURE: Calculate math passing score by creating a filtered DataFrame.\n",
      "# UNSURE: per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "# UNSURE: per_school_passing_math.head()\n",
      "17/336:\n",
      "# Assign passing_reading variable to determine passing score parameters.\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/337:\n",
      "# Add students who passed math: passing_math to school_data_complete_df as math_score column.\n",
      "passing_math = school_data_complete_df[school_data_complete_df[\"math_score\"] >= 70]\n",
      "passing_math.head()\n",
      "17/338:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/339:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/340:\n",
      "## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "17/341:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/342: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "17/343:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/344:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "## Unable to use school_data_df DataFrame, as there aren't any columns containing grades. We also can't use the set_index() method on the school_name column in student_data_df because there are too many occurrences of the school_name column.\n",
      "## See next cell for fix.\n",
      "17/345:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "## There is unnecessary data in the school summary DataFrame, only the reading and math scores are needed. To get the average math score and reading score for each school, we can add the math_score and reading_score columns at the end. Add the following code to a new cell and run the cell.\n",
      "## See next cell for fix.\n",
      "17/346:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "17/347:\n",
      "# 4.8.5\n",
      "# Get the Passing Percentages Per School\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/348:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/349:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/350: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "17/351:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/352:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading\n",
      "17/353:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# per_school_passing_reading\n",
      "17/354:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# per_school_passing_reading\n",
      "17/355:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/356:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/357: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "17/358:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/359:\n",
      "# Calculate per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "per_school_capita\n",
      "17/360:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "## Unable to use school_data_df DataFrame, as there aren't any columns containing grades. We also can't use the set_index() method on the school_name column in student_data_df because there are too many occurrences of the school_name column.\n",
      "## See next cell for fix.\n",
      "17/361:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "## There is unnecessary data in the school summary DataFrame, only the reading and math scores are needed. To get the average math score and reading score for each school, we can add the math_score and reading_score columns at the end. Add the following code to a new cell and run the cell.\n",
      "## See next cell for fix.\n",
      "17/362:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "17/363:\n",
      "# 4.8.5\n",
      "# Get the Passing Percentages Per School\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/364:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/365:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/366: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "17/367:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/368:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# per_school_passing_reading\n",
      "17/369:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/370:\n",
      "# 4.8.5\n",
      "# Get the Passing Percentages Per School\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "17/371:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "17/372:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "17/373: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "17/374:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "17/375:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# per_school_passing_reading\n",
      "17/376:\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_math\n",
      "17/377:\n",
      "# Calculate the percentage of passing reading scores per school.\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "17/378:\n",
      "# To get the overall passing percentage, divide students who passed both math and reading by the total number of students.\n",
      "# Calculate overall math and reading passing percentage.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_passing_math_reading.head()\n",
      "17/379:\n",
      "## To get the total number of students who passed both math and reading on the per_passing_math_reading DataFrame, we use the following code, which sets the index to school_name, and then use the count() method for the student_name.\n",
      "# Place total number of students who passed  math and reading in per_passing_math_reading DataFrame.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "17/380:\n",
      "# Calculate percentage of students who passed math and reading by dividing them by the total number of students and multiplying by 100.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "per_overall_passing_percentage\n",
      "17/381:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "        \"School Type\": per_school_types,\n",
      "        \"Total Students\": per_school_counts,\n",
      "        \"Total School Budget\": per_school_budget,\n",
      "        \"Per Student Budget\": per_school_capita,\n",
      "        \"Average Math Score\": per_school_math,\n",
      "        \"Average Reading Score\": per_school_reading,\n",
      "        \"% Passing Math\": per_school_passing_math,\n",
      "        \"% Passing Reading\": per_school_passing_reading,\n",
      "        \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df.head()\n",
      "17/382:\n",
      "# 4.8.7\n",
      "# Clean Up the per_school_summary_df DataFrame.\n",
      "# Format Total School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format Student School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df.head()\n",
      "17/383:\n",
      "## IF NEEDED... Reorder columns desired in order.\n",
      "#new_column_order = [\"School Type\", \"Total Students\", \"Total School Budget\", \"Per Student Budget\", \"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign district summary df the new column order.\n",
      "#per_school_summary_df = per_school_summary_df[new_column_order]\n",
      "#per_school_summary_df.head()\n",
      "17/384:\n",
      "# 4.9.1\n",
      "# Find Highest Performing Schools.\n",
      "# Assign, sort, and print top five best performing schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "17/385:\n",
      "# 4.9.2\n",
      "# Find Lowest Performing Schools\n",
      "# Assign, sort, and print top five worse performing schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "17/386:\n",
      "# 4.10.1\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive each grade level student's grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "17/387:\n",
      "# Score Averages Grouped by School Name.\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "17/388:\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "17/389:\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Create a DataFrame for the average math scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade.head()\n",
      "17/390:\n",
      "# 4.10.2\n",
      "# Score Averages Grouped by School Name.\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "17/391:\n",
      "# Get the Average Reading Scores by School.\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "17/392:\n",
      "# 4.10.3\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Create a DataFrame for the average math scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade.head()\n",
      "17/393:\n",
      "# 4.10.3\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Add the math scores for each grade level to a new DataFrame.\n",
      "# Create a DataFrame for the average math scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade.head()\n",
      "17/394:\n",
      "# 4.10.3\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Add the math scores for each grade level to a new DataFrame.\n",
      "# Create a DataFrame for the average math scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade.head()\n",
      "17/395:\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Add the reading scores for each grade level to a new DataFrame.\n",
      "# Create a DataFrame for the average reading scores by grade level for each school.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "reading_scores_by_grade.head()\n",
      "17/396:\n",
      "# 4.10.4\n",
      "# Format Averages and Remove Index Name.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "# Place columns in correct order.\n",
      "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove index name.\n",
      "math_scores_by_grade.index.name = None\n",
      "math_scores_by_grade.head()\n",
      "17/397:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Place columns in correct order.\n",
      "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove  index name.\n",
      "reading_scores_by_grade.index.name = None\n",
      "reading_scores_by_grade.head()\n",
      "17/398:\n",
      "# 4.11.1\n",
      "# Establish Spending Ranges per Student\n",
      "# School spending per student's affect average scores and passing percentages.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "17/399:\n",
      "## Group Series by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "17/400:\n",
      "## Group Series evenly by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "17/401:\n",
      "# 4.11.2\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "17/402:\n",
      "# 4.11.3\n",
      "# Group by Spending Ranges.\n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "17/403:\n",
      "# 4.11.4\n",
      "# Create a DataFrame for Scores by School Spending.\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "17/404:\n",
      "# Format spending_summary_df\n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "17/405:\n",
      "# 4.12.1\n",
      "# Create Bins for School Size.\n",
      "# Establish School Size bins.\n",
      "size_bins = [0, 999, 1999, 5000]\n",
      "group_names = [\"Small (<1000)\", \"Medium (1000-1999)\", \"Large (2000-5000)\"]\n",
      "17/406:\n",
      "# 4.12.2\n",
      "# Categorize the School Size Bins.\n",
      "# Categorize spending based on the bins.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "17/407:\n",
      "# 4.12.2\n",
      "# Categorize the School Size Bins.\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "17/408:\n",
      "# 4.12.3\n",
      "# Group scores and averages by School Size.\n",
      "# Calculate averages for desired columns.\n",
      "size_math_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
      "size_reading_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
      "size_passing_math = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
      "size_passing_reading = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
      "size_overall_passing = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]\n",
      "17/409:\n",
      "# 4.12.2\n",
      "# Categorize the School Size Bins.\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "17/410:\n",
      "# 4.12.3\n",
      "# Group scores and averages by School Size.\n",
      "# Calculate averages for desired columns.\n",
      "size_math_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
      "size_reading_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
      "size_passing_math = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
      "size_passing_reading = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
      "size_overall_passing = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]\n",
      "17/411:\n",
      "# 4.12.4\n",
      "# Create DataFrame for the Scores by School Size.\n",
      "# Create School Size Summary DataFrame.\n",
      "size_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : size_math_scores,\n",
      "          \"Average Reading Score\": size_reading_scores,\n",
      "          \"% Passing Math\": size_passing_math,\n",
      "          \"% Passing Reading\": size_passing_reading,\n",
      "          \"% Overall Passing\": size_overall_passing})\n",
      "size_summary_df\n",
      "17/412:\n",
      "# Format DataFrame.\n",
      "# Format average math score to one decimal place.\n",
      "size_summary_df[\"Average Math Score\"] = size_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format average reading score to one decimal place.\n",
      "size_summary_df[\"Average Reading Score\"] = size_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentages of students who passed math and reading, and the overall passing percentage to nearest whole number.\n",
      "size_summary_df[\"% Passing Math\"] = size_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Passing Reading\"] = size_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Overall Passing\"] = size_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "size_summary_df\n",
      "17/413:\n",
      "# 4.13.1\n",
      "# Group averages and percentages by school type.\n",
      "# No need to create a School Type column as one already exists in per_school_summary_df.\n",
      "# Assign variables and calculate averages for desired columns.\n",
      "type_math_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Math Score\"]\n",
      "type_reading_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Reading Score\"]\n",
      "type_passing_math = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Math\"]\n",
      "type_passing_reading = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Reading\"]\n",
      "type_overall_passing = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Overall Passing\"]\n",
      "17/414:\n",
      "# 4.13.2\n",
      "# Create a Scores by School Type DataFrame.\n",
      "# Add dictionary to School Type DataFrame.\n",
      "type_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : type_math_scores,\n",
      "          \"Average Reading Score\": type_reading_scores,\n",
      "          \"% Passing Math\": type_passing_math,\n",
      "          \"% Passing Reading\": type_passing_reading,\n",
      "          \"% Overall Passing\": type_overall_passing})\n",
      "type_summary_df\n",
      "17/415:\n",
      "# Format type_summary_df.\n",
      "# Format average math and reading scores to one decimal place.\n",
      "type_summary_df[\"Average Math Score\"] = type_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "type_summary_df[\"Average Reading Score\"] = type_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentage of students who passed math and reading, and the overall passing percentage to the nearest whole number.\n",
      "type_summary_df[\"% Passing Math\"] = type_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Passing Reading\"] = type_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Overall Passing\"] = type_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "type_summary_df\n",
      "24/1:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "24/2:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "24/3:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "24/4:\n",
      "\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "24/5:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "24/6:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df()\n",
      "24/7:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "24/8:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "24/9:\n",
      "\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "24/10:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df()\n",
      "26/1:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "26/2:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "26/3:\n",
      "\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "#school_data_df = pd.read_csv(school_data_to_load)\n",
      "#student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "#prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "#for word in prefixes_suffixes:\n",
      "    #student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "#student_data_df.head(10)\n",
      "26/4:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df()\n",
      "26/5:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "26/6:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df.head()\n",
      "26/7:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "#school_data_df.head()\n",
      "26/8:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "#student_data_df.head()\n",
      "26/9:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "student_data_df.head(10)\n",
      "26/10:\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "#student_data_df.head(10)\n",
      "26/11:\n",
      "# Install numpy using conda install numpy or pip install numpy. \n",
      "# Step 1. Import numpy as np.\n",
      "import numpy as np\n",
      "26/12:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[]\n",
      "26/13:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import Numpy\n",
      "import numpy as np\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "26/14:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "26/15:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\")]\n",
      "26/16:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "26/17:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "student_data_df\n",
      "26/18:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "26/19:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "student_data_df\n",
      "26/20:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "#student_data_df\n",
      "26/21:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df\n",
      "26/22:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail()\n",
      "26/23:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail(10)\n",
      "28/1:\n",
      "# Deliverable 2 : Repeat the school district analysis\n",
      "# District Summary\n",
      "# Step 1. Use loc(), retrieve student_count of Thomas High School ninth graders in school_data_complete_df\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"Student ID\".count()\n",
      "28/2:\n",
      "# Deliverable 2 : Repeat the school district analysis\n",
      "# District Summary\n",
      "# Step 1. Use loc(), retrieve student_count of Thomas High School ninth graders in school_data_complete_df\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"Student ID\"\n",
      "28/3:\n",
      "# Deliverable 2 : Repeat the school district analysis\n",
      "# District Summary\n",
      "# Step 1. Use loc(), retrieve student_count of Thomas High School ninth graders in school_data_complete_df\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\")&(student_count)]\n",
      "28/4:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "28/5:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "28/6:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "#school_data_df.head()\n",
      "28/7:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "#student_data_df.head()\n",
      "28/8:\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "#student_data_df.head(10)\n",
      "28/9:\n",
      "# Deliverable 1: Replace reading and math scores.\n",
      "# Replace the 9th grade reading and math scores at Thomas High School with NaN.\n",
      "28/10:\n",
      "# Install numpy using conda install numpy or pip install numpy. \n",
      "# Step 1. Import numpy as np.\n",
      "import numpy as np\n",
      "28/11:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "28/12:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "#student_data_df\n",
      "28/13:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail(10)\n",
      "28/14:\n",
      "# Deliverable 2 : Repeat the school district analysis\n",
      "# District Summary\n",
      "# Step 1. Use loc(), retrieve student_count of Thomas High School ninth graders in school_data_complete_df\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\")&(student_count)]\n",
      "28/15:\n",
      "# Deliverable 2 : Repeat the school district analysis\n",
      "# District Summary\n",
      "# Step 1. Use loc(), retrieve student_count of Thomas High School ninth graders in school_data_complete_df\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), school_data_df[\"school_name\"].count()]\n",
      "28/16:\n",
      "# Deliverable 2 : Repeat the school district analysis\n",
      "# District Summary\n",
      "# Assign variable and merge student_data_df and school_data_df into single dataset.\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "# Step 1. Use loc(), retrieve student_count of Thomas High School ninth graders in school_data_complete_df\n",
      "28/17:\n",
      "# Deliverable 2 : Repeat the school district analysis\n",
      "# District Summary\n",
      "# Assign variable and merge student_data_df and school_data_df into single dataset.\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "# Step 1. Use loc(), retrieve student_count of Thomas High School ninth graders in school_data_complete_df\n",
      "28/18:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "school_count\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "total_budget\n",
      "28/19:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "school_count\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "school_count\n",
      "school_count\n",
      "total_budget\n",
      "28/20:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "school_count\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "#student_count\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "#total_budget\n",
      "28/21:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "school_count\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "#student_count\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "#total_budget\n",
      "28/22:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "school_count\n",
      "#student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "#student_count\n",
      "# Calculate the Total Budget\n",
      "#total_budget = school_data_df[\"budget\"].sum()\n",
      "#total_budget\n",
      "28/23:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "#school_count\n",
      "#student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "# Calculate the Total Budget\n",
      "#total_budget = school_data_df[\"budget\"].sum()\n",
      "#total_budget\n",
      "28/24:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "#school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "#school_count\n",
      "#student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "#student_count\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "total_budget\n",
      "28/25:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "#school_count\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "#student_count\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "#total_budget\n",
      "28/26:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "28/27:\n",
      "# Calculate the Average Scores using the \"clean_student_data\".\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "28/28:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"math_score\"]==\"NaN\")&&(student_data_df[\"reading_score\"]==\"NaN\")].count\n",
      "28/29:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"math_score\"]==\"NaN\")&&(student_data_df[\"reading_score\"]==\"NaN\")].count()\n",
      "28/30:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"math_score\"]==\"NaN\")&&(student_data_df[\"reading_score\"]==\"NaN\")]=count()\n",
      "28/31:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"math_score\"]==\"NaN\")&&(student_data_df[\"reading_score\"]==\"NaN\")]\n",
      "28/32:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"math_score\"]==\"NaN\")&(student_data_df[\"reading_score\"]==\"NaN\")]\n",
      "28/33:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\")&(student_data_df[\"reading_score\"]==\"NaN\")&(student_data_df[\"math_score\"]==\"NaN\")]\n",
      "28/34:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\")&(student_data_df[\"reading_score\"]==\"NaN\")&(student_data_df[\"math_score\"]==\"NaN\")].count()\n",
      "28/35:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\")&(school_data_complete_df[\"reading_score\"]==\"NaN\")&(school_data_complete_df[\"math_score\"]==\"NaN\")].count()\n",
      "28/36:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "nan_9=((school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\")&(school_data_complete_df[\"reading_score\"]==\"NaN\")&(school_data_complete_df[\"math_score\"]==\"NaN\")).count()\n",
      "28/37:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "nan_9=((school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\")&(school_data_complete_df[\"reading_score\"]==\"NaN\")&(school_data_complete_df[\"math_score\"]==\"NaN\")).count()\n",
      "nan_9\n",
      "28/38:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "nan_9=((school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\")).mean()\n",
      "nan_9\n",
      "28/39:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "nan_9=((school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\")).count()\n",
      "nan_9\n",
      "28/40:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "nan_9=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\")].count()\n",
      "nan_9\n",
      "28/41:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "nan_9=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\"), \"Student ID\"].count()\n",
      "nan_9\n",
      "28/42:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades.\n",
      "ths_9=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\"), \"Student ID\"].count()\n",
      "# Get the total student count \n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Step 2. Subtract the number of students that are in ninth grade at Thomas High School from the total student count to get the new total student count.\n",
      "new_total_student_count=student_count-ths_9\n",
      "28/43:\n",
      "# Calculate the passing rates using the \"clean_student_data\".\n",
      "passing_math_count = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
      "passing_reading_count = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)].count()[\"student_name\"]\n",
      "28/44:\n",
      "# Step 3. Calculate the passing percentages with the new total student count.\n",
      "passing_math_percentage = passing_math_count / float(new_student_count) * 100\n",
      "passing_reading_percentage = passing_reading_count / float(new_student_count) * 100\n",
      "28/45:\n",
      "# Step 3. Calculate the passing percentages with the new total student count.\n",
      "passing_math_percentage = passing_math_count / float(new_total_student_count) * 100\n",
      "passing_reading_percentage = passing_reading_count / float(new_total_student_count) * 100\n",
      "28/46:\n",
      "# Calculate the students who passed both reading and math.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)&(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "# Calculate the number of students that passed both reading and math.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "# Step 4.Calculate the overall passing percentage with new total student count.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / new_total_student_count * 100\n",
      "28/47:\n",
      "# Create a DataFrame\n",
      "district_summary_df = pd.DataFrame(\n",
      "        [{\"Total Schools\": school_count, \n",
      "        \"Total Students\": student_count, \n",
      "        \"Total Budget\": total_budget,\n",
      "        \"Average Math Score\": average_math_score, \n",
      "        \"Average Reading Score\": average_reading_score,\n",
      "        \"% Passing Math\": passing_math_percentage,\n",
      "        \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "# Format the \"Total Students\" to have the comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "# Format the \"Total Budget\" to have the comma for a thousands separator, a decimal separator and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format the columns.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.1f}\".format)\n",
      "# Display the data frame\n",
      "district_summary_df\n",
      "28/48:\n",
      "#School Summary\n",
      "# Determine the School Type\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "# Calculate the total student count.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "# Calculate the total school budget and per capita spending\n",
      "per_school_budget = school_data_complete_df.groupby([\"school_name\"]).mean()[\"budget\"]\n",
      "# Calculate the per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "# Calculate the average test scores.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "# Calculate the passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "# Calculate the students who passed both reading and math.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)&(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "28/49:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "# per_school_summary_df.head()\n",
      "28/50:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "# Display the data frame\n",
      "per_school_summary_df\n",
      "28/51:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "# Display the data frame\n",
      "#per_school_summary_df\n",
      "28/52:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "# Display the data frame\n",
      "per_school_summary_df\n",
      "28/53:\n",
      "#School Summary\n",
      "# Determine the School Type\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "# Calculate the total student count.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "# Calculate the total school budget and per capita spending\n",
      "per_school_budget = school_data_complete_df.groupby([\"school_name\"]).mean()[\"budget\"]\n",
      "# Calculate the per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "# Calculate the average test scores.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "# Calculate the passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "# Calculate the students who passed both reading and math.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)&(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "28/54:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "# per_school_summary_df.head()\n",
      "28/55:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "# Display the data frame\n",
      "per_school_summary_df\n",
      "28/56:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "# Display the data frame\n",
      "#per_school_summary_df\n",
      "28/57:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "# per_school_summary_df.head()\n",
      "28/58:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "# Display the data frame\n",
      "#per_school_summary_df\n",
      "28/59:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_10=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"10th\"), \"Student ID\"].count()\n",
      "28/60:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_remainder=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"10th\")&(school_data_complete_df[\"grade\"]==\"11th\")&(school_data_complete_df[\"grade\"]==\"12th\"),\"Student ID\"].count()\n",
      "28/61:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
      "28/62:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70))].count()[\"student_name\"]\n",
      "28/63:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70))].count()[\"student_name\"]\n",
      "28/64:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_remainder=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"10th\")&(school_data_complete_df[\"grade\"]==\"11th\")&(school_data_complete_df[\"grade\"]==\"12th\"),\"Student ID\"].count()\n",
      "ths_remainder\n",
      "28/65:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_remainder=school_data_complete.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"10th\")&(school_data_complete_df[\"grade\"]==\"11th\")&(school_data_complete_df[\"grade\"]==\"12th\"),\"Student ID\"].count()\n",
      "ths_remainder\n",
      "28/66:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_remainder=school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"10th\")&(school_data_complete_df[\"grade\"]==\"11th\")&(school_data_complete_df[\"grade\"]==\"12th\"),\"Student ID\"].count()\n",
      "ths_remainder\n",
      "28/67:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "#(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70))].count()[\"student_name\"]\n",
      "\n",
      "ths_10_12=school_data_complete_df.loc[(student_data_complete_df[\"school_name\"]==\"Thomas High School\")&(student_data_complete_df[\"grade\"]!=\"9th\"),\"Student ID\"].count()\n",
      "ths_remainder\n",
      "28/68:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "#(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70))].count()[\"student_name\"]\n",
      "\n",
      "ths_10_12=school_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]!=\"9th\"),\"Student ID\"].count()\n",
      "ths_remainder\n",
      "28/69:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "#(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70))].count()[\"student_name\"]\n",
      "\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_remainder\n",
      "28/70:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "#(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70))].count()[\"student_name\"]\n",
      "\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_10_12\n",
      "28/71:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70))].count()[\"student_name\"]\n",
      "28/72:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\")].count()\n",
      "28/73:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "28/74:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "28/75:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "28/76:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "28/77:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "28/78:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")& (school_data_complete_df[\"math_score\"] >= 70)&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "28/79:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading_count = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")& (school_data_complete_df[\"math_score\"] >= 70)&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_reading_count\n",
      "28/80:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading_count = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70)&(school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading_count\n",
      "28/81:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading_count = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70)&(school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading_count\n",
      "28/82:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading_count = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\"&school_data_complete_df[\"math_score\"] >= 70&school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading_count\n",
      "28/83:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading_count = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & school_data_complete_df[\"math_score\"] >= 70 & school_data_complete_df[\"reading_score\"] >= 70,\"Student ID\"].count()\n",
      "ths_passing_math_reading_count\n",
      "28/84:\n",
      "#School Summary\n",
      "# Determine the School Type\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "# Calculate the total student count.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "# Calculate the total school budget and per capita spending\n",
      "per_school_budget = school_data_complete_df.groupby([\"school_name\"]).mean()[\"budget\"]\n",
      "# Calculate the per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "# Calculate the average test scores.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "# Calculate the passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "# Calculate the students who passed both reading and math.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)&(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "28/85:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "# per_school_summary_df.head()\n",
      "28/86:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "# Display the data frame\n",
      "#per_school_summary_df\n",
      "28/87:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_10_12\n",
      "28/88:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "28/89:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "28/90:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading_count = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & school_data_complete_df[\"math_score\"] >= 70 & school_data_complete_df[\"reading_score\"] >= 70,\"Student ID\"].count()\n",
      "ths_passing_math_reading_count\n",
      "28/91:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading_count = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & (school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading_count\n",
      "28/92:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "28/93:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "28/94:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_reading/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "28/95:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "28/96:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "28/97:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "28/98:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & (school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading\n",
      "28/99:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "28/100:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "28/101:\n",
      "# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.\n",
      "ths_passing_reading_percentage= ths_reading_math_count/float(ths_10_12) * 100\n",
      "ths_passing_reading_percentage\n",
      "28/102:\n",
      "# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. \n",
      "ths_overall_passing_percentage=ths_passing_math_reading/ths_10_12 * 100\n",
      "28/103:\n",
      "# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. \n",
      "ths_overall_passing_percentage=ths_passing_math_reading/ths_10_12 * 100\n",
      "ths_overall_passing_percentage\n",
      "28/104:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "28/105:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "per_school_summary_df\n",
      "28/106:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "per_school_summary_df.tail()\n",
      "28/107:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "28/108:\n",
      "# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "28/109:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "28/110:\n",
      "# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "28/111:\n",
      "# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "28/112: per_school_summary_df\n",
      "28/113: #per_school_summary_df\n",
      "28/114:\n",
      "# High and Low Performing Schools\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "28/115:\n",
      "# Sort and show top five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "28/116: per_school_summary_df\n",
      "28/117: #per_school_summary_df\n",
      "28/118:\n",
      "# High and Low Performing Schools\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "28/119:\n",
      "# Sort and show top five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "28/120:\n",
      "# Math and Reading Scores by Grade\n",
      "# Create a Series of scores by grade levels using conditionals.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "# Group each school Series by the school name for the average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "# Group each school Series by the school name for the average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "28/121:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "28/122:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "28/123:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "28/124:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "math_scores_by_grade.head()\n",
      "28/125:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "reading_scores_by_grade.head()\n",
      "28/126:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "math_scores_by_grade\n",
      "28/127:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "reading_scores_by_grade\n",
      "28/128:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "28/129:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "28/130:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "28/131:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "math_scores_by_grade\n",
      "28/132:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "reading_scores_by_grade\n",
      "28/133: school_data_complete_df\n",
      "28/134:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#math_scores_by_grade\n",
      "28/135:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#reading_scores_by_grade\n",
      "28/136: school_data_complete_df\n",
      "28/137:\n",
      "# Sort and show lowest five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "28/138:\n",
      "# Math and Reading Scores by Grade\n",
      "# Create a Series of scores by grade levels using conditionals.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "# Group each school Series by the school name for the average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "# Group each school Series by the school name for the average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "28/139:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "28/140:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "28/141:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "28/142:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#math_scores_by_grade\n",
      "28/143:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#reading_scores_by_grade\n",
      "28/144:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "28/145:\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#reading_scores_by_grade\n",
      "28/146: #per_school_summary_df\n",
      "28/147:\n",
      "# High and Low Performing Schools\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "28/148:\n",
      "# Sort and show lowest five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "28/149:\n",
      "# Math and Reading Scores by Grade\n",
      "# Create a Series of scores by grade levels using conditionals.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "# Group each school Series by the school name for the average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "# Group each school Series by the school name for the average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "28/150:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "28/151:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "28/152:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "28/153:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#math_scores_by_grade\n",
      "28/154:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "28/155:\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#reading_scores_by_grade\n",
      "28/156:\n",
      "# Scores by School Spending.\n",
      "# Establish the spending bins and group names.\n",
      "\n",
      "\n",
      "# Categorize spending based on the bins.\n",
      "28/157: # Calculate averages for the desired columns.\n",
      "29/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "\n",
      "# File to Load (Remember to change the path if needed.)\n",
      "school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "student_data_to_load = \"Resources/students_complete.csv\"\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "30/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "\n",
      "# File to Load (Remember to change the path if needed.)\n",
      "school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "student_data_to_load = \"Resources/students_complete.csv\"\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "30/2:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/3:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "\n",
      "# File to Load (Remember to change the path if needed.)\n",
      "school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "student_data_to_load = \"Resources/students_complete.csv\"\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "30/4:\n",
      "# Install numpy using conda install numpy or pip install numpy. \n",
      "# Step 1. Import numpy as np.\n",
      "import numpy as np\n",
      "30/5:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/6:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/7:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail(10)\n",
      "26/24:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "#student_data_df.tail(10)\n",
      "30/8:\n",
      "# Combine the data into a single dataset\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "30/9:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "30/10:\n",
      "# Combine the data into a single dataset\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "30/11:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "30/12:\n",
      "# Calculate the Average Scores using the \"clean_student_data\".\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "30/13:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "\n",
      "# File to Load (Remember to change the path if needed.)\n",
      "school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "student_data_to_load = \"Resources/students_complete.csv\"\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "30/14:\n",
      "# Install numpy using conda install numpy or pip install numpy. \n",
      "# Step 1. Import numpy as np.\n",
      "import numpy as np\n",
      "30/15:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/16:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/17:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail(10)\n",
      "30/18:\n",
      "# Combine the data into a single dataset\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "30/19:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "30/20:\n",
      "# Calculate the Average Scores using the \"clean_student_data\".\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "30/21:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades. \n",
      "ths_9=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\"), \"Student ID\"].count()\n",
      "# Get the total student count \n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Step 2. Subtract the number of students that are in ninth grade at \n",
      "# Thomas High School from the total student count to get the new total student count.\n",
      "new_total_student_count=student_count-ths_9\n",
      "30/22:\n",
      "# Calculate the passing rates using the \"clean_student_data\".\n",
      "passing_math_count = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
      "passing_reading_count = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)].count()[\"student_name\"]\n",
      "30/23:\n",
      "# Step 3. Calculate the passing percentages with the new total student count.\n",
      "passing_math_percentage = passing_math_count / float(new_total_student_count) * 100\n",
      "passing_reading_percentage = passing_reading_count / float(new_total_student_count) * 100\n",
      "30/24:\n",
      "# Calculate the students who passed both reading and math.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students that passed both reading and math.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "\n",
      "\n",
      "# Step 4.Calculate the overall passing percentage with new total student count.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / new_total_student_count * 100\n",
      "30/25:\n",
      "# Create a DataFrame\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count, \n",
      "          \"Total Students\": student_count, \n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score, \n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "\n",
      "\n",
      "\n",
      "# Format the \"Total Students\" to have the comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "# Format the \"Total Budget\" to have the comma for a thousands separator, a decimal separator and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format the columns.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.1f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "district_summary_df\n",
      "30/26:\n",
      "# Determine the School Type\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "\n",
      "# Calculate the total student count.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "\n",
      "# Calculate the total school budget and per capita spending\n",
      "per_school_budget = school_data_complete_df.groupby([\"school_name\"]).mean()[\"budget\"]\n",
      "# Calculate the per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "\n",
      "# Calculate the average test scores.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "\n",
      "# Calculate the passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "\n",
      "# Calculate the students who passed both reading and math.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"math_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "30/27:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "\n",
      "\n",
      "# per_school_summary_df.head()\n",
      "30/28:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "per_school_summary_df\n",
      "30/29:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_10_12\n",
      "30/30:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "30/31:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "30/32:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & (school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading\n",
      "30/33:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "30/34:\n",
      "# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.\n",
      "ths_passing_reading_percentage= ths_reading_math_count/float(ths_10_12) * 100\n",
      "ths_passing_reading_percentage\n",
      "30/35:\n",
      "# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. \n",
      "ths_overall_passing_percentage=ths_passing_math_reading/ths_10_12 * 100\n",
      "ths_overall_passing_percentage\n",
      "30/36:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "30/37:\n",
      "# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "30/38:\n",
      "# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "30/39: # per_school_summary_df\n",
      "30/40:\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "30/41:\n",
      "# Sort and show lowest five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "30/42:\n",
      "# Create a Series of scores by grade levels using conditionals.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "# Group each school Series by the school name for the average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "# Group each school Series by the school name for the average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "30/43:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "30/44:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "30/45:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "30/46:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#math_scores_by_grade\n",
      "30/47:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#reading_scores_by_grade\n",
      "30/48:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "\n",
      "# File to Load (Remember to change the path if needed.)\n",
      "school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "student_data_to_load = \"Resources/students_complete.csv\"\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "30/49:\n",
      "# Install numpy using conda install numpy or pip install numpy. \n",
      "# Step 1. Import numpy as np.\n",
      "import numpy as np\n",
      "30/50:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/51:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/52:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail(10)\n",
      "30/53:\n",
      "# Combine the data into a single dataset\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "30/54:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "30/55:\n",
      "# Calculate the Average Scores using the \"clean_student_data\".\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "30/56:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades. \n",
      "ths_9=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\"), \"Student ID\"].count()\n",
      "# Get the total student count \n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Step 2. Subtract the number of students that are in ninth grade at \n",
      "# Thomas High School from the total student count to get the new total student count.\n",
      "new_total_student_count=student_count-ths_9\n",
      "30/57:\n",
      "# Calculate the passing rates using the \"clean_student_data\".\n",
      "passing_math_count = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
      "passing_reading_count = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)].count()[\"student_name\"]\n",
      "30/58:\n",
      "# Step 3. Calculate the passing percentages with the new total student count.\n",
      "passing_math_percentage = passing_math_count / float(new_total_student_count) * 100\n",
      "passing_reading_percentage = passing_reading_count / float(new_total_student_count) * 100\n",
      "30/59:\n",
      "# Calculate the students who passed both reading and math.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students that passed both reading and math.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "\n",
      "\n",
      "# Step 4.Calculate the overall passing percentage with new total student count.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / new_total_student_count * 100\n",
      "30/60:\n",
      "# Create a DataFrame\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count, \n",
      "          \"Total Students\": student_count, \n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score, \n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "\n",
      "\n",
      "\n",
      "# Format the \"Total Students\" to have the comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "# Format the \"Total Budget\" to have the comma for a thousands separator, a decimal separator and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format the columns.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.1f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "district_summary_df\n",
      "30/61:\n",
      "# Determine the School Type\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "\n",
      "# Calculate the total student count.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "\n",
      "# Calculate the total school budget and per capita spending\n",
      "per_school_budget = school_data_complete_df.groupby([\"school_name\"]).mean()[\"budget\"]\n",
      "# Calculate the per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "\n",
      "# Calculate the average test scores.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "\n",
      "# Calculate the passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "\n",
      "# Calculate the students who passed both reading and math.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"math_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "30/62:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "\n",
      "\n",
      "# per_school_summary_df.head()\n",
      "30/63:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "per_school_summary_df\n",
      "30/64:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_10_12\n",
      "30/65:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "30/66:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "30/67:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & (school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading\n",
      "30/68:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "30/69:\n",
      "# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.\n",
      "ths_passing_reading_percentage= ths_reading_math_count/float(ths_10_12) * 100\n",
      "ths_passing_reading_percentage\n",
      "30/70:\n",
      "# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. \n",
      "ths_overall_passing_percentage=ths_passing_math_reading/ths_10_12 * 100\n",
      "ths_overall_passing_percentage\n",
      "30/71:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "30/72:\n",
      "# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "30/73:\n",
      "# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "30/74: # per_school_summary_df\n",
      "30/75:\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "30/76:\n",
      "# Sort and show lowest five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "30/77:\n",
      "# Create a Series of scores by grade levels using conditionals.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "# Group each school Series by the school name for the average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "# Group each school Series by the school name for the average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "30/78:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "30/79:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "30/80:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "30/81:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#math_scores_by_grade\n",
      "30/82:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "#reading_scores_by_grade\n",
      "30/83:\n",
      "# Establish the spending bins and group names.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "# Categorize spending based on the bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/84:\n",
      "# Calculate averages for the desired columns. \n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "30/85:\n",
      "# Create the DataFrame\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "30/86:\n",
      "# Format the DataFrame \n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "30/87:\n",
      "# Establish the bins.\n",
      "size_bins = [0, 999, 1999, 5000]\n",
      "group_names = [\"Small (<1000)\", \"Medium (1000-1999)\", \"Large (2000-5000)\"]\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/88:\n",
      "# Calculate averages for the desired columns. \n",
      "size_math_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
      "size_reading_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
      "size_passing_math = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
      "size_passing_reading = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
      "size_overall_passing = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]\n",
      "30/89:\n",
      "# Assemble into DataFrame. \n",
      "size_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : size_math_scores,\n",
      "          \"Average Reading Score\": size_reading_scores,\n",
      "          \"% Passing Math\": size_passing_math,\n",
      "          \"% Passing Reading\": size_passing_reading,\n",
      "          \"% Overall Passing\": size_overall_passing})\n",
      "size_summary_df\n",
      "30/90:\n",
      "# Format the DataFrame  \n",
      "# Format average math score to one decimal place.\n",
      "size_summary_df[\"Average Math Score\"] = size_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format average reading score to one decimal place.\n",
      "size_summary_df[\"Average Reading Score\"] = size_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentages of students who passed math and reading, and the overall passing percentage to nearest whole number.\n",
      "size_summary_df[\"% Passing Math\"] = size_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Passing Reading\"] = size_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Overall Passing\"] = size_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "size_summary_df\n",
      "30/91:\n",
      "# Calculate averages for the desired columns. \n",
      "type_math_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Math Score\"]\n",
      "type_reading_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Reading Score\"]\n",
      "type_passing_math = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Math\"]\n",
      "type_passing_reading = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Reading\"]\n",
      "type_overall_passing = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Overall Passing\"]\n",
      "30/92:\n",
      "# Assemble into DataFrame. \n",
      "type_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : type_math_scores,\n",
      "          \"Average Reading Score\": type_reading_scores,\n",
      "          \"% Passing Math\": type_passing_math,\n",
      "          \"% Passing Reading\": type_passing_reading,\n",
      "          \"% Overall Passing\": type_overall_passing})\n",
      "type_summary_df\n",
      "30/93:\n",
      "# Format the DataFrame \n",
      "# Format average math and reading scores to one decimal place.\n",
      "type_summary_df[\"Average Math Score\"] = type_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "type_summary_df[\"Average Reading Score\"] = type_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentage of students who passed math and reading, and the overall passing percentage to the nearest whole number.\n",
      "type_summary_df[\"% Passing Math\"] = type_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Passing Reading\"] = type_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Overall Passing\"] = type_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "type_summary_df\n",
      "30/94:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "\n",
      "# File to Load (Remember to change the path if needed.)\n",
      "school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "student_data_to_load = \"Resources/students_complete.csv\"\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "30/95:\n",
      "# Install numpy using conda install numpy or pip install numpy. \n",
      "# Step 1. Import numpy as np.\n",
      "import numpy as np\n",
      "30/96:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/97:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/98:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail(10)\n",
      "30/99:\n",
      "# Combine the data into a single dataset\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "30/100:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "30/101:\n",
      "# Calculate the Average Scores using the \"clean_student_data\".\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "30/102:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades. \n",
      "ths_9=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\"), \"Student ID\"].count()\n",
      "# Get the total student count \n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Step 2. Subtract the number of students that are in ninth grade at \n",
      "# Thomas High School from the total student count to get the new total student count.\n",
      "new_total_student_count=student_count-ths_9\n",
      "30/103:\n",
      "# Calculate the passing rates using the \"clean_student_data\".\n",
      "passing_math_count = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
      "passing_reading_count = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)].count()[\"student_name\"]\n",
      "30/104:\n",
      "# Step 3. Calculate the passing percentages with the new total student count.\n",
      "passing_math_percentage = passing_math_count / float(new_total_student_count) * 100\n",
      "passing_reading_percentage = passing_reading_count / float(new_total_student_count) * 100\n",
      "30/105:\n",
      "# Calculate the students who passed both reading and math.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students that passed both reading and math.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "\n",
      "\n",
      "# Step 4.Calculate the overall passing percentage with new total student count.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / new_total_student_count * 100\n",
      "30/106:\n",
      "# Create a DataFrame\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count, \n",
      "          \"Total Students\": student_count, \n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score, \n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "\n",
      "\n",
      "\n",
      "# Format the \"Total Students\" to have the comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "# Format the \"Total Budget\" to have the comma for a thousands separator, a decimal separator and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format the columns.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.1f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "district_summary_df\n",
      "30/107:\n",
      "# Determine the School Type\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "\n",
      "# Calculate the total student count.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "\n",
      "# Calculate the total school budget and per capita spending\n",
      "per_school_budget = school_data_complete_df.groupby([\"school_name\"]).mean()[\"budget\"]\n",
      "# Calculate the per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "\n",
      "# Calculate the average test scores.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "\n",
      "# Calculate the passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "\n",
      "# Calculate the students who passed both reading and math.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"math_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "30/108:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "\n",
      "\n",
      "# per_school_summary_df.head()\n",
      "30/109:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "per_school_summary_df\n",
      "30/110:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_10_12\n",
      "30/111:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "30/112:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "30/113:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & (school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading\n",
      "30/114:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "30/115:\n",
      "# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.\n",
      "ths_passing_reading_percentage= ths_reading_math_count/float(ths_10_12) * 100\n",
      "ths_passing_reading_percentage\n",
      "30/116:\n",
      "# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. \n",
      "ths_overall_passing_percentage=ths_passing_math_reading/ths_10_12 * 100\n",
      "ths_overall_passing_percentage\n",
      "30/117:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "30/118:\n",
      "# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "30/119:\n",
      "# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "30/120: per_school_summary_df\n",
      "30/121:\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "30/122:\n",
      "# Sort and show lowest five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "30/123:\n",
      "# Create a Series of scores by grade levels using conditionals.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "# Group each school Series by the school name for the average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "# Group each school Series by the school name for the average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "30/124:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "30/125:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "30/126:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "30/127:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "math_scores_by_grade\n",
      "30/128:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "reading_scores_by_grade\n",
      "30/129:\n",
      "# Establish the spending bins and group names.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "# Categorize spending based on the bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/130:\n",
      "# Calculate averages for the desired columns. \n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "30/131:\n",
      "# Create the DataFrame\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "30/132:\n",
      "# Format the DataFrame \n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "30/133:\n",
      "# Establish the bins.\n",
      "size_bins = [0, 999, 1999, 5000]\n",
      "group_names = [\"Small (<1000)\", \"Medium (1000-1999)\", \"Large (2000-5000)\"]\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/134:\n",
      "# Calculate averages for the desired columns. \n",
      "size_math_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
      "size_reading_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
      "size_passing_math = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
      "size_passing_reading = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
      "size_overall_passing = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]\n",
      "30/135:\n",
      "# Assemble into DataFrame. \n",
      "size_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : size_math_scores,\n",
      "          \"Average Reading Score\": size_reading_scores,\n",
      "          \"% Passing Math\": size_passing_math,\n",
      "          \"% Passing Reading\": size_passing_reading,\n",
      "          \"% Overall Passing\": size_overall_passing})\n",
      "size_summary_df\n",
      "30/136:\n",
      "# Format the DataFrame  \n",
      "# Format average math score to one decimal place.\n",
      "size_summary_df[\"Average Math Score\"] = size_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format average reading score to one decimal place.\n",
      "size_summary_df[\"Average Reading Score\"] = size_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentages of students who passed math and reading, and the overall passing percentage to nearest whole number.\n",
      "size_summary_df[\"% Passing Math\"] = size_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Passing Reading\"] = size_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Overall Passing\"] = size_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "size_summary_df\n",
      "30/137:\n",
      "# Calculate averages for the desired columns. \n",
      "type_math_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Math Score\"]\n",
      "type_reading_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Reading Score\"]\n",
      "type_passing_math = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Math\"]\n",
      "type_passing_reading = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Reading\"]\n",
      "type_overall_passing = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Overall Passing\"]\n",
      "30/138:\n",
      "# Assemble into DataFrame. \n",
      "type_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : type_math_scores,\n",
      "          \"Average Reading Score\": type_reading_scores,\n",
      "          \"% Passing Math\": type_passing_math,\n",
      "          \"% Passing Reading\": type_passing_reading,\n",
      "          \"% Overall Passing\": type_overall_passing})\n",
      "type_summary_df\n",
      "30/139:\n",
      "# Format the DataFrame \n",
      "# Format average math and reading scores to one decimal place.\n",
      "type_summary_df[\"Average Math Score\"] = type_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "type_summary_df[\"Average Reading Score\"] = type_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentage of students who passed math and reading, and the overall passing percentage to the nearest whole number.\n",
      "type_summary_df[\"% Passing Math\"] = type_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Passing Reading\"] = type_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Overall Passing\"] = type_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "type_summary_df\n",
      "30/140:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "\n",
      "\n",
      "per_school_summary_df.head()\n",
      "30/141:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "\n",
      "\n",
      "per_school_summary_df\n",
      "27/1:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "        \"School Type\": per_school_types,\n",
      "        \"Total Students\": per_school_counts,\n",
      "        \"Total School Budget\": per_school_budget,\n",
      "        \"Per Student Budget\": per_school_capita,\n",
      "        \"Average Math Score\": per_school_math,\n",
      "        \"Average Reading Score\": per_school_reading,\n",
      "        \"% Passing Math\": per_school_passing_math,\n",
      "        \"% Passing Reading\": per_school_passing_reading,\n",
      "        \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df\n",
      "27/2:\n",
      "# 4.8.5\n",
      "# Get the Passing Percentages Per School\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "27/3:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "27/4:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "27/5: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "27/6:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "27/7:\n",
      "# Assign variables for files to load via path.\n",
      "#school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "#student_data_to_load = \"Resources/students_complete.csv\"\n",
      "27/8:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "27/9:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df\n",
      "27/10:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "27/11:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.count()\n",
      "27/12:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.count()\n",
      "27/13:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.isnull()\n",
      "27/14:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.isnull()\n",
      "27/15:\n",
      "# Determine if there are any missing values in the student data using .sum() to see number of empty rows.\n",
      "student_data_df.isnull().sum()\n",
      "27/16:\n",
      "# Determine if there are not any missing values in the school data.\n",
      "school_data_df.notnull()\n",
      "27/17:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.notnull().sum()\n",
      "27/18:\n",
      "# Determine data types for the school DataFrame.\n",
      "school_data_df.dtypes\n",
      "27/19:\n",
      "# Determine data types for the student DataFrame.\n",
      "student_data_df.dtypes\n",
      "27/20:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "student_data_df.head(10)\n",
      "27/21:\n",
      "# Merge DataFrames\n",
      "# Assign a variable and combine student_data_df and school_data_df into a single dataset.\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "27/22:\n",
      "#Get Number of Students.\n",
      "# Count all the items in each row for each column that is not null.\n",
      "# Code to use: school_data_complete_df.count()\n",
      "# Assign variable for student_count.\n",
      "student_count = school_data_complete_df.count()\n",
      "student_count\n",
      "27/23:\n",
      "# Assign student_count to a column that identifies with students in school_data_complete_df.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "student_count=school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "27/24:\n",
      "# Calculate number of schools, option one.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "# Assign variable for school_count.\n",
      "school_count = school_data_df[\"school_name\"].count()\n",
      "school_count\n",
      "27/25:\n",
      "# Calculate number of schools, option two, .unique().\n",
      "# Assign variable for school_count_2.\n",
      "school_count_2 = school_data_complete_df[\"school_name\"].unique()\n",
      "school_count_2\n",
      "27/26:\n",
      "#Get the Total Budget.\n",
      "# Assign variable for and calculate total_budget.\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "total_budget\n",
      "27/27:\n",
      "# Find the Average Reading Score.\n",
      "# Assign variable for and calculate average_reading_score.\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_reading_score\n",
      "27/28:\n",
      "# Find the Average Math Score.\n",
      "# Assign variable for and calculate average_math_score.\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "average_math_score\n",
      "27/29:\n",
      "# Determine passing Percentages\n",
      "# Determine Passing Grade.\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "passing_math.head(7)\n",
      "27/30:\n",
      "# Determine Number of Students Who Passed Math.\n",
      "# Retreive the students who are passing math in a new DataFrame.\n",
      "passing_math = school_data_complete_df[school_data_complete_df[\"math_score\"] >= 70]\n",
      "passing_math.head()\n",
      "27/31:\n",
      "# Get all of Students Who Passed Reading.\n",
      "# Retreive the students who are passing reading in a new DataFrame.\n",
      "passing_reading = school_data_complete_df[school_data_complete_df[\"reading_score\"] >= 70]\n",
      "#passing_reading.head()\n",
      "27/32:\n",
      "# Determine the number of students who passed math and reading.\n",
      "# Calculate number of students passing math.\n",
      "passing_math_count = passing_math[\"student_name\"].count()\n",
      "# Calculate number of students passing reading.\n",
      "passing_reading_count = passing_reading[\"student_name\"].count()\n",
      "print(passing_math_count)\n",
      "print(passing_reading_count)\n",
      "27/33:\n",
      "# Determine Percentage of Students Who Passed Math and Reading and convert student_count to a floating-point decimal.\n",
      "# Calculate percent that passed math and convert student_count to a floating-point decimal.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "# Calculate percent that passed reading and convert student_count to a floating-point decimal.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "print(passing_reading_percentage)\n",
      "27/34:\n",
      "# Calculate the Overall Passing Percentage.\n",
      "# Calculate students who passed both math and reading.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "passing_math_reading.head()\n",
      "27/35:\n",
      "# Calculate total number of students who passed both math and reading.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "overall_passing_math_reading_count\n",
      "27/36:\n",
      "# Calculate percentage of students who passed both math and reading.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / student_count * 100\n",
      "overall_passing_percentage\n",
      "27/37:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "        [{\"Total Schools\": school_count,\n",
      "        \"Total Students\": student_count,\n",
      "        \"Total Budget\": total_budget,\n",
      "        \"Average Math Score\": average_math_score,\n",
      "        \"Average Reading Score\": average_reading_score,\n",
      "        \"% Passing Math\": passing_math_percentage,\n",
      "        \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "27/38:\n",
      "# Format Columns by writing functions.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "#def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    #return pass_math_count / float(student_count) * 100\n",
      "27/39:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "#passing_math_count = 29370\n",
      "#total_student_count = 39170\n",
      "# Call the function.\n",
      "#passing_math_percent(passing_math_count, total_student_count)\n",
      "27/40:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "27/41:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "27/42:\n",
      "# Format and print colums as requested.\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "# Display district_summary_df.\n",
      "district_summary_df\n",
      "27/43:\n",
      "## Reorder Columns IF/WHEN NEEDED.\n",
      "## Can also be used to filter out columns that aren't needed by leaving unwanted columns out of brackets.\n",
      "## Reorder columns in the desired order:\n",
      "## new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign a new or use same DataFrame for the new_column_order object:\n",
      "## df = df[new_column_order]\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "## Print.\n",
      "#district_summary_df\n",
      "27/44:\n",
      "# Indexing school_name column.\n",
      "# Index school_name column and follow by school type.\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "per_school_types\n",
      "27/45:\n",
      "# Convert per_school_types Series to a DataFrame.\n",
      "df = pd.DataFrame(per_school_types)\n",
      "df\n",
      "27/46:\n",
      "# Get the Student Count Per School.\n",
      "# Calculate student count per school in school_data_df.\n",
      "#per_school_counts = school_data_df[\"size\"]\n",
      "#per_school_counts\n",
      "# This Series doesn't have an index with \"school_name.\" Therefore, we can't use the \"size\" column from school_data_df to get the count of the student population.\n",
      "# See fix in next cell.\n",
      "27/47:\n",
      "# Index school_name column and calculate student count in school_data_df.\n",
      "per_school_counts = school_data_df.set_index([\"school_name\"])[\"size\"]\n",
      "per_school_counts\n",
      "27/48:\n",
      "# Index school_name column and calculate student count from school_data_complete_df.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "per_school_counts\n",
      "27/49:\n",
      "# Budget Per Student.\n",
      "# Index school_name column and calculate the total school budget from school_data_df.\n",
      "per_school_budget = school_data_df.set_index([\"school_name\"])[\"budget\"]\n",
      "per_school_budget\n",
      "27/50:\n",
      "# Calculate per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "per_school_capita\n",
      "27/51:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "## Unable to use school_data_df DataFrame, as there aren't any columns containing grades. We also can't use the set_index() method on the school_name column in student_data_df because there are too many occurrences of the school_name column.\n",
      "## See next cell for fix.\n",
      "27/52:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "## There is unnecessary data in the school summary DataFrame, only the reading and math scores are needed. To get the average math score and reading score for each school, we can add the math_score and reading_score columns at the end. Add the following code to a new cell and run the cell.\n",
      "## See next cell for fix.\n",
      "27/53:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "27/54:\n",
      "# 4.8.5\n",
      "# Get the Passing Percentages Per School\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "27/55:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "27/56:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "27/57: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "27/58:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "27/59:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# per_school_passing_reading\n",
      "27/60:\n",
      "# Calculate the percentage of passing math scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_math\n",
      "27/61:\n",
      "# Calculate the percentage of passing reading scores per school.\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "27/62:\n",
      "# To get the overall passing percentage, divide students who passed both math and reading by the total number of students.\n",
      "# Calculate overall math and reading passing percentage.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_passing_math_reading.head()\n",
      "27/63:\n",
      "## To get the total number of students who passed both math and reading on the per_passing_math_reading DataFrame, we use the following code, which sets the index to school_name, and then use the count() method for the student_name.\n",
      "# Place total number of students who passed  math and reading in per_passing_math_reading DataFrame.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "27/64:\n",
      "# Calculate percentage of students who passed math and reading by dividing them by the total number of students and multiplying by 100.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "per_overall_passing_percentage\n",
      "27/65:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "        \"School Type\": per_school_types,\n",
      "        \"Total Students\": per_school_counts,\n",
      "        \"Total School Budget\": per_school_budget,\n",
      "        \"Per Student Budget\": per_school_capita,\n",
      "        \"Average Math Score\": per_school_math,\n",
      "        \"Average Reading Score\": per_school_reading,\n",
      "        \"% Passing Math\": per_school_passing_math,\n",
      "        \"% Passing Reading\": per_school_passing_reading,\n",
      "        \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df\n",
      "27/66:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "        \"School Type\": per_school_types,\n",
      "        \"Total Students\": per_school_counts,\n",
      "        \"Total School Budget\": per_school_budget,\n",
      "        \"Per Student Budget\": per_school_capita,\n",
      "        \"Average Math Score\": per_school_math,\n",
      "        \"Average Reading Score\": per_school_reading,\n",
      "        \"% Passing Math\": per_school_passing_math,\n",
      "        \"% Passing Reading\": per_school_passing_reading,\n",
      "        \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df.head()\n",
      "30/142:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "per_school_summary_df.head()\n",
      "27/67:\n",
      "# 4.8.7\n",
      "# Clean Up the per_school_summary_df DataFrame.\n",
      "# Format Total School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format Student School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df.head()\n",
      "27/68:\n",
      "## IF NEEDED... Reorder columns desired in order.\n",
      "#new_column_order = [\"School Type\", \"Total Students\", \"Total School Budget\", \"Per Student Budget\", \"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign district summary df the new column order.\n",
      "#per_school_summary_df = per_school_summary_df[new_column_order]\n",
      "#per_school_summary_df.head()\n",
      "27/69:\n",
      "# 4.9.1\n",
      "# Find Highest Performing Schools.\n",
      "# Assign, sort, and print top five best performing schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "30/143:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_10_12\n",
      "30/144:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "30/145:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "30/146:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & (school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading\n",
      "30/147:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "30/148:\n",
      "# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.\n",
      "ths_passing_reading_percentage= ths_reading_math_count/float(ths_10_12) * 100\n",
      "ths_passing_reading_percentage\n",
      "30/149:\n",
      "# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. \n",
      "ths_overall_passing_percentage=ths_passing_math_reading/ths_10_12 * 100\n",
      "ths_overall_passing_percentage\n",
      "30/150:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "30/151:\n",
      "# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "30/152:\n",
      "# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "30/153: per_school_summary_df\n",
      "30/154:\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "27/70:\n",
      "# Import Pandas library as a dependency.\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "27/71:\n",
      "# Assign variables for files to load via path.\n",
      "#school_data_to_load = \"Resources/schools_complete.csv\"\n",
      "#student_data_to_load = \"Resources/students_complete.csv\"\n",
      "27/72:\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "27/73:\n",
      "# Read school data file and store it in a Pandas DataFrame.\n",
      "school_data_df=pd.read_csv(school_data_to_load)\n",
      "school_data_df\n",
      "27/74:\n",
      "# Read student data file and store it in a Pandas DataFrame.\n",
      "student_data_df=pd.read_csv(student_data_to_load)\n",
      "student_data_df.head()\n",
      "27/75:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.count()\n",
      "27/76:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.count()\n",
      "27/77:\n",
      "# Determine if there are any missing values in the school data.\n",
      "school_data_df.isnull()\n",
      "27/78:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.isnull()\n",
      "27/79:\n",
      "# Determine if there are any missing values in the student data using .sum() to see number of empty rows.\n",
      "student_data_df.isnull().sum()\n",
      "27/80:\n",
      "# Determine if there are not any missing values in the school data.\n",
      "school_data_df.notnull()\n",
      "27/81:\n",
      "# Determine if there are any missing values in the student data.\n",
      "student_data_df.notnull().sum()\n",
      "27/82:\n",
      "# Determine data types for the school DataFrame.\n",
      "school_data_df.dtypes\n",
      "27/83:\n",
      "# Determine data types for the student DataFrame.\n",
      "student_data_df.dtypes\n",
      "27/84:\n",
      "# Remove prefixes and suffixes.\n",
      "# Declare prefixes_suffixes list.\n",
      "prefixes_suffixes=[\"Dr. \", \"Mr. \", \"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "# Iterate through prefixes_suffixes list.\n",
      "for word in prefixes_suffixes:\n",
      "    # Replace prefixes_suffixes with \"\".\n",
      "    student_data_df[\"student_name\"]=student_data_df[\"student_name\"].str.replace(word, \"\")\n",
      "student_data_df.head(10)\n",
      "27/85:\n",
      "# Merge DataFrames\n",
      "# Assign a variable and combine student_data_df and school_data_df into a single dataset.\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "27/86:\n",
      "#Get Number of Students.\n",
      "# Count all the items in each row for each column that is not null.\n",
      "# Code to use: school_data_complete_df.count()\n",
      "# Assign variable for student_count.\n",
      "student_count = school_data_complete_df.count()\n",
      "student_count\n",
      "27/87:\n",
      "# Assign student_count to a column that identifies with students in school_data_complete_df.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "student_count=school_data_complete_df[\"Student ID\"].count()\n",
      "student_count\n",
      "27/88:\n",
      "# Calculate number of schools, option one.\n",
      "# Code to use: school_data_complete_df[\"column\"].count()\n",
      "# Assign variable for school_count.\n",
      "school_count = school_data_df[\"school_name\"].count()\n",
      "school_count\n",
      "27/89:\n",
      "# Calculate number of schools, option two, .unique().\n",
      "# Assign variable for school_count_2.\n",
      "school_count_2 = school_data_complete_df[\"school_name\"].unique()\n",
      "school_count_2\n",
      "27/90:\n",
      "#Get the Total Budget.\n",
      "# Assign variable for and calculate total_budget.\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "total_budget\n",
      "27/91:\n",
      "# Find the Average Reading Score.\n",
      "# Assign variable for and calculate average_reading_score.\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_reading_score\n",
      "27/92:\n",
      "# Find the Average Math Score.\n",
      "# Assign variable for and calculate average_math_score.\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "average_math_score\n",
      "27/93:\n",
      "# Determine passing Percentages\n",
      "# Determine Passing Grade.\n",
      "# Assign variables for passing grades.\n",
      "passing_math = school_data_complete_df[\"math_score\"] >= 70\n",
      "passing_reading = school_data_complete_df[\"reading_score\"] >= 70\n",
      "passing_math.head(7)\n",
      "27/94:\n",
      "# Determine Number of Students Who Passed Math.\n",
      "# Retreive the students who are passing math in a new DataFrame.\n",
      "passing_math = school_data_complete_df[school_data_complete_df[\"math_score\"] >= 70]\n",
      "passing_math.head()\n",
      "27/95:\n",
      "# Get all of Students Who Passed Reading.\n",
      "# Retreive the students who are passing reading in a new DataFrame.\n",
      "passing_reading = school_data_complete_df[school_data_complete_df[\"reading_score\"] >= 70]\n",
      "#passing_reading.head()\n",
      "27/96:\n",
      "# Determine the number of students who passed math and reading.\n",
      "# Calculate number of students passing math.\n",
      "passing_math_count = passing_math[\"student_name\"].count()\n",
      "# Calculate number of students passing reading.\n",
      "passing_reading_count = passing_reading[\"student_name\"].count()\n",
      "print(passing_math_count)\n",
      "print(passing_reading_count)\n",
      "27/97:\n",
      "# Determine Percentage of Students Who Passed Math and Reading and convert student_count to a floating-point decimal.\n",
      "# Calculate percent that passed math and convert student_count to a floating-point decimal.\n",
      "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
      "# Calculate percent that passed reading and convert student_count to a floating-point decimal.\n",
      "passing_reading_percentage = passing_reading_count / float(student_count) * 100\n",
      "print(passing_math_percentage)\n",
      "print(passing_reading_percentage)\n",
      "27/98:\n",
      "# Calculate the Overall Passing Percentage.\n",
      "# Calculate students who passed both math and reading.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "passing_math_reading.head()\n",
      "27/99:\n",
      "# Calculate total number of students who passed both math and reading.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "overall_passing_math_reading_count\n",
      "27/100:\n",
      "# Calculate percentage of students who passed both math and reading.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / student_count * 100\n",
      "overall_passing_percentage\n",
      "27/101:\n",
      "# Create a District Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "district_summary_df = pd.DataFrame(\n",
      "        [{\"Total Schools\": school_count,\n",
      "        \"Total Students\": student_count,\n",
      "        \"Total Budget\": total_budget,\n",
      "        \"Average Math Score\": average_math_score,\n",
      "        \"Average Reading Score\": average_reading_score,\n",
      "        \"% Passing Math\": passing_math_percentage,\n",
      "        \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "district_summary_df\n",
      "27/102:\n",
      "# Format Columns by writing functions.\n",
      "# Define a function that calculates the percentage of students that passed both math and reading and returns the passing percentage when the function is called.\n",
      "# Add pass_math_count and student_count values to the passing_math_percent function.\n",
      "#def passing_math_percent(pass_math_count, student_count):\n",
      "    # Add return in front of the calculation for the passing percentage.\n",
      "    #return pass_math_count / float(student_count) * 100\n",
      "27/103:\n",
      "# Assign passing_math_count and total_student_count variables.\n",
      "#passing_math_count = 29370\n",
      "#total_student_count = 39170\n",
      "# Call the function.\n",
      "#passing_math_percent(passing_math_count, total_student_count)\n",
      "27/104:\n",
      "# Format Columns by writing functions for the School District Data.\n",
      "# Format the \"Total Students\" column to have a comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "district_summary_df[\"Total Students\"]\n",
      "27/105:\n",
      "# Format the \"Total Budget\" column to have a comma for a thousands separator, a decimal separator, and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "district_summary_df[\"Total Budget\"]\n",
      "27/106:\n",
      "# Format and print colums as requested.\n",
      "# Format the \"Average Reading Score\" column to be formatted to one decimal place.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"Average Math Score\" column yo be formatted to one decimal place.\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Passing Reading\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "# Format the \"% Overall Passing\" column to be formatted to nearest whole number percentage.\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "# Display district_summary_df.\n",
      "district_summary_df\n",
      "27/107:\n",
      "## Reorder Columns IF/WHEN NEEDED.\n",
      "## Can also be used to filter out columns that aren't needed by leaving unwanted columns out of brackets.\n",
      "## Reorder columns in the desired order:\n",
      "## new_column_order = [\"column2\", \"column4\", \"column1\"]\n",
      "#new_column_order = [\"Total Schools\", \"Total Students\", \"Total Budget\",\"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign a new or use same DataFrame for the new_column_order object:\n",
      "## df = df[new_column_order]\n",
      "#district_summary_df = district_summary_df[new_column_order]\n",
      "## Print.\n",
      "#district_summary_df\n",
      "27/108:\n",
      "# Indexing school_name column.\n",
      "# Index school_name column and follow by school type.\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "per_school_types\n",
      "27/109:\n",
      "# Convert per_school_types Series to a DataFrame.\n",
      "df = pd.DataFrame(per_school_types)\n",
      "df\n",
      "27/110:\n",
      "# Get the Student Count Per School.\n",
      "# Calculate student count per school in school_data_df.\n",
      "#per_school_counts = school_data_df[\"size\"]\n",
      "#per_school_counts\n",
      "# This Series doesn't have an index with \"school_name.\" Therefore, we can't use the \"size\" column from school_data_df to get the count of the student population.\n",
      "# See fix in next cell.\n",
      "27/111:\n",
      "# Index school_name column and calculate student count in school_data_df.\n",
      "per_school_counts = school_data_df.set_index([\"school_name\"])[\"size\"]\n",
      "per_school_counts\n",
      "27/112:\n",
      "# Index school_name column and calculate student count from school_data_complete_df.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "per_school_counts\n",
      "27/113:\n",
      "# Budget Per Student.\n",
      "# Index school_name column and calculate the total school budget from school_data_df.\n",
      "per_school_budget = school_data_df.set_index([\"school_name\"])[\"budget\"]\n",
      "per_school_budget\n",
      "27/114:\n",
      "# Calculate per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "per_school_capita\n",
      "27/115:\n",
      "## Score Averages Per School.\n",
      "## Index school_name column and calculate math scores.\n",
      "#student_school_math = student_data_df.set_index([\"school_name\"])[\"math_score\"]\n",
      "#student_school_math\n",
      "## Unable to use school_data_df DataFrame, as there aren't any columns containing grades. We also can't use the set_index() method on the school_name column in student_data_df because there are too many occurrences of the school_name column.\n",
      "## See next cell for fix.\n",
      "27/116:\n",
      "## Calculate average math scores using groupby() and mean().\n",
      "#per_school_averages = school_data_complete_df.groupby([\"school_name\"]).mean()\n",
      "#per_school_averages\n",
      "## There is unnecessary data in the school summary DataFrame, only the reading and math scores are needed. To get the average math score and reading score for each school, we can add the math_score and reading_score columns at the end. Add the following code to a new cell and run the cell.\n",
      "## See next cell for fix.\n",
      "27/117:\n",
      "# Calculate average math scores using groupby() and mean() and reference the Series.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_math\n",
      "27/118:\n",
      "# 4.8.5\n",
      "# Get the Passing Percentages Per School\n",
      "# Calculate average reading scores using groupby() and mean() and reference the Series.\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "per_school_reading\n",
      "27/119:\n",
      "# Passing Percentages Per School.\n",
      "# Determine the Passing Grade.\n",
      "# Calculate math passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_math.head()\n",
      "27/120:\n",
      "# Calculate reading passing score by creating a filtered DataFrame.\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "#per_school_passing_reading.head()\n",
      "27/121: ## Next We need to get the average reading and math scores for each school. So, the index needs to be the school_name, and we need to get the number of students in the per_school_passing_math and the per_school_passing_reading DataFrames.\n",
      "27/122:\n",
      "# Calculate students passing math using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_math\n",
      "27/123:\n",
      "# Calculate students passing reading using groupby() and count() for indexing and concise list.\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "# per_school_passing_reading\n",
      "27/124:\n",
      "# Calculate the percentage of passing math scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_math\n",
      "27/125:\n",
      "# Calculate the percentage of passing reading scores per school.\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "27/126:\n",
      "# To get the overall passing percentage, divide students who passed both math and reading by the total number of students.\n",
      "# Calculate overall math and reading passing percentage.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "per_passing_math_reading.head()\n",
      "27/127:\n",
      "## To get the total number of students who passed both math and reading on the per_passing_math_reading DataFrame, we use the following code, which sets the index to school_name, and then use the count() method for the student_name.\n",
      "# Place total number of students who passed  math and reading in per_passing_math_reading DataFrame.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "27/128:\n",
      "# Calculate percentage of students who passed math and reading by dividing them by the total number of students and multiplying by 100.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "per_overall_passing_percentage\n",
      "27/129:\n",
      "# Create School Summary DataFrame.\n",
      "# Assign variable and add list of values with keys to new DataFrame.\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "        \"School Type\": per_school_types,\n",
      "        \"Total Students\": per_school_counts,\n",
      "        \"Total School Budget\": per_school_budget,\n",
      "        \"Per Student Budget\": per_school_capita,\n",
      "        \"Average Math Score\": per_school_math,\n",
      "        \"Average Reading Score\": per_school_reading,\n",
      "        \"% Passing Math\": per_school_passing_math,\n",
      "        \"% Passing Reading\": per_school_passing_reading,\n",
      "        \"% Overall Passing\": per_overall_passing_percentage})\n",
      "per_school_summary_df.head()\n",
      "27/130:\n",
      "# 4.8.7\n",
      "# Clean Up the per_school_summary_df DataFrame.\n",
      "# Format Total School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format Student School Budget column, ${:,.2f}, .map(\"changes to be made to every row in column\".format).\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df.head()\n",
      "27/131:\n",
      "## IF NEEDED... Reorder columns desired in order.\n",
      "#new_column_order = [\"School Type\", \"Total Students\", \"Total School Budget\", \"Per Student Budget\", \"Average Math Score\", \"Average Reading Score\", \"% Passing Math\", \"% Passing Reading\", \"% Overall Passing\"]\n",
      "## Assign district summary df the new column order.\n",
      "#per_school_summary_df = per_school_summary_df[new_column_order]\n",
      "#per_school_summary_df.head()\n",
      "27/132:\n",
      "# 4.9.1\n",
      "# Find Highest Performing Schools.\n",
      "# Assign, sort, and print top five best performing schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "27/133:\n",
      "# 4.9.2\n",
      "# Find Lowest Performing Schools\n",
      "# Assign, sort, and print top five worse performing schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "27/134:\n",
      "# 4.10.1\n",
      "# Grade-Level DataFrames.\n",
      "# Assign variables, create DataFrames, and retreive each grade level student's grades.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "27/135:\n",
      "# 4.10.2\n",
      "# Score Averages Grouped by School Name.\n",
      "# Get the Average Math Scores by School.\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "27/136:\n",
      "# Get the Average Reading Scores by School.\n",
      "# Assign variables, groupby() school_name column, and retreive each grade levels' average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "27/137:\n",
      "# 4.10.3\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Add the math scores for each grade level to a new DataFrame.\n",
      "# Create a DataFrame for the average math scores by grade level for each school.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "math_scores_by_grade\n",
      "27/138:\n",
      "# Combine each grade level Series into a DataFrame.\n",
      "# Add the reading scores for each grade level to a new DataFrame.\n",
      "# Create a DataFrame for the average reading scores by grade level for each school.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "reading_scores_by_grade.head()\n",
      "27/139:\n",
      "# 4.10.4\n",
      "# Format Averages and Remove Index Name.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "# Place columns in correct order.\n",
      "math_scores_by_grade = math_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove index name.\n",
      "math_scores_by_grade.index.name = None\n",
      "math_scores_by_grade.head()\n",
      "27/140:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Place columns in correct order.\n",
      "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
      "# Remove  index name.\n",
      "reading_scores_by_grade.index.name = None\n",
      "reading_scores_by_grade.head()\n",
      "27/141:\n",
      "# 4.11.1\n",
      "# Establish Spending Ranges per Student\n",
      "# School spending per student's affect average scores and passing percentages.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "27/142:\n",
      "## Group Series evenly by Spending Ranges.\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "## Cut  DataFrame into ranges and print.\n",
      "#pd.cut(per_school_capita, spending_bins)\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "27/143:\n",
      "# 4.11.2\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "27/144:\n",
      "# 4.11.3\n",
      "# Group by Spending Ranges.\n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "27/145:\n",
      "# 4.11.4\n",
      "# Create a DataFrame for Scores by School Spending.\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "27/146:\n",
      "# Format spending_summary_df\n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "30/155:\n",
      "# Establish the spending bins and group names.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "# Categorize spending based on the bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df\n",
      "27/147:\n",
      "# 4.11.2\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df\n",
      "30/156:\n",
      "# Establish the spending bins and group names.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "# Categorize spending based on the bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "27/148:\n",
      "# 4.11.2\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.()\n",
      "27/149:\n",
      "# 4.11.3\n",
      "# Group by Spending Ranges.\n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "27/150:\n",
      "# 4.11.2\n",
      "# Categorize Spending Bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "27/151:\n",
      "# 4.11.3\n",
      "# Group by Spending Ranges.\n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "27/152:\n",
      "# 4.11.4\n",
      "# Create a DataFrame for Scores by School Spending.\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "27/153:\n",
      "# 4.11.4\n",
      "# Create a DataFrame for Scores by School Spending.\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "27/154:\n",
      "# Format spending_summary_df\n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "27/155:\n",
      "# 4.12.1\n",
      "# Create  School Size Bins.\n",
      "# Establish School Size bins.\n",
      "size_bins = [0, 999, 1999, 5000]\n",
      "group_names = [\"Small (<1000)\", \"Medium (1000-1999)\", \"Large (2000-5000)\"]\n",
      "27/156:\n",
      "# 4.12.2\n",
      "# Categorize the School Size Bins.\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df\n",
      "30/157:\n",
      "# Calculate averages for the desired columns. \n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "30/158:\n",
      "# Create the DataFrame\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "30/159:\n",
      "# Format the DataFrame \n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "30/160:\n",
      "# Establish the bins.\n",
      "size_bins = [0, 999, 1999, 5000]\n",
      "group_names = [\"Small (<1000)\", \"Medium (1000-1999)\", \"Large (2000-5000)\"]\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df\n",
      "27/157:\n",
      "# 4.12.2\n",
      "# Categorize the School Size Bins.\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/161:\n",
      "# Establish the bins.\n",
      "size_bins = [0, 999, 1999, 5000]\n",
      "group_names = [\"Small (<1000)\", \"Medium (1000-1999)\", \"Large (2000-5000)\"]\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/162:\n",
      "# Calculate averages for the desired columns. \n",
      "size_math_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
      "size_reading_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
      "size_passing_math = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
      "size_passing_reading = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
      "size_overall_passing = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]\n",
      "30/163:\n",
      "# Assemble into DataFrame. \n",
      "size_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : size_math_scores,\n",
      "          \"Average Reading Score\": size_reading_scores,\n",
      "          \"% Passing Math\": size_passing_math,\n",
      "          \"% Passing Reading\": size_passing_reading,\n",
      "          \"% Overall Passing\": size_overall_passing})\n",
      "size_summary_df\n",
      "30/164:\n",
      "# Format the DataFrame  \n",
      "# Format average math score to one decimal place.\n",
      "size_summary_df[\"Average Math Score\"] = size_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format average reading score to one decimal place.\n",
      "size_summary_df[\"Average Reading Score\"] = size_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentages of students who passed math and reading, and the overall passing percentage to nearest whole number.\n",
      "size_summary_df[\"% Passing Math\"] = size_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Passing Reading\"] = size_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Overall Passing\"] = size_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "size_summary_df\n",
      "30/165:\n",
      "# Calculate averages for the desired columns. \n",
      "type_math_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Math Score\"]\n",
      "type_reading_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Reading Score\"]\n",
      "type_passing_math = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Math\"]\n",
      "type_passing_reading = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Reading\"]\n",
      "type_overall_passing = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Overall Passing\"]\n",
      "30/166:\n",
      "# Assemble into DataFrame. \n",
      "type_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : type_math_scores,\n",
      "          \"Average Reading Score\": type_reading_scores,\n",
      "          \"% Passing Math\": type_passing_math,\n",
      "          \"% Passing Reading\": type_passing_reading,\n",
      "          \"% Overall Passing\": type_overall_passing})\n",
      "type_summary_df\n",
      "30/167:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "school_data_to_load=os.path.join(\"Resources\", \"schools_complete.csv\")\n",
      "student_data_to_load=os.path.join(\"Resources\", \"students_complete.csv\")\n",
      "\n",
      "# Read the School Data and Student Data and store into a Pandas DataFrame\n",
      "school_data_df = pd.read_csv(school_data_to_load)\n",
      "student_data_df = pd.read_csv(student_data_to_load)\n",
      "\n",
      "# Cleaning Student Names and Replacing Substrings in a Python String\n",
      "# Add each prefix and suffix to remove to a list.\n",
      "prefixes_suffixes = [\"Dr. \", \"Mr. \",\"Ms. \", \"Mrs. \", \"Miss \", \" MD\", \" DDS\", \" DVM\", \" PhD\"]\n",
      "\n",
      "# Iterate through the words in the \"prefixes_suffixes\" list and replace them with an empty space, \"\".\n",
      "for word in prefixes_suffixes:\n",
      "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
      "\n",
      "# Check names.\n",
      "student_data_df.head(10)\n",
      "30/168:\n",
      "# Install numpy using conda install numpy or pip install numpy. \n",
      "# Step 1. Import numpy as np.\n",
      "import numpy as np\n",
      "30/169:\n",
      "# Step 2. Use the loc method on the student_data_df to select all the reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "# Set school name to Thomas High School.\n",
      "student_data_df[\"school_name\"]==\"Thomas High School\"\n",
      "# Set grade to 9th garde\n",
      "student_data_df[\"grade\"]==\"9th\"\n",
      "# Select reading scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"reading_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/170:\n",
      "#  Step 3. Refactor the code in Step 2 to replace the math scores with NaN.\n",
      "# Select math scores from the 9th grade at Thomas High School and replace them with NaN.\n",
      "student_data_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(student_data_df[\"grade\"]==\"9th\"), \"math_score\"]=np.nan\n",
      "#student_data_df\n",
      "30/171:\n",
      "#  Step 4. Check the student data for NaN's. \n",
      "student_data_df.tail(10)\n",
      "30/172:\n",
      "# Combine the data into a single dataset\n",
      "school_data_complete_df = pd.merge(student_data_df, school_data_df, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
      "school_data_complete_df.head()\n",
      "30/173:\n",
      "# Calculate the Totals (Schools and Students)\n",
      "school_count = len(school_data_complete_df[\"school_name\"].unique())\n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Calculate the Total Budget\n",
      "total_budget = school_data_df[\"budget\"].sum()\n",
      "30/174:\n",
      "# Calculate the Average Scores using the \"clean_student_data\".\n",
      "average_reading_score = school_data_complete_df[\"reading_score\"].mean()\n",
      "average_math_score = school_data_complete_df[\"math_score\"].mean()\n",
      "30/175:\n",
      "# Step 1. Get the number of students that are in ninth grade at Thomas High School.\n",
      "# These students have no grades. \n",
      "ths_9=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]==\"9th\"), \"Student ID\"].count()\n",
      "# Get the total student count \n",
      "student_count = school_data_complete_df[\"Student ID\"].count()\n",
      "# Step 2. Subtract the number of students that are in ninth grade at \n",
      "# Thomas High School from the total student count to get the new total student count.\n",
      "new_total_student_count=student_count-ths_9\n",
      "30/176:\n",
      "# Calculate the passing rates using the \"clean_student_data\".\n",
      "passing_math_count = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
      "passing_reading_count = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)].count()[\"student_name\"]\n",
      "30/177:\n",
      "# Step 3. Calculate the passing percentages with the new total student count.\n",
      "passing_math_percentage = passing_math_count / float(new_total_student_count) * 100\n",
      "passing_reading_percentage = passing_reading_count / float(new_total_student_count) * 100\n",
      "30/178:\n",
      "# Calculate the students who passed both reading and math.\n",
      "passing_math_reading = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students that passed both reading and math.\n",
      "overall_passing_math_reading_count = passing_math_reading[\"student_name\"].count()\n",
      "\n",
      "\n",
      "# Step 4.Calculate the overall passing percentage with new total student count.\n",
      "overall_passing_percentage = overall_passing_math_reading_count / new_total_student_count * 100\n",
      "30/179:\n",
      "# Create a DataFrame\n",
      "district_summary_df = pd.DataFrame(\n",
      "          [{\"Total Schools\": school_count, \n",
      "          \"Total Students\": student_count, \n",
      "          \"Total Budget\": total_budget,\n",
      "          \"Average Math Score\": average_math_score, \n",
      "          \"Average Reading Score\": average_reading_score,\n",
      "          \"% Passing Math\": passing_math_percentage,\n",
      "         \"% Passing Reading\": passing_reading_percentage,\n",
      "        \"% Overall Passing\": overall_passing_percentage}])\n",
      "\n",
      "\n",
      "\n",
      "# Format the \"Total Students\" to have the comma for a thousands separator.\n",
      "district_summary_df[\"Total Students\"] = district_summary_df[\"Total Students\"].map(\"{:,}\".format)\n",
      "# Format the \"Total Budget\" to have the comma for a thousands separator, a decimal separator and a \"$\".\n",
      "district_summary_df[\"Total Budget\"] = district_summary_df[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
      "# Format the columns.\n",
      "district_summary_df[\"Average Math Score\"] = district_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"Average Reading Score\"] = district_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Math\"] = district_summary_df[\"% Passing Math\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Passing Reading\"] = district_summary_df[\"% Passing Reading\"].map(\"{:.1f}\".format)\n",
      "district_summary_df[\"% Overall Passing\"] = district_summary_df[\"% Overall Passing\"].map(\"{:.1f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "district_summary_df\n",
      "30/180:\n",
      "# Determine the School Type\n",
      "per_school_types = school_data_df.set_index([\"school_name\"])[\"type\"]\n",
      "\n",
      "# Calculate the total student count.\n",
      "per_school_counts = school_data_complete_df[\"school_name\"].value_counts()\n",
      "\n",
      "# Calculate the total school budget and per capita spending\n",
      "per_school_budget = school_data_complete_df.groupby([\"school_name\"]).mean()[\"budget\"]\n",
      "# Calculate the per capita spending.\n",
      "per_school_capita = per_school_budget / per_school_counts\n",
      "\n",
      "# Calculate the average test scores.\n",
      "per_school_math = school_data_complete_df.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "per_school_reading = school_data_complete_df.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "\n",
      "# Calculate the passing scores by creating a filtered DataFrame.\n",
      "per_school_passing_math = school_data_complete_df[(school_data_complete_df[\"math_score\"] >= 70)]\n",
      "per_school_passing_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_school_passing_math = per_school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "per_school_passing_reading = per_school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_school_passing_math = per_school_passing_math / per_school_counts * 100\n",
      "per_school_passing_reading = per_school_passing_reading / per_school_counts * 100\n",
      "\n",
      "# Calculate the students who passed both reading and math.\n",
      "per_passing_math_reading = school_data_complete_df[(school_data_complete_df[\"reading_score\"] >= 70)\n",
      "                                               & (school_data_complete_df[\"math_score\"] >= 70)]\n",
      "\n",
      "# Calculate the number of students passing math and passing reading by school.\n",
      "per_passing_math_reading = per_passing_math_reading.groupby([\"school_name\"]).count()[\"student_name\"]\n",
      "\n",
      "# Calculate the percentage of passing math and reading scores per school.\n",
      "per_overall_passing_percentage = per_passing_math_reading / per_school_counts * 100\n",
      "30/181:\n",
      "# Create the DataFrame\n",
      "per_school_summary_df = pd.DataFrame({\n",
      "    \"School Type\": per_school_types,\n",
      "    \"Total Students\": per_school_counts,\n",
      "    \"Total School Budget\": per_school_budget,\n",
      "    \"Per Student Budget\": per_school_capita,\n",
      "    \"Average Math Score\": per_school_math,\n",
      "    \"Average Reading Score\": per_school_reading,\n",
      "    \"% Passing Math\": per_school_passing_math,\n",
      "    \"% Passing Reading\": per_school_passing_reading,\n",
      "    \"% Overall Passing\": per_overall_passing_percentage})\n",
      "\n",
      "\n",
      "per_school_summary_df\n",
      "30/182:\n",
      "# Format the Total School Budget and the Per Student Budget\n",
      "per_school_summary_df[\"Total School Budget\"] = per_school_summary_df[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
      "per_school_summary_df[\"Per Student Budget\"] = per_school_summary_df[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
      "\n",
      "# Display the data frame\n",
      "per_school_summary_df.head()\n",
      "30/183:\n",
      "# Step 5.  Get the number of 10th-12th graders from Thomas High School (THS).\n",
      "ths_10_12=student_data_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"grade\"]!=\"9th\"), \"Student ID\"].count()\n",
      "ths_10_12\n",
      "30/184:\n",
      "# Step 6. Get all the students passing math from THS\n",
      "ths_passing_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"math_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_passing_math_count\n",
      "30/185:\n",
      "# Step 7. Get all the students passing reading from THS\n",
      "ths_reading_math_count = school_data_complete_df.loc[(student_data_df[\"school_name\"]==\"Thomas High School\")&(school_data_complete_df[\"reading_score\"] >= 70), \"Student ID\"].count()\n",
      "ths_reading_math_count\n",
      "30/186:\n",
      "# Step 8. Get all the students passing math and reading from THS\n",
      "ths_passing_math_reading = school_data_complete_df.loc[(school_data_complete_df[\"school_name\"]==\"Thomas High School\") & (school_data_complete_df[\"math_score\"] >= 70) & (school_data_complete_df[\"reading_score\"] >= 70),\"Student ID\"].count()\n",
      "ths_passing_math_reading\n",
      "30/187:\n",
      "# Step 9. Calculate the percentage of 10th-12th grade students passing math from Thomas High School. \n",
      "ths_passing_math_percentage= ths_passing_math_count/float(ths_10_12) * 100\n",
      "ths_passing_math_percentage\n",
      "30/188:\n",
      "# Step 10. Calculate the percentage of 10th-12th grade students passing reading from Thomas High School.\n",
      "ths_passing_reading_percentage= ths_reading_math_count/float(ths_10_12) * 100\n",
      "ths_passing_reading_percentage\n",
      "30/189:\n",
      "# Step 11. Calculate the overall passing percentage of 10th-12th grade from Thomas High School. \n",
      "ths_overall_passing_percentage=ths_passing_math_reading/ths_10_12 * 100\n",
      "ths_overall_passing_percentage\n",
      "30/190:\n",
      "# Step 12. Replace the passing math percent for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Math\"]=ths_passing_math_percentage\n",
      "30/191:\n",
      "# Step 13. Replace the passing reading percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Passing Reading\"]=ths_passing_reading_percentage\n",
      "30/192:\n",
      "# Step 14. Replace the overall passing percentage for Thomas High School in the per_school_summary_df.\n",
      "per_school_summary_df.loc[\"Thomas High School\", \"% Overall Passing\"]=ths_overall_passing_percentage\n",
      "30/193: per_school_summary_df\n",
      "30/194:\n",
      "# Sort and show top five schools.\n",
      "top_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=False)\n",
      "top_schools.head()\n",
      "30/195:\n",
      "# Sort and show lowest five schools.\n",
      "bottom_schools = per_school_summary_df.sort_values([\"% Overall Passing\"], ascending=True)\n",
      "bottom_schools.head()\n",
      "30/196:\n",
      "# Create a Series of scores by grade levels using conditionals.\n",
      "ninth_graders =school_data_complete_df[(school_data_complete_df[\"grade\"] == \"9th\")]\n",
      "tenth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"10th\")]\n",
      "eleventh_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"11th\")]\n",
      "twelfth_graders = school_data_complete_df[(school_data_complete_df[\"grade\"] == \"12th\")]\n",
      "# Group each school Series by the school name for the average math score.\n",
      "ninth_grade_math_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "tenth_grade_math_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "eleventh_grade_math_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "twelfth_grade_math_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"math_score\"]\n",
      "# Group each school Series by the school name for the average reading score.\n",
      "ninth_grade_reading_scores = ninth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "tenth_grade_reading_scores = tenth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "eleventh_grade_reading_scores = eleventh_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "twelfth_grade_reading_scores = twelfth_graders.groupby([\"school_name\"]).mean()[\"reading_score\"]\n",
      "30/197:\n",
      "# Combine each Series for average math scores by school into single data frame.\n",
      "math_scores_by_grade = pd.DataFrame({\n",
      "               \"9th\": ninth_grade_math_scores,\n",
      "               \"10th\": tenth_grade_math_scores,\n",
      "               \"11th\": eleventh_grade_math_scores,\n",
      "               \"12th\": twelfth_grade_math_scores})\n",
      "#math_scores_by_grade.head()\n",
      "30/198:\n",
      "# Combine each Series for average reading scores by school into single data frame.\n",
      "reading_scores_by_grade = pd.DataFrame({\n",
      "              \"9th\": ninth_grade_reading_scores,\n",
      "              \"10th\": tenth_grade_reading_scores,\n",
      "              \"11th\": eleventh_grade_reading_scores,\n",
      "              \"12th\": twelfth_grade_reading_scores})\n",
      "#reading_scores_by_grade.head()\n",
      "30/199:\n",
      "# Format each grade column.\n",
      "# math_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "math_scores_by_grade[\"9th\"] = math_scores_by_grade[\"9th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"10th\"] = math_scores_by_grade[\"10th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"11th\"] = math_scores_by_grade[\"11th\"].map(\"{:.1f}\".format)\n",
      "math_scores_by_grade[\"12th\"] = math_scores_by_grade[\"12th\"].map(\"{:.1f}\".format)\n",
      "30/200:\n",
      "# Remove the index.\n",
      "math_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "math_scores_by_grade\n",
      "30/201:\n",
      "# reading_scores_by_grade format each grade column to one decimal place, remove name of the index column school_name.\n",
      "reading_scores_by_grade[\"9th\"] = reading_scores_by_grade[\"9th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"10th\"] = reading_scores_by_grade[\"10th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"11th\"] = reading_scores_by_grade[\"11th\"].map(\"{:,.1f}\".format)\n",
      "reading_scores_by_grade[\"12th\"] = reading_scores_by_grade[\"12th\"].map(\"{:,.1f}\".format)\n",
      "# Remove the index.\n",
      "reading_scores_by_grade.index.name = None\n",
      "# Display the data frame\n",
      "reading_scores_by_grade\n",
      "30/202:\n",
      "# Establish the spending bins and group names.\n",
      "# Get descriptive statistics for per_school_capita.\n",
      "per_school_capita.describe()\n",
      "## Assign variable for ranges.\n",
      "spending_bins = [0, 585, 630, 645, 675]\n",
      "# Label ranges using list of string values.\n",
      "group_names = [\"<$586\", \"$586-630\", \"$631-645\", \"$646-675\"]\n",
      "# Determine how many schools are in each range.\n",
      "per_school_capita.groupby(pd.cut(per_school_capita, spending_bins)).count()\n",
      "# Categorize spending based on the bins.\n",
      "# Create new \"Spending Ranges (Per Student)\" column in the per_school_summary_df, use cut() on per_school_capita Series to add bin data as new column.\n",
      "per_school_summary_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_capita, spending_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/203:\n",
      "# Calculate averages for the desired columns. \n",
      "# Assign variables and create Series and calculate averages for desired columns.\n",
      "spending_math_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
      "spending_reading_scores = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
      "spending_passing_math = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
      "spending_passing_reading = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
      "overall_passing_spending = per_school_summary_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]\n",
      "overall_passing_spending\n",
      "30/204:\n",
      "# Create the DataFrame\n",
      "# Assign variable for new DataFrame and add series.\n",
      "spending_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : spending_math_scores,\n",
      "          \"Average Reading Score\": spending_reading_scores,\n",
      "          \"% Passing Math\": spending_passing_math,\n",
      "          \"% Passing Reading\": spending_passing_reading,\n",
      "          \"% Overall Passing\": overall_passing_spending})\n",
      "spending_summary_df\n",
      "30/205:\n",
      "# Format the DataFrame \n",
      "# Format Average Math Score and Average Reading Score columns to one decimal place.\n",
      "spending_summary_df[\"Average Math Score\"] = spending_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "spending_summary_df[\"Average Reading Score\"] = spending_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format % Passing Math, % Passing Reading, and % overall passing columns to nearest whole number.\n",
      "spending_summary_df[\"% Passing Math\"] = spending_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Passing Reading\"] = spending_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df[\"% Overall Passing\"] = spending_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "spending_summary_df\n",
      "30/206:\n",
      "# Establish the bins.\n",
      "size_bins = [0, 999, 1999, 5000]\n",
      "group_names = [\"Small (<1000)\", \"Medium (1000-1999)\", \"Large (2000-5000)\"]\n",
      "# Categorize spending based on the bins.\n",
      "# added a new column: \"School Size\" to per_school_summary_df DataFrame, use the cut() function on the per_school_summary_df DataFrame column: \"Total Students\", group the student size in the size_bins, adde labels=group_names labels.\n",
      "per_school_summary_df[\"School Size\"] = pd.cut(per_school_summary_df[\"Total Students\"], size_bins, labels=group_names)\n",
      "per_school_summary_df.head()\n",
      "30/207:\n",
      "# Calculate averages for the desired columns. \n",
      "size_math_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
      "size_reading_scores = per_school_summary_df.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
      "size_passing_math = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
      "size_passing_reading = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
      "size_overall_passing = per_school_summary_df.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]\n",
      "30/208:\n",
      "# Assemble into DataFrame. \n",
      "size_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : size_math_scores,\n",
      "          \"Average Reading Score\": size_reading_scores,\n",
      "          \"% Passing Math\": size_passing_math,\n",
      "          \"% Passing Reading\": size_passing_reading,\n",
      "          \"% Overall Passing\": size_overall_passing})\n",
      "size_summary_df\n",
      "30/209:\n",
      "# Format the DataFrame  \n",
      "# Format average math score to one decimal place.\n",
      "size_summary_df[\"Average Math Score\"] = size_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "# Format average reading score to one decimal place.\n",
      "size_summary_df[\"Average Reading Score\"] = size_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentages of students who passed math and reading, and the overall passing percentage to nearest whole number.\n",
      "size_summary_df[\"% Passing Math\"] = size_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Passing Reading\"] = size_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "size_summary_df[\"% Overall Passing\"] = size_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "size_summary_df\n",
      "30/210:\n",
      "# Calculate averages for the desired columns. \n",
      "type_math_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Math Score\"]\n",
      "type_reading_scores = per_school_summary_df.groupby([\"School Type\"]).mean()[\"Average Reading Score\"]\n",
      "type_passing_math = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Math\"]\n",
      "type_passing_reading = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Passing Reading\"]\n",
      "type_overall_passing = per_school_summary_df.groupby([\"School Type\"]).mean()[\"% Overall Passing\"]\n",
      "30/211:\n",
      "# Assemble into DataFrame. \n",
      "type_summary_df = pd.DataFrame({\n",
      "          \"Average Math Score\" : type_math_scores,\n",
      "          \"Average Reading Score\": type_reading_scores,\n",
      "          \"% Passing Math\": type_passing_math,\n",
      "          \"% Passing Reading\": type_passing_reading,\n",
      "          \"% Overall Passing\": type_overall_passing})\n",
      "type_summary_df\n",
      "30/212:\n",
      "# Format the DataFrame \n",
      "# Format average math and reading scores to one decimal place.\n",
      "type_summary_df[\"Average Math Score\"] = type_summary_df[\"Average Math Score\"].map(\"{:.1f}\".format)\n",
      "type_summary_df[\"Average Reading Score\"] = type_summary_df[\"Average Reading Score\"].map(\"{:.1f}\".format)\n",
      "# Format percentage of students who passed math and reading, and the overall passing percentage to the nearest whole number.\n",
      "type_summary_df[\"% Passing Math\"] = type_summary_df[\"% Passing Math\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Passing Reading\"] = type_summary_df[\"% Passing Reading\"].map(\"{:.0f}\".format)\n",
      "type_summary_df[\"% Overall Passing\"] = type_summary_df[\"% Overall Passing\"].map(\"{:.0f}\".format)\n",
      "type_summary_df\n",
      "33/1:\n",
      "# Display chart within file's cell.\n",
      "%matplotlib inline\n",
      "33/2:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "33/3:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "33/4:\n",
      "# Create the plot\n",
      "plt.plot(x_axis, y_axis)\n",
      "33/5:\n",
      "## Create a Line Chart Using the Object-Oriented Interface.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "33/6:\n",
      "# Create the plot with ax.plt()\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "33/7:\n",
      "# Create the plot with ax.plt(), Option 2\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "33/8:\n",
      "# Create the plot with ax.plt()\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "33/9:\n",
      "# Use fig = plt.figure() to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "33/10:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "33/11:\n",
      "# Use fig = plt.figure() to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/1:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label='Boston')\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/2:\n",
      "# Display chart within file's cell.\n",
      "%matplotlib inline\n",
      "34/3:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "34/4:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/5:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/6:\n",
      "## Create a Line Chart Using the Object-Oriented Interface.\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/7:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/8:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/9:\n",
      "# Use fig = plt.figure() to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/10:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label='Boston')\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/11:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"*\", color=\"blue\", linewidth=2, label='Boston')\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/12:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label='Boston')\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/13:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/14:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/15:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label='Boston')\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/16:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/17:\n",
      "# To switch the data on the axes, use .barh(Y,X):\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/18:\n",
      "# .gca(): Switches/Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis)\n",
      "plt.gca().invert_yaxis()\n",
      "34/19:\n",
      "# .gca(): Switches/Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, , color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/20:\n",
      "# .gca(): Switches/Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/21:\n",
      "# .gca(): Switches/Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/22:\n",
      "# Create Bar Charts Using the Object-Oriented Approach.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/23:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/24:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/25:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/26:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "fig, ax = plt.subplots(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/27:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "#fig, ax = plt.subplots(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "34/28:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "#fig, ax = plt.subplots(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "34/29:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "#fig, ax = plt.subplots(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "34/30:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "#fig, ax = plt.subplots(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "fig, ax = plt.subplots()\n",
      "fig, ax.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "34/31:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "# Use fig = plt.figure() to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure(color=\"cyan\", label='Chicago')\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/32:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig, ax = plt.subplots(color=\"cyan\", label='Chicago')\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/33:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig, ax = plt.subplots(figure=(color=\"cyan\", label='Chicago'))\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/34:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig, ax = plt.subplots((color=\"cyan\"), (label='Chicago'))\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/35:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig, ax = plt.subplots((color \"cyan\"), (label 'Chicago'))\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/36:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "34/37:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "ax.ylabel(\"Date\")\n",
      "34/38:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "plt.ylabel(\"Date\")\n",
      "34/39:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/40:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/41:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/42:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "plt.barh(color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/43:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "plt.barh(x_axis, y_axis, color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/44:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "ax.barh(color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/45:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/46:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, label=\"chicago\")\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/47:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.legend(\"chicago\")\n",
      "fig = plt.figure() \n",
      "#Add a title and axes labels.\n",
      "34/48:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.legend(\"chicago\")\n",
      "#Add a title and axes labels.\n",
      "34/49:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.barh.legend(\"chicago\")\n",
      "#Add a title and axes labels.\n",
      "34/50:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()(color=\"cyan\")\n",
      "ax.barh(x_axis, y_axis)\n",
      "ax.barh(\"chicago\")\n",
      "#Add a title and axes labels.\n",
      "34/51:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()(color=\"cyan\")\n",
      "ax.barh(x_axis, y_axis)\n",
      "#Add a title and axes labels.\n",
      "34/52:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.barh.legend()\n",
      "#Add a title and axes labels.\n",
      "34/53:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.barh.legend(label=\"Boston\")\n",
      "#Add a title and axes labels.\n",
      "34/54:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.barh.legend(\"Boston\")\n",
      "#Add a title and axes labels.\n",
      "34/55:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.legend(\"Boston\")\n",
      "#Add a title and axes labels.\n",
      "34/56:\n",
      "# Display chart within file's cell.\n",
      "%matplotlib inline\n",
      "34/57:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "34/58:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/59:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/60:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/61:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/62:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/63:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/64:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/65:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/66:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/67:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/68:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/69:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/70:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/71:\n",
      "# .gca(): Switches/Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label=\"Boston\")\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/72:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/73:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/74:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.legend(\"Boston\")\n",
      "#Add a title and axes labels.\n",
      "34/75:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.plot(x, y, label='line')\n",
      "#Add a title and axes labels.\n",
      "34/76:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.plot(x, y, label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "34/77:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.plot(label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "34/78:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.plot(x_axis, y_axis, label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "34/79:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\")\n",
      "ax.barh(x_axis, y_axis, label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "34/80:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "34/81:\n",
      "# .gca(): Switches/Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label=\"Boston\")\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/82:\n",
      "# .gca(): Switches/Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/83:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/84:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/85:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/86:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "# Use fig = plt.subplots(figure=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "# Change the bar color to cyan, a legend for the city of Chicago.plt.xlabel(\"Fare($)\")fig, ax = plt.subplots()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "plt.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Create the plot and add a label for the legend.\n",
      "#plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "#plt.xlabel(\"Date\")\n",
      "#plt.ylabel(\"Fare($)\")\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "34/87:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add  legend for the city of Chicago\n",
      "ax.legend()\n",
      "34/88:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add  legend for the city of Chicago\n",
      "ax.legend()\n",
      "34/89:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label='Chicago')\n",
      "#Add a title and axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Add  legend for the city of Chicago\n",
      "ax.legend()\n",
      "34/90:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "#Add a title and axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Add  legend for the city of Chicago\n",
      "ax.legend()\n",
      "34/91:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "34/92:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "34/93:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/94:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/95:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/96: plt.plot(x_axis, y_axis, 'o')\n",
      "34/97:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "plt.scatter(x_axis, y_axis)\n",
      "34/98:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.set_xlabel(\"Fare($)\")\n",
      "plt.set_ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/99:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.set_xlabel(\"Fare($)\")\n",
      "plt.set_ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/100:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/101:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/102:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Invert the y-axis data.\n",
      "ax.gca().invert_yaxis()\n",
      "34/103:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "34/104:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "# plt.gca().invert_yaxis()\n",
      "34/105:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/106:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/107:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/108:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/109:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/110: plt.plot(x_axis, y_axis, 'o')\n",
      "34/111:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/112:\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/113:\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/114:\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x, y, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/115:\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/116:\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/117:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/118:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/119:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/120:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.ylabel(\"Fare($)\")\n",
      "plt.xlabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/121:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.ylabel(\"Fare($)\")\n",
      "plt.xlabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/122:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.ylabel(\"Fare($)\")\n",
      "plt.xlabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/123:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/124:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/125:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/126:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/127:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "#plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/128:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/129:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/130:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/131:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red and add a limit for the x-axis data.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/132:\n",
      "# Display chart within file's cell.\n",
      "%matplotlib inline\n",
      "34/133:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "34/134:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/135:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/136:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/137:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/138:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/139:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/140:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/141:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/142:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/143:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/144:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/145:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/146:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/147:\n",
      "# .gca(): Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/148:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/149:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/150:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "34/151:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/152:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/153: plt.plot(x_axis, y_axis, 'o')\n",
      "34/154:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/155:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/156:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.plot(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/157:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "#plt.show()\n",
      "34/158:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/159:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, c=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/160:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/161:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/162: plt.plot(x_axis, y_axis, 'o')\n",
      "34/163:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/164:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/165: plt.scatter(x_axis, y_axis)\n",
      "34/166:\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/167:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "34/168:\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/169:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/170: plt.plot(x_axis, y_axis, 'o')\n",
      "34/171:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(x_axis, y_axis)\n",
      "34/172:\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/173:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/174: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/175:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(x_axis, y_axis)\n",
      "34/176:\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/177:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "34/178:\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/179:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/180: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/181:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/182:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "# Import additional dependencies\n",
      "import random\n",
      "import numpy as np\n",
      "34/183:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/184:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/185:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/186:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/187:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/188:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/189:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/190:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/191:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/192:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/193:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/194:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/195:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/196:\n",
      "# .gca(): Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/197:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/198:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/199:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "34/200:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/201:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/202: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/203:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"r\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/204:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "plt.ylim()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/205:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, marker=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/206:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/207:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "#plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/208:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/209:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/210: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/211:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/212:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/213: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/214:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/215:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/216: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/217:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/218:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/219: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/220:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/221:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/222: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/223:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/224:\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/225:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "\n",
      "plt.show()\n",
      "34/226:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.show()\n",
      "34/227:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/228:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/229:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/230:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/231:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/232:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/233:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/234:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/235:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/236:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/237:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/238:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/239:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/240:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/241:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/242:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "plt.show()\n",
      "34/243:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "plt.show()\n",
      "34/244:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/245:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/246:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "plt.show()\n",
      "34/247:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "plt.show()\n",
      "34/248:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "plt.show()\n",
      "34/249:\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/250:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/251:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/252: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/253:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/254:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/255: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/256:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "\n",
      "\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "34/257:\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/258:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "34/259:\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/260:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "34/261:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "34/262:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/263:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_xaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/264:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_xaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(x_axis, x_axis)\n",
      "34/265:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_xaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(x_axis, x_axis)\n",
      "34/266:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/267: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/268:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_xaxis()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(x_axis, x_axis)\n",
      "34/269:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/270: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/271:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(x_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_xaxis()\n",
      "34/272:\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.ylim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/273:\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/274:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "34/275:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "34/276:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "34/277:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/278:\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/279:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(x_axis, y_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/280:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/281:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/282:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/283: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/284:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/285:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "34/286:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "34/287:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/288:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(x_axis, y_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/289:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/290:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/291:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis,  color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/292:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis,  color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/293:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis,  color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/294:\n",
      "# Display chart within file's cell.\n",
      "%matplotlib inline\n",
      "34/295:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "# Import additional dependencies\n",
      "import random\n",
      "import numpy as np\n",
      "34/296:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/297:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/298:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/299:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/300:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/301:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/302:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/303:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/304:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/305:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/306:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/307:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/308:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/309:\n",
      "# .gca(): Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/310:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/311:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/312:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "34/313:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/314:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/315: #plt.plot(x_axis, y_axis, 'o')\n",
      "34/316:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis,  color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/317:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, label=\"Chicago\", color=\"red\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/318:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "34/319:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "# Multiply each data point in the y-axis by 3.\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*3)\n",
      "34/320:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "34/321:\n",
      "# Multiply each data point in the y-axis by 3.\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*3)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "34/322:\n",
      "# Refactor code, list comprehension, s = [i * 3 for i in y_axis].\n",
      "plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])\n",
      "34/323:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "ax.scatter(x_axis, y_axis)\n",
      "34/324:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], facecolors=\"sky blue\", edgecolors=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/325:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], c=\"sky blue\", edgecolors=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/326:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis, color=\"sky blue\", edgecolors=\"black\", lw=2, alpha=20], label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/327:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], color=\"sky blue\", edgecolors=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/328:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], facecolor=\"sky blue\", edgecolor=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/329:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], facecolor=colors[\"sky blue\"], edgecolor=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/330:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], facecolor=color[\"sky blue\"], edgecolor=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/331:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], facecolor=[\"sky blue\"], edgecolor=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/332:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "# Add a title.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], facecolor=[\"sky blue\"], edgecolor=\"black\", lw=2, alpha=20, label=\"Chicago\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Add a legend for the city of Boston.\n",
      "ax=fig.add_subplot (title=\"PyBer Fare by Month\")\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/333:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], facecolor=[\"sky blue\"], edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/334:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], color=[\"sky blue\"], edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/335:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 5 for i in y_axis], color=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/336:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], color=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/337:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], c=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/338:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], c=\"blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/339:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], c=\"light blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/340:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], facecolor=colors[sky blue], edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/341:\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], facecolor=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/342:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], facecolor=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/343:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "#ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], facecolor=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/344:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "#plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "#ax.scatter(x_axis, y_axis, s=[i * 5 for i in y_axis], facecolor=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/345:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "#plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis,facecolor=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/346:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "#plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, color=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/347:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, color=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/348:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "#ax.plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, color=\"sky blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/349:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "#ax.plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, color=\"blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/350:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "#ax.plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, facecolor=\"blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Chicago\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/351:\n",
      "import matplotlib.colors as mcolors\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "#ax.plot_colortable(mcolors.CSS4_COLORS)\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, facecolor=\"blue\", edgecolor=\"black\", lw=2, alpha=.20, label=\"Boston\")\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*5)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/352:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "34/353:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/354:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, label=\"Chicago\", color=\"red\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/355:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to red.\n",
      "plt.scatter(y_axis, x_axis, label=\"Chicago\", color=\"red\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/356:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", label=\"Chicago\", color=\"red\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "\n",
      "\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/357:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "\n",
      "\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "34/358:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/359:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, facecolor=\"#75bbfd\", alpha=.2, edgecolor=\"black\", lw=2, label=\"Boston\")\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/360:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "\n",
      "\n",
      "\n",
      "ax.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis], facecolor=\"#75bbfd\", alpha=.2, edgecolor=\"black\", lw=2, label=\"Boston\")\n",
      "\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "\n",
      "# Add a limit for the x-axis data.\n",
      "\n",
      "# Invert the y-axis so that January is at the top.\n",
      "34/361:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(x_axis, \n",
      "           y_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\", lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/362:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(x_axis, y_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\", lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/363:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\", lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/364:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis, s=x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in x_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/365:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis, s=x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/366:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/367:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/368:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/369:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/370:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "\n",
      "\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/371:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/372:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/373:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/374:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/375: plt.plot(x_axis, y_axis, 'o')\n",
      "34/376:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "34/377:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/378:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "34/379:\n",
      "# Multiply each data point in the y-axis by 3.\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*3)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "34/380:\n",
      "# Refactor code, list comprehension, s = [i * 3 for i in y_axis].\n",
      "plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])\n",
      "34/381:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/382:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/383:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "# Import additional dependencies\n",
      "import random\n",
      "import numpy as np\n",
      "import matplotlib.colors as mcolors\n",
      "34/384:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/385:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/386:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/387:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/388:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/389:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/390:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/391:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/392:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/393:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/394:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/395:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/396:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/397:\n",
      "# .gca(): Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/398:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/399:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/400:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/401:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/402:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/403: plt.plot(x_axis, y_axis, 'o')\n",
      "34/404:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "34/405:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/406:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "34/407:\n",
      "# Multiply each data point in the y-axis by 3.\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*3)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "34/408:\n",
      "# Refactor code, list comprehension, s = [i * 3 for i in y_axis].\n",
      "plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])\n",
      "34/409:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"#75bbfd\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/410:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/411:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/412:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "# Import additional dependencies\n",
      "import random\n",
      "import numpy as np\n",
      "#import matplotlib.colors as mcolors\n",
      "34/413:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/414:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/415:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/416:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/417:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/418:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/419:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/420:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/421:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/422:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/423:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/424:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/425:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/426:\n",
      "# .gca(): Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/427:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/428:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/429:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/430:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/431:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/432: plt.plot(x_axis, y_axis, 'o')\n",
      "34/433:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "34/434:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/435:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "34/436:\n",
      "# Multiply each data point in the y-axis by 3.\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*3)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "34/437:\n",
      "# Refactor code, list comprehension, s = [i * 3 for i in y_axis].\n",
      "plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])\n",
      "34/438:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "34/439:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/440:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plot_colortable(mcolors.CSS4_COLORS)\n",
      "plt.show()\n",
      "34/441:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "ax.plot_colortable(mcolors.CSS4_COLORS)\n",
      "plt.show()\n",
      "34/442:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/443:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=.2,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/444:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/445:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/446:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           c=x,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/447:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           c=x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/448:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           color=x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/449:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "# Import additional dependencies\n",
      "import random\n",
      "import numpy as np\n",
      "import matplotlib.colors as mcolors\n",
      "import seaborn as sns\n",
      "34/450:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/451:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/452:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/453:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/454:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/455:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/456:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/457:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/458:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/459:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/460:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/461:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/462:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/463:\n",
      "# .gca(): Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/464:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/465:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/466:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/467:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/468:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/469: plt.plot(x_axis, y_axis, 'o')\n",
      "34/470:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "34/471:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/472:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "34/473:\n",
      "# Multiply each data point in the y-axis by 3.\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*3)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "34/474:\n",
      "# Refactor code, list comprehension, s = [i * 3 for i in y_axis].\n",
      "plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])\n",
      "34/475:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           color=x_axis,\n",
      "           cmap=\"Blues\"\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/476:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           color=x_axis,\n",
      "           cmap=\"Blues\"\n",
      "           #facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/477:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           color=x_axis,\n",
      "           cmap=\"Blues\"\n",
      "           #facecolor=\"skyblue\",\n",
      "           edgecolors=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/478:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolors=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/479:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           #facecolor=\"skyblue\",\n",
      "           edgecolors=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/480:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=.2,\n",
      "           facecolors=\"skyblue\",\n",
      "           edgecolors=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/481:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           facecolors=\"skyblue\",\n",
      "           edgecolors=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/482:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           facecolors=\"skyblue\",\n",
      "           edgecolors=\"k\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/483:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           color=\"skyblue\",\n",
      "           edgecolors=\"k\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/484:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis, s=y_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           color=\"skyblue\",\n",
      "           edgecolors=\"k\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/485:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           color=\"skyblue\",\n",
      "           edgecolors=\"k\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/486:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"k\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/487:\n",
      "# Display chart within file's cell.\n",
      "%matplotlib inline\n",
      "34/488:\n",
      "# Import matplotlib dependency, from matplotlib import pyplot.\n",
      "import matplotlib.pyplot as plt\n",
      "# Import additional dependencies\n",
      "import random\n",
      "import numpy as np\n",
      "import matplotlib.colors as mcolors\n",
      "import seaborn as sns\n",
      "34/489:\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/490:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "34/491:\n",
      "## Create a Line Chart Using the Object-Oriented Interface. fig, ax = plt.subplots()\n",
      "# Create the plot with ax.plt(), Option 1.\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/492:\n",
      "# Create the plot with ax.plt(), Option 2.\n",
      "# Use fig = plt.subplots(figsize=(w,h)) to change figure-level attributes (such as axis labels, a title, or a legend) or save the figure as an image.\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/493:\n",
      "# Create the plot with ax.plt(), Option 3.\n",
      "ax = plt.axes()\n",
      "ax.plot(x_axis, y_axis)\n",
      "34/494:\n",
      "# Use plt.show() to look for all the active figure objects and open a window that displays them if there are two or more sets of data to plot.\n",
      "# Ex: Create the plot.\n",
      "plt.plot(x_axis, y_axis)\n",
      "plt.show()\n",
      "34/495:\n",
      "# Create the plot and add a label for the legend.\n",
      "plt.plot(x_axis, y_axis, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/496:\n",
      "# Create the plot.\n",
      "plt.plot(x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 45)\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/497:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/498:\n",
      "# Create the plot\n",
      "plt.bar(x_axis, y_axis)\n",
      "34/499:\n",
      "# Annotate bar chart.\n",
      "# Create the plot.\n",
      "plt.bar(x_axis, y_axis, color=\"green\", label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"Date\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Create a title.\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "34/500:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot\n",
      "plt.barh(x_axis, y_axis)\n",
      "34/501:\n",
      "# .barh(Y,X): Switches the data on the axes:\n",
      "# Create the plot\n",
      "plt.barh(y_axis, x_axis)\n",
      "34/502:\n",
      "# .gca(): Inverts the data's order:\n",
      "# Create the plot.\n",
      "plt.barh(x_axis, y_axis, color=\"magenta\", label='Boston')\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "plt.gca().invert_yaxis()\n",
      "34/503:\n",
      "# Create Bar Charts Using the Object-Oriented Approach, fig, ax = plt.subplots()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/504:\n",
      "# Create a Vertical Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis)\n",
      "34/505:\n",
      "# Create a Horizontal Bar Chart.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "# Change the bar color to cyan, add Chicago label.\n",
      "ax.barh(x_axis, y_axis, color=\"cyan\", label=\"Chicago\")\n",
      "# Invert the y-axis data.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add  legend for the city of Chicago.\n",
      "ax.legend()\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "# Add axes labels.\n",
      "ax.set_xlabel(\"Fare($)\")\n",
      "ax.set_ylabel(\"Date\")\n",
      "34/506:\n",
      "# Switch the data on the axes.\n",
      "# Create the plot with ax.plt()\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(y_axis, x_axis)\n",
      "34/507:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.plot()\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "34/508: plt.plot(x_axis, y_axis, 'o')\n",
      "34/509:\n",
      "# Create a Scatter Plot Using the MATLAB Method.plt.scatter()\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "34/510:\n",
      "# Skill Drill, plt.plot()\n",
      "# Change the color of the markers to red.\n",
      "plt.plot(y_axis, x_axis, \"o\", color=\"red\", label=\"Chicago\")\n",
      "# Add a title \"PyBer Fare by Month\".\n",
      "plt.title(\"PyBer Fare by Month\")\n",
      "# Add a legend for the city of Chicago.\n",
      "plt.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "# Add limit for x-axis.\n",
      "plt.xlim(0, 50)\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "34/511:\n",
      "# Create a Bubble Chart Using the MATLAB Method.\n",
      "plt.scatter(x_axis, y_axis,  s=y_axis)\n",
      "34/512:\n",
      "# Multiply each data point in the y-axis by 3.\n",
      "y_axis_larger = []\n",
      "for data in y_axis:\n",
      "  y_axis_larger.append(data*3)\n",
      "# Use the new y-axis list for the s parameter.\n",
      "plt.scatter(x_axis, y_axis, s=y_axis_larger)\n",
      "34/513:\n",
      "# Refactor code, list comprehension, s = [i * 3 for i in y_axis].\n",
      "plt.scatter(x_axis, y_axis, s = [i * 3 for i in y_axis])\n",
      "34/514:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"k\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/515:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in x_axis],\n",
      "           alpha=0.2,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/516:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           facecolor=\"skyblue\",\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/517:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/518:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/519:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           alpha=0.2,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/520:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=0.2,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/521:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=0.2,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           alpha=alpha\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/522:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=0.2,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           alpha=alpha,\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/523:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=0.2,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/524:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "#ax.scatter(y_axis, x_axis)\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=0.2,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "#plt.scatter(y_axis, x_axis)\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/525:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           alpha=0.2,\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/526:\n",
      "# Skill Drill\n",
      "# Create a Scatter Plot Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "# Add the s parameter.\n",
      "# Switch the axis so that the Fare($) data is on the x-axis.\n",
      "# Change the color of the markers to sky blue.\n",
      "# Change the size of the markers to 5 times each data point.\n",
      "# Make the color 20% transparent.\n",
      "# Add a black edge color to the circles.\n",
      "# Make the linewidth of the circles 2 points.\n",
      "ax.scatter(y_axis, \n",
      "           x_axis,\n",
      "           facecolor=\"skyblue\",\n",
      "           s = [i * 5 for i in y_axis],\n",
      "           alpha=0.2,\n",
      "           edgecolor=\"black\",\n",
      "           lw=2, \n",
      "           label=\"Boston\")\n",
      "# Add a title.\n",
      "ax.set_title(\"PyBer Fare by Month\")\n",
      "#Add a legend for the city of Boston.\n",
      "ax.legend()\n",
      "# Add axes labels.\n",
      "plt.xlabel(\"Fare($)\")\n",
      "plt.ylabel(\"Date\")\n",
      "# Add a limit for the x-axis data.\n",
      "plt.xlim(0, 50)\n",
      "# Invert the y-axis so that January is at the top.\n",
      "plt.gca().invert_yaxis()\n",
      "plt.show()\n",
      "34/527:\n",
      "# Create Pie Charts.\n",
      "# Create a Pie Chart Using the MATLAB Method.\n",
      "plt.pie(y_axis, labels=x_axis)\n",
      "plt.show()\n",
      "34/528:\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')\n",
      "34/529:\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "# Assign tuple variable, explode_values\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')\n",
      "plt.show()\n",
      "34/530:\n",
      "# Create Pie Charts.\n",
      "# Create a Pie Chart Using the MATLAB Method.\n",
      "# Increase the size of the pie chart.\n",
      "plt.subplots(figsize=(8, 8))\n",
      "plt.pie(y_axis, labels=x_axis)\n",
      "plt.show()\n",
      "34/531:\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "# Assign tuple variable, explode_values, The length of the tuple should be equal to the number of wedges in the pie chart.\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add the percentage of each wedge on the pie chart, use the autopct parameter and provide the format of one decimal place using .1f%, % before and after the .1f% formats the number as a percentage.\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/532:\n",
      "# Create Pie Charts.\n",
      "# Create a Pie Chart Using the MATLAB Method.\n",
      "# Increase the size of the pie chart.\n",
      "plt.subplots(figsize=(9, 9))\n",
      "plt.pie(y_axis, labels=x_axis)\n",
      "plt.show()\n",
      "34/533:\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "# Assign tuple variable, explode_values, The length of the tuple should be equal to the number of wedges in the pie chart.\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add the percentage of each wedge on the pie chart, use the autopct parameter and provide the format of one decimal place using .1f%, % before and after the .1f% formats the number as a percentage.\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/534:\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "# Assign tuple variable, explode_values, The length of the tuple should be equal to the number of wedges in the pie chart.\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add the percentage of each wedge on the pie chart, use the autopct parameter and provide the format of one decimal place using .1f%, % before and after the .1f% formats the number as a percentage.\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/535:\n",
      "# Increase the size of the pie chart.\n",
      "plt.subplots(figsize=(9, 9))\n",
      "\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "# Assign tuple variable, explode_values, The length of the tuple should be equal to the number of wedges in the pie chart.\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add the percentage of each wedge on the pie chart, use the autopct parameter and provide the format of one decimal place using .1f%, % before and after the .1f% formats the number as a percentage.\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/536:\n",
      "# Create Pie Charts.\n",
      "# Create a Pie Chart Using the MATLAB Method.\n",
      "plt.pie(y_axis, labels=x_axis)\n",
      "plt.show()\n",
      "34/537:\n",
      "# Increase the size of the pie chart.\n",
      "plt.subplots(figsize=(8, 8))\n",
      "\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "# Assign tuple variable, explode_values, The length of the tuple should be equal to the number of wedges in the pie chart.\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add the percentage of each wedge on the pie chart, use the autopct parameter and provide the format of one decimal place using .1f%, % before and after the .1f% formats the number as a percentage.\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/538:\n",
      "# Assign variable with 12 colors, one for each month.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# The \"explode\" parameter offsets the indicated wedge by a fraction of the radius, where \"0\" is zero distance from the center of the pie, and \"1\" is completely outside the diameter of the pie.\n",
      "# Assign tuple variable, explode_values, The length of the tuple should be equal to the number of wedges in the pie chart.\n",
      "explode_values = (0, 0, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Increase the size of the pie chart.\n",
      "plt.subplots(figsize=(8, 8))\n",
      "# Add the percentage of each wedge on the pie chart, use the autopct parameter and provide the format of one decimal place using .1f%, % before and after the .1f% formats the number as a percentage.\n",
      "# Add colors= parameter.\n",
      "plt.pie(y_axis, explode=explode_values, labels=x_axis, colors=colors, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/539:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "fig, ax = plt.subplots()\n",
      "ax.pie(y_axis,labels=x_axis)\n",
      "plt.show()\n",
      "34/540:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top.\n",
      "ax.pie(y_axis,labels=x_axis, shadow=True, startangle=90, autopct='%.1f%%')\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/541:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "ax.pie(y_axis,labels=x_axis, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/542:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8)\n",
      "\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      ")\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "ax.pie(y_axis,labels=x_axis, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/543:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "ax.pie(y_axis,labels=x_axis, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/544:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "plt.pie(y_axis,labels=x_axis, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/545:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "plt.pie(y_axis,labels=x_axis, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/546:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add exploded values\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "plt.pie(y_axis, labels=x_axis, explode_values=explode_values, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/547:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add exploded values\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "ax.pie(y_axis, labels=x_axis, explode_values=explode_values, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/548:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add exploded values\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "plt.pie(y_axis, labels=x_axis, explode_values=explode_values, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/549:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add exploded values\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "plt.pie(y_axis, labels=x_axis, explode=explode_values, shadow=True, startangle=90, counterclock=False, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/550:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add exploded values, explode=explode_values.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "# # Add new colors, colors=colors.\n",
      "plt.pie(y_axis, labels=x_axis, explode=explode_values, shadow=True, startangle=90, counterclock=False, colors=colors, autopct='%.1f%%')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "34/551:\n",
      "# Create a Pie Chart Using the Object-Oriented Interface.\n",
      "# Increase the figure size to 8x8.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "# Add new colors of your own choosing or use the colors from the previous pie chart.\n",
      "colors = [\"slateblue\", \"magenta\", \"lightblue\", \"green\", \"yellowgreen\", \"greenyellow\", \"yellow\", \"orange\", \"gold\", \"indianred\", \"tomato\", \"mistyrose\"]\n",
      "# Explode the two highest percentage months.\n",
      "explode_values = (0, 0, 0.2, 0, 0, 0, 0.2, 0, 0, 0, 0, 0)\n",
      "# Add a percentage to one decimal place to each wedge of the pie.\n",
      "# Add exploded values, explode=explode_values.\n",
      "# Add a shadow, shadow=True.\n",
      "# Add a start angle so that January is at the top, startangle=90.\n",
      "# Reverse the order so that the month order is in a clockwise direction, counterclock=False.\n",
      "# # Add new colors, colors=colors.\n",
      "plt.pie(y_axis, labels=x_axis, explode=explode_values, shadow=True, startangle=90, counterclock=False, colors=colors, autopct='%.1f%%')\n",
      "plt.show()\n",
      "37/1:\n",
      "# Create a line chart with error bars using the MATLAB approach.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "37/2:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "37/3: %matplotlib inline\n",
      "37/4:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import statistics\n",
      "37/5:\n",
      "# Create a line chart with error bars using the MATLAB approach.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "37/6:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "37/7:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "#stdev = statistics.stdev(y_axis)\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "stdev = statistics.stdev(x_axis, y_axis,  yerr=stdev)\n",
      "stdev\n",
      "37/8: %matplotlib inline\n",
      "37/9:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import statistics\n",
      "37/10:\n",
      "# Create a line chart with error bars using the MATLAB approach.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "37/11:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "#stdev = statistics.stdev(y_axis)\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "stdev = statistics.stdev(x_axis, y_axis,  yerr=stdev)\n",
      "stdev\n",
      "37/12:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "plt.errorbar(x_axis, y_axis, yerr=stdev)\n",
      "37/13:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "plt.errorbar(x_axis, y_axis, yerr=stdev)\n",
      "37/14:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "plt.errorbar(x_axis, y_axis, yerr=stdev)\n",
      "plot.show()\n",
      "37/15:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "plt.errorbar(x_axis, y_axis, yerr=stdev)\n",
      "plt.show()\n",
      "37/16:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "# Add capsize= parameter.\n",
      "plt.errorbar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "plt.show()\n",
      "37/17: %matplotlib inline\n",
      "37/18:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import statistics\n",
      "37/19:\n",
      "# Create a line chart with error bars using the MATLAB approach.\n",
      "# Set the x-axis to a list of strings for each month.\n",
      "x_axis = [\"Jan\", \"Feb\", \"Mar\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
      "# Set the y-axis to a list of floats as the total fare in US dollars accumulated for each month.\n",
      "y_axis = [10.02, 23.24, 39.20, 35.42, 32.34, 27.04, 43.82, 10.56, 11.85, 27.90, 20.71, 20.09]\n",
      "37/20:\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "stdev\n",
      "37/21:\n",
      "# Add the x_axis, y_axis, and yerr=stdev to the errorbar function.\n",
      "# Add capsize= parameter.\n",
      "plt.errorbar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "plt.show()\n",
      "37/22:\n",
      "# Add error bars and a capsize using the object-oriented approach.\n",
      "fig, ax = plt.subplots()\n",
      "ax.errorbar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "plt.show()\n",
      "37/23:\n",
      "# Add error bars and caps to a bar chart using the MATLAB approach.\n",
      "plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "37/24:\n",
      "# Create the same graph using the object-oriented approach.\n",
      "fig, ax = plt.subplots()\n",
      "ax.bar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "plt.show()\n",
      "37/25:\n",
      "# Change the Major Ticks.\n",
      "# Use the xticks() function to adjust the major x-axis ticks on a horizontal bar chart.\n",
      "import numpy as np\n",
      "plt.barh(x_axis, y_axis)\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.gca().invert_yaxis()\n",
      "37/26:\n",
      "# Change the Major Ticks.\n",
      "import numpy as np\n",
      "plt.barh(x_axis, y_axis)\n",
      "# Use the xticks() to adjust the major x-axis ticks on a horizontal bar chart.\n",
      "# Use np.arange() to adjust the major ticks on the x-axis.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.gca().invert_yaxis()\n",
      "37/27:\n",
      "# Change the Major Ticks, MATLAB approach.\n",
      "# Import NumPy, a numerical mathematics library that can be used to create arrays or matrices of numbers.\n",
      "import numpy as np\n",
      "# create a horizontal bar graph using barh() and pass the x- and y-axis data inside the parentheses.\n",
      "plt.barh(x_axis, y_axis)\n",
      "# Use xticks() to adjust the major x-axis ticks on a horizontal bar chart.\n",
      "# Use np.arange() to adjust the major ticks on the x-axis.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "# Get the current axes and invert them, plt.gca().invert_yaxis().\n",
      "plt.gca().invert_yaxis()\n",
      "37/28:\n",
      "import numpy as np\n",
      "np.arange(0, 51, step=5.0)\n",
      "37/29:\n",
      "import numpy as np\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "37/30:\n",
      "# Create the same graph using the object-oriented approach.\n",
      "fig, ax = plt.subplots()\n",
      "ax.barh(x_axis, y_axis)\n",
      "# ax.xaxis.set_ticks() can also be used instead of ax.set_xticks().\n",
      "ax.set_xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "37/31:\n",
      "# Add Minor Ticks, x.xaxis.set_minor_locator(), object-oriented approach.\n",
      "# Import the MultipleLocator method from the matplotlib.ticker.\n",
      "from matplotlib.ticker import MultipleLocator\n",
      "# Increase the size of the plot figure.\n",
      "fig, ax = plt.subplots(figsize=(8, 8))\n",
      "ax.barh(x_axis, y_axis)\n",
      "ax.set_xticks(np.arange(0, 51, step=5.0))\n",
      "# Create minor ticks at an increment of 1.\n",
      "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
      "plt.show()\n",
      "38/1:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "38/2:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "pyber_rife_df=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "38/3:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "pyber_rife_df=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "pyber_rife_df\n",
      "38/4:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "pyber_ride_data_to_load=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "pyber_ride_df=pd.read_csv(pyber_ride_data_to_load)\n",
      "pyber_ride_df\n",
      "38/5:\n",
      "# Plot the months along the x-axis and the fare on the y-axis, .plot().\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "plt.show()\n",
      "38/6:\n",
      "# Matplotlib magic command.\n",
      "# Import dependencies.\n",
      "# Import os module to upload csv files via inderect path.\n",
      "# Assign variables for files to load via indirect path.\n",
      "# Read df and store it in a Pandas DataFrame.\n",
      "# Plot the x-axis and y-axis from df data, df.plot(x=\"\", y=\"\").\n",
      "# Set/Assign x-axis, # Set x-axis, create an array of numbers using arange () for the length of the df, x_axis = np.arange(len(df)).\n",
      "# Set/Assign tick locations,tick_locations = [value for value in x_axis].\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, df[\"WHATEVER X EQUALS\"]).\n",
      "38/7:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "pyber_ride_data_to_load=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "pyber_ride_df=pd.read_csv(pyber_ride_data_to_load)\n",
      "pyber_ride_df\n",
      "38/8:\n",
      "# Set x-axis, create an array of numbers using arange () for the length of the df.\n",
      "x_axis = np.arange(len(pyber_ride_df))\n",
      "# Set tick locations.\n",
      "tick_locations = [value for value in x_axis]\n",
      "# Plot the months along the x-axis and the fare on the y-axis, .plot().\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "# Create an array of numbers using arange () for the length of pyber_ride_df:\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, pyber_ride_df[\"Month\"]).\n",
      "plt.xticks(tick_locations, pyber_ride_df[\"Month\"])\n",
      "plt.show()\n",
      "38/9:\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "plt.show()\n",
      "38/10:\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\", kind=\"bar\")\n",
      "plt.show()\n",
      "37/32:\n",
      "# Add error bars and caps to a bar chart using the MATLAB approach.\n",
      "plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "plt.show()\n",
      "38/11:\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\", kind=\"bar\")\n",
      "#plt.show()\n",
      "38/12:\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\", kind=\"bar\")\n",
      "plt.show()\n",
      "38/13:\n",
      "# Skill Drill.\n",
      "# Add error bars.\n",
      "# Add caps to the error bars, using the MATLAB approach.\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   kind=\"bar\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/14:\n",
      "# Skill Drill.\n",
      "# Add error bars.\n",
      "# Add caps to the error bars, using the MATLAB approach.\n",
      "plt.errorbar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   kind=\"bar\",\n",
      "                   #yerr=stdev,\n",
      "                   #capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/15:\n",
      "# Skill Drill.\n",
      "# Add error bars.\n",
      "# Add caps to the error bars, using the MATLAB approach.\n",
      "plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   kind=\"bar\",\n",
      "                   #yerr=stdev,\n",
      "                   #capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/16:\n",
      "# Skill Drill.\n",
      "# Add error bars.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# Add caps to the error bars, using the MATLAB approach.\n",
      "plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   kind=\"bar\",\n",
      "                   #yerr=stdev,\n",
      "                   #capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/17:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "pyber_ride_data_to_load=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "pyber_ride_df=pd.read_csv(pyber_ride_data_to_load)\n",
      "pyber_ride_df\n",
      "38/18:\n",
      "# Set x-axis, create an array of numbers using arange () for the length of the df.\n",
      "x_axis = np.arange(len(pyber_ride_df))\n",
      "# Set tick locations.\n",
      "tick_locations = [value for value in x_axis]\n",
      "# Plot the months along the x-axis and the fare on the y-axis, .plot().\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "# Create an array of numbers using arange () for the length of pyber_ride_df:\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, pyber_ride_df[\"Month\"]).\n",
      "plt.xticks(tick_locations, pyber_ride_df[\"Month\"])\n",
      "plt.show()\n",
      "38/19:\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "plt.show()\n",
      "38/20:\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\", kind=\"bar\")\n",
      "plt.show()\n",
      "38/21:\n",
      "# Skill Drill.\n",
      "# Add error bars.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# Add caps to the error bars, using the MATLAB approach.\n",
      "plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   kind=\"bar\",\n",
      "                   #yerr=stdev,\n",
      "                   #capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/22:\n",
      "# Skill Drill.\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   kind=\"bar\",\n",
      "                   #yerr=stdev,\n",
      "                   #capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# Add caps to the error bars, using the MATLAB approach.\n",
      "plt.bar(x_axis, y_axis, yerr=stdev, capsize=3)\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/23:\n",
      "# Skill Drill.\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/24:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "pyber_ride_data_to_load=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "pyber_ride_df=pd.read_csv(pyber_ride_data_to_load)\n",
      "pyber_ride_df\n",
      "38/25:\n",
      "# Set x-axis, create an array of numbers using arange () for the length of the df.\n",
      "x_axis = np.arange(len(pyber_ride_df))\n",
      "# Set tick locations.\n",
      "tick_locations = [value for value in x_axis]\n",
      "# Plot the months along the x-axis and the fare on the y-axis, .plot().\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "# Create an array of numbers using arange () for the length of pyber_ride_df:\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, pyber_ride_df[\"Month\"]).\n",
      "plt.xticks(tick_locations, pyber_ride_df[\"Month\"])\n",
      "plt.show()\n",
      "38/26:\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "plt.show()\n",
      "38/27:\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\", kind=\"bar\")\n",
      "plt.show()\n",
      "38/28:\n",
      "# Skill Drill.\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/29:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/30:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/31:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.xticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/32:\n",
      "# Matplotlib magic command.\n",
      "# Import dependencies.\n",
      "# Import os module to upload csv files via inderect path.\n",
      "# Assign variables for files to load via indirect path.\n",
      "# Read df and store it in a Pandas DataFrame.\n",
      "# Plot the x-axis and y-axis from df data, df.plot(x=\"\", y=\"\").\n",
      "# Set/Assign x-axis, # Set x-axis, create an array of numbers using arange () for the length of the df, x_axis = np.arange(len(df)).\n",
      "# Set/Assign tick locations,tick_locations = [value for value in x_axis].\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, df[\"WHATEVER X EQUALS\"]).\n",
      "38/33:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variables for files to load via indirect path.\n",
      "pyber_ride_data_to_load=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "pyber_ride_df=pd.read_csv(pyber_ride_data_to_load)\n",
      "pyber_ride_df\n",
      "38/34:\n",
      "# Set x-axis, create an array of numbers using arange () for the length of the df.\n",
      "x_axis = np.arange(len(pyber_ride_df))\n",
      "# Set tick locations.\n",
      "tick_locations = [value for value in x_axis]\n",
      "# Plot the months along the x-axis and the fare on the y-axis, .plot().\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "# Create an array of numbers using arange () for the length of pyber_ride_df:\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, pyber_ride_df[\"Month\"]).\n",
      "plt.xticks(tick_locations, pyber_ride_df[\"Month\"])\n",
      "plt.show()\n",
      "38/35:\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "plt.show()\n",
      "38/36:\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\", kind=\"bar\")\n",
      "plt.show()\n",
      "38/37:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/38:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\",\n",
      "                   y=\"Avg. Fare ($USD)\",\n",
      "                   yerr=stdev,\n",
      "                   capsize=3,\n",
      "                   facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/39:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/40:\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "plt.show()\n",
      "38/41:\n",
      "# create a bar chart with the same data, option 2, kind=\"\" parameter, .plot(x=\"\", y=\"\", kind=\"\")\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\", kind=\"bar\")\n",
      "plt.show()\n",
      "38/42:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/43:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "#stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/44:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(y_axis)\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/45:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(pyber_ride_df[\"Avg. Fare ($USD)\"])\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "\n",
      "# Add error bars.\n",
      "\n",
      "# Change the color of the bars to sky blue.\n",
      "\n",
      "\n",
      "\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/46:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(pyber_ride_df[\"Avg. Fare ($USD)\"])\n",
      "# Add error bars.\n",
      "# Change the color of the bars to sky blue.\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/47:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(pyber_ride_df[\"Avg. Fare ($USD)\"])\n",
      "# Add error bars.\n",
      "# Change the color of the bars to sky blue.\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "#plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/48:\n",
      "# Skill Drill.\n",
      "# Get the standard deviation of the values in the y-axis.\n",
      "stdev = statistics.stdev(pyber_ride_df[\"Avg. Fare ($USD)\"])\n",
      "# Add error bars.\n",
      "# Change the color of the bars to sky blue.\n",
      "# create a bar chart with the same data, option 1, chaining, .plot.bar()\n",
      "pyber_ride_df.plot.bar(x=\"Month\", y=\"Avg. Fare ($USD)\",\n",
      "                       yerr=stdev,\n",
      "                       capsize=3,\n",
      "                       facecolor=\"skyblue\")\n",
      "# Rotate the labels on the x-axis to horizontal.\n",
      "#plt.gca().invert_xaxis()\n",
      "# Create a range between zero and 50 with an increment of 5.\n",
      "np.arange(0, 51, step=5.0)\n",
      "# Set the y-axis increment to every $5.\n",
      "plt.yticks(np.arange(0, 51, step=5.0))\n",
      "plt.show()\n",
      "38/49:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "city_data_df\n",
      "38/50:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "city_data_df.head(11)\n",
      "38/51:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "city_data_df.tail(11)\n",
      "38/52:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "city_data_df.head(10)\n",
      "38/53:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.head(10)\n",
      "38/54:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.tail(10)\n",
      "38/55:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "# Assign variable for file to load via indirect path.\n",
      "pyber_ride_data_to_load=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "pyber_ride_df=pd.read_csv(pyber_ride_data_to_load)\n",
      "pyber_ride_df\n",
      "38/56:\n",
      "# Set x-axis, create an array of numbers using arange () for the length of the df.\n",
      "x_axis = np.arange(len(pyber_ride_df))\n",
      "# Set tick locations.\n",
      "tick_locations = [value for value in x_axis]\n",
      "# Plot the months along the x-axis and the fare on the y-axis, .plot().\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "# Create an array of numbers using arange () for the length of pyber_ride_df:\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, pyber_ride_df[\"Month\"]).\n",
      "plt.xticks(tick_locations, pyber_ride_df[\"Month\"])\n",
      "#plt.show()\n",
      "38/57:\n",
      "# Set x-axis, create an array of numbers using arange () for the length of the df.\n",
      "x_axis = np.arange(len(pyber_ride_df))\n",
      "# Set tick locations.\n",
      "tick_locations = [value for value in x_axis]\n",
      "# Plot the months along the x-axis and the fare on the y-axis, .plot().\n",
      "pyber_ride_df.plot(x=\"Month\", y=\"Avg. Fare ($USD)\")\n",
      "# Create an array of numbers using arange () for the length of pyber_ride_df:\n",
      "# Add ticks and location to the x-axis, plt.xticks(tick_locations, pyber_ride_df[\"Month\"]).\n",
      "plt.xticks(tick_locations, pyber_ride_df[\"Month\"])\n",
      "plt.show()\n",
      "40/1:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variable for file to load via indirect path.\n",
      "pyber_ride_data_to_load=os.path.join(\"Resources\", \"PyBer_ride_data.csv\")\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "pyber_ride_df=pd.read_csv(pyber_ride_data_to_load)\n",
      "pyber_ride_df\n",
      "40/2:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "40/3:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "40/4:\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.tail(10)\n",
      "40/5:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "40/6:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "40/7:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "40/8:\n",
      "# Read pyber_rife_df and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.tail(10)\n",
      "40/9:\n",
      "# Read city data and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "city_data_df.head(10)\n",
      "40/10:\n",
      "# Read ride data and store it in a Pandas DataFrame.\n",
      "ride_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.head(10)\n",
      "40/11:\n",
      "# Explore Data in Pandas.\n",
      "# Inspect city_data_df.\n",
      "# Columns and rows not null, df.count()\n",
      "city_data_df.count()\n",
      "40/12:\n",
      "# Columns and rows not null, option 2, chaning, df.isnull().sum().\n",
      "city_data_df.isnull().sum()\n",
      "40/13:\n",
      "# Data types of each column.\n",
      "city_data_df.dtypes\n",
      "40/14:\n",
      "# Unique values of the type of city.\n",
      "city_data_df[\"type\"].unique()\n",
      "40/15:\n",
      "# Number of data points from the Urban cities.\n",
      "sum(city_data_df[\"type\"]==\"Urban\")\n",
      "40/16:\n",
      "# Number of data points from the Suburban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Suburban\")\n",
      "40/17:\n",
      "# Number of data points from the Rural cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Rural\")\n",
      "40/18:\n",
      "# Inspect ride_data_df.\n",
      "# Columns and the rows not null, .count().\n",
      "ride_data_df.count()\n",
      "40/19:\n",
      "# Columns and the rows not null, .sum().\n",
      "ride_data_.isnull().sum()\n",
      "40/20:\n",
      "# Columns and the rows not null, .sum().\n",
      "ride_data_df.isnull().sum()\n",
      "40/21:\n",
      "# Data types of each column.\n",
      "ride_data_df.dtypes\n",
      "40/22:\n",
      "# Merge DataFrames.\n",
      "# Combine data into a single dataset.\n",
      "# Syntax, new_df = pd.merge(leftdf, rightdf, on=[\"column_leftdf\", \"column_rightdf\"])\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "# Display DataFrame.\n",
      "pyber_data_df.head()\n",
      "40/23:\n",
      "# Create DataFrames for Each Type of City.\n",
      "# Create scatter plot/bubble chart with average fare versus total number of rides.\n",
      "# Urban, suburban, and rural.\n",
      "# Y-axis= average fare for each city type, mean().\n",
      "# X-axis= total number of rides for each city type, count().\n",
      "# Size of each marker to correlate with average number of drivers for each city type.\n",
      "# Get average [\"driver_count\"] for each city.\n",
      "40/24:\n",
      "# Create separate DataFrames for each City type, then create Data Series for each step.\n",
      "# Create the Urban city DataFrame.\n",
      "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
      "urban_cities_df.head()\n",
      "40/25:\n",
      "# Create Suburban city DataFrame.\n",
      "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
      "40/26:\n",
      "# Create Rural city DataFrame.\n",
      "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
      "40/27:\n",
      "# Create DataFrames for Each Type of City.\n",
      "# Create scatter plot/bubble chart with average fare versus total number of rides.\n",
      "# Urban, suburban, and rural.\n",
      "# Y-axis= average fare for each city type, mean().\n",
      "# X-axis= total number of rides for each city type, count().\n",
      "# Size of each marker to correlate with average number of drivers for each city type.\n",
      "# Get average [\"driver_count\"] for each city.\n",
      "40/28:\n",
      "# Create separate DataFrames for each City type, then create Data Series for each step.\n",
      "# Create Urban city DataFrame.\n",
      "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
      "urban_cities_df.head()\n",
      "40/29:\n",
      "# Create Suburban city DataFrame.\n",
      "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
      "40/30:\n",
      "# Create Rural city DataFrame.\n",
      "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
      "rural_cities_df\n",
      "40/31:\n",
      "# Create separate DataFrames for each City type, then create Data Series for each step.\n",
      "# Create Urban city DataFrame.\n",
      "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
      "#urban_cities_df.head()\n",
      "40/32:\n",
      "# Create Suburban city DataFrame.\n",
      "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
      "#suburban_cities_df\n",
      "40/33:\n",
      "# Create Rural city DataFrame.\n",
      "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
      "#rural_cities_df\n",
      "40/34:\n",
      "# Create Data Series for each step.\n",
      "# Get Number of Rides for Each City Type, groupby().\n",
      "# Get number of rides for urban cities.\n",
      "urban_ride_count = urban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "urban_ride_count.head()\n",
      "40/35:\n",
      "# Create suburban ride count.\n",
      "suburban_ride_count = suburban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "40/36:\n",
      "# Rural cities' ride count.\n",
      "rural_ride_count = rural_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "40/37:\n",
      "# Get Average Fare for Each City Type, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' average fare.\n",
      "urban_avg_fare = urban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "urban_avg_fare.head()\n",
      "40/38:\n",
      "# Suburban cities' average fare.\n",
      "suburban_avg_fare = suburban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "40/39:\n",
      "# Rural cities' average fare.\n",
      "rural_avg_fare = rural_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "40/40:\n",
      "# Get Average Number of Drivers for Each City Type, marker, .groupby([\"\"]).mean()[\"\"].\n",
      "# Suburban cities' driver count.\n",
      "urban_driver_count = urban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "urban_driver_count.head()\n",
      "40/41:\n",
      "# Suburban cities' diver count.\n",
      "suburban_driver_count = suburban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "40/42:\n",
      "# Rural cities' driver count.\n",
      "rural_driver_count = rural_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "40/43:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count, urban_avg_fare)\n",
      "plt.show()\n",
      "40/44:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count,\n",
      "            urban_avg_fare,\n",
      "            s=urban_driver_count)\n",
      "plt.show()\n",
      "40/45:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count,\n",
      "            urban_avg_fare,\n",
      "            s=urban_driver_count, c=\"coral\",\n",
      "            edgecolor=\"black\", linewidths=1,\n",
      "            alpha=0.8, label=\"Urban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()            \n",
      "plt.show()\n",
      "40/46:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count,\n",
      "            urban_avg_fare,\n",
      "            s=10*urban_driver_count, c=\"coral\",\n",
      "            edgecolor=\"black\", linewidths=1,\n",
      "            alpha=0.8, label=\"Urban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()            \n",
      "plt.show()\n",
      "40/47:\n",
      "# Suburban cities scatter plot chart.\n",
      "# Build the scatter plots for suburban cities.\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show()\n",
      "40/48:\n",
      "# Rural Cities Bubble Chart.\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "40/49:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "plt.scatter(urban_ride_count,\n",
      "      urban_avg_fare,\n",
      "      s=10*urban_driver_count, c=\"coral\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "\n",
      "plt.show()\n",
      "40/50:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "      urban_avg_fare,\n",
      "      s=10*urban_driver_count, c=\"coral\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Add legend.\n",
      "plt.legend()\n",
      "\n",
      "plt.show()\n",
      "40/51:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "      urban_avg_fare,\n",
      "      s=10*urban_driver_count, c=\"coral\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\", mode=\"Expanded\",\n",
      "         scatterpoints=1, loc=\"best\", title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "\n",
      "plt.show()\n",
      "40/52:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "40/53:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "40/54:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "40/55:\n",
      "# Read city data and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "city_data_df.head(10)\n",
      "40/56:\n",
      "# Read ride data and store it in a Pandas DataFrame.\n",
      "ride_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.head(10)\n",
      "40/57:\n",
      "# Explore Data in Pandas.\n",
      "# Inspect city_data_df.\n",
      "# Columns and rows not null, option 1, df.count().\n",
      "city_data_df.count()\n",
      "40/58:\n",
      "# Columns and rows not null, option 2, chaning, df.isnull().sum().\n",
      "city_data_df.isnull().sum()\n",
      "40/59:\n",
      "# Data types of each column.\n",
      "city_data_df.dtypes\n",
      "40/60:\n",
      "# Unique values of the type of city.\n",
      "city_data_df[\"type\"].unique()\n",
      "40/61:\n",
      "# Number of data points from the Urban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Urban\")\n",
      "40/62:\n",
      "# Number of data points from the Suburban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Suburban\")\n",
      "40/63:\n",
      "# Number of data points from the Rural cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Rural\")\n",
      "40/64:\n",
      "# Inspect ride_data_df.\n",
      "# Columns and the rows not null, .count().\n",
      "ride_data_df.count()\n",
      "40/65:\n",
      "# Columns and the rows not null, .sum().\n",
      "ride_data_df.isnull().sum()\n",
      "40/66:\n",
      "# Data types of each column.\n",
      "ride_data_df.dtypes\n",
      "40/67:\n",
      "# Merge DataFrames.\n",
      "# Combine data into a single dataset.\n",
      "# Syntax, new_df = pd.merge(leftdf, rightdf, on=[\"column_leftdf\", \"column_rightdf\"])\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "# Display DataFrame.\n",
      "pyber_data_df.head()\n",
      "40/68:\n",
      "# Create DataFrames for Each Type of City.\n",
      "# Create scatter plot/bubble chart with average fare versus total number of rides.\n",
      "# Urban, suburban, and rural.\n",
      "# Y-axis= average fare for each city type, mean().\n",
      "# X-axis= total number of rides for each city type, count().\n",
      "# Size of each marker to correlate with average number of drivers for each city type.\n",
      "# Get average [\"driver_count\"] for each city.\n",
      "40/69:\n",
      "# Create separate DataFrames for each City type.\n",
      "# Urban city DataFrame.\n",
      "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
      "#urban_cities_df.head()\n",
      "40/70:\n",
      "# Suburban city DataFrame.\n",
      "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
      "#suburban_cities_df\n",
      "40/71:\n",
      "# Rural city DataFrame.\n",
      "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
      "#rural_cities_df\n",
      "40/72:\n",
      "# Create Data Series for each step, cities' ride count, X-axis, groupby().\n",
      "# Get Number of Rides for Each City Type.\n",
      "# Urban cities' ride count.\n",
      "urban_ride_count = urban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "urban_ride_count.head()\n",
      "40/73:\n",
      "# Suburban cities' ride count.\n",
      "suburban_ride_count = suburban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "40/74:\n",
      "# Rural cities' ride count.\n",
      "rural_ride_count = rural_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "40/75:\n",
      "# Get Average Fare for Each City Type, Y-axis, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' average fare.\n",
      "urban_avg_fare = urban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "urban_avg_fare.head()\n",
      "40/76:\n",
      "# Suburban cities' average fare.\n",
      "suburban_avg_fare = suburban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "40/77:\n",
      "# Rural cities' average fare.\n",
      "rural_avg_fare = rural_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "40/78:\n",
      "# Get Average Number of Drivers for Each City Type, marker, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' driver count.\n",
      "urban_driver_count = urban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "urban_driver_count.head()\n",
      "40/79:\n",
      "# Suburban cities' diver count.\n",
      "suburban_driver_count = suburban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "40/80:\n",
      "# Rural cities' driver count.\n",
      "rural_driver_count = rural_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "40/81:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count,\n",
      "            urban_avg_fare,\n",
      "            s=10*urban_driver_count, c=\"coral\",\n",
      "            edgecolor=\"black\", linewidths=1,\n",
      "            alpha=0.8, label=\"Urban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()            \n",
      "plt.show()\n",
      "40/82:\n",
      "# Suburban cities scatter plot chart.\n",
      "# Build the scatter plots for suburban cities.\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show()\n",
      "40/83:\n",
      "# Rural Cities Bubble Chart.\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "40/84:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\", mode=\"Expanded\",\n",
      "         scatterpoints=1, loc=\"best\", title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "\n",
      "plt.show()\n",
      "40/85:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\", mode=\"Expanded\",\n",
      "         scatterpoints=1, loc=\"best\", title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "\n",
      "plt.show()\n",
      "40/86:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.gcf().subplots_adjust(bottom=0.15)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "40/87:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.gcf().subplots_adjust(bottom=0.15)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "40/88:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.gcf().subplots_adjust(bottom=0.15)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "40/89:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.gcf().subplots_adjust(bottom=0.15)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "43/1:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "43/2:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import statistics\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "43/3:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "43/4:\n",
      "# Read city data and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "city_data_df.head(10)\n",
      "43/5:\n",
      "# Read ride data and store it in a Pandas DataFrame.\n",
      "ride_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.head(10)\n",
      "43/6:\n",
      "# Explore Data in Pandas.\n",
      "# Inspect city_data_df.\n",
      "# Columns and rows not null, option 1, df.count().\n",
      "city_data_df.count()\n",
      "43/7:\n",
      "# Columns and rows not null, option 2, chaning, df.isnull().sum().\n",
      "city_data_df.isnull().sum()\n",
      "43/8:\n",
      "# Data types of each column.\n",
      "city_data_df.dtypes\n",
      "43/9:\n",
      "# Unique values of the type of city.\n",
      "city_data_df[\"type\"].unique()\n",
      "43/10:\n",
      "# Number of data points from the Urban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Urban\")\n",
      "43/11:\n",
      "# Number of data points from the Suburban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Suburban\")\n",
      "43/12:\n",
      "# Number of data points from the Rural cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Rural\")\n",
      "43/13:\n",
      "# Inspect ride_data_df.\n",
      "# Columns and the rows not null, .count().\n",
      "ride_data_df.count()\n",
      "43/14:\n",
      "# Columns and the rows not null, .sum().\n",
      "ride_data_df.isnull().sum()\n",
      "43/15:\n",
      "# Data types of each column.\n",
      "ride_data_df.dtypes\n",
      "43/16:\n",
      "# Merge DataFrames.\n",
      "# Combine data into a single dataset.\n",
      "# Syntax, new_df = pd.merge(leftdf, rightdf, on=[\"column_leftdf\", \"column_rightdf\"])\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "# Display DataFrame.\n",
      "pyber_data_df.head()\n",
      "43/17:\n",
      "# Create DataFrames for Each Type of City.\n",
      "# Create scatter plot/bubble chart with average fare versus total number of rides.\n",
      "# Urban, suburban, and rural.\n",
      "# Y-axis= average fare for each city type, mean().\n",
      "# X-axis= total number of rides for each city type, count().\n",
      "# Size of each marker to correlate with average number of drivers for each city type.\n",
      "# Get average [\"driver_count\"] for each city.\n",
      "43/18:\n",
      "# Create separate DataFrames for each City type.\n",
      "# Urban city DataFrame.\n",
      "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
      "#urban_cities_df.head()\n",
      "43/19:\n",
      "# Suburban city DataFrame.\n",
      "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
      "#suburban_cities_df\n",
      "43/20:\n",
      "# Rural city DataFrame.\n",
      "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
      "#rural_cities_df\n",
      "43/21:\n",
      "# Create Data Series for each step, cities' ride count, X-axis, groupby().\n",
      "# Get Number of Rides for Each City Type.\n",
      "# Urban cities' ride count.\n",
      "urban_ride_count = urban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "urban_ride_count.head()\n",
      "43/22:\n",
      "# Suburban cities' ride count.\n",
      "suburban_ride_count = suburban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "43/23:\n",
      "# Rural cities' ride count.\n",
      "rural_ride_count = rural_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "43/24:\n",
      "# Get Average Fare for Each City Type, Y-axis, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' average fare.\n",
      "urban_avg_fare = urban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "urban_avg_fare.head()\n",
      "43/25:\n",
      "# Suburban cities' average fare.\n",
      "suburban_avg_fare = suburban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "43/26:\n",
      "# Rural cities' average fare.\n",
      "rural_avg_fare = rural_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "43/27:\n",
      "# Get Average Number of Drivers for Each City Type, marker, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' driver count.\n",
      "urban_driver_count = urban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "urban_driver_count.head()\n",
      "43/28:\n",
      "# Suburban cities' diver count.\n",
      "suburban_driver_count = suburban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "43/29:\n",
      "# Rural cities' driver count.\n",
      "rural_driver_count = rural_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "43/30:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count,\n",
      "            urban_avg_fare,\n",
      "            s=10*urban_driver_count, c=\"coral\",\n",
      "            edgecolor=\"black\", linewidths=1,\n",
      "            alpha=0.8, label=\"Urban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()            \n",
      "plt.show()\n",
      "43/31:\n",
      "# Suburban cities scatter plot chart.\n",
      "# Build the scatter plots for suburban cities.\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show()\n",
      "43/32:\n",
      "# Rural Cities Bubble Chart.\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "43/33:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.gcf().subplots_adjust(bottom=0.15)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "43/34:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.gcf().subplots_adjust(bottom=0.15)\n",
      "\n",
      "\n",
      "plt.show()\n",
      "43/35:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "\n",
      "\n",
      "plt.show()\n",
      "43/36:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "plt.show()\n",
      "43/37:\n",
      "# Summary Statistics for Number of Rides by City Type.\n",
      "# Urban cities' summary statistics.\n",
      "urban_cities_df.describe()\n",
      "43/38:\n",
      "# Suburban cities' summary statistics.\n",
      "suburban_cities_df.describe()\n",
      "43/39:\n",
      "# Rural cities' summary statistics.\n",
      "rural_cities_df.describe()\n",
      "43/40:\n",
      "# Urban cities' ride count summary statistics.\n",
      "urban_ride_count.describe()\n",
      "43/41:\n",
      "# Suburban cities' ride count summary statistics.\n",
      "suburban_ride_count.describe()\n",
      "43/42:\n",
      "# Rural cities' ride count summary statistics.\n",
      "rural_ride_count.describe()\n",
      "43/43:\n",
      "# Ride count mean for each city type.\n",
      "round(urban_ride_count.mean(),2), round(suburban_ride_count.mean(),2), round(rural_ride_count.mean(),2)\n",
      "43/44:\n",
      "# Ride count median for each city type.\n",
      "round(urban_ride_count.median(),2), round(suburban_ride_count.median(),2), round(rural_ride_count.median(),2)\n",
      "43/45:\n",
      "# Urban cities' ride count mode.\n",
      "urban_ride_count.mode()\n",
      "43/46:\n",
      "# Suburban cities' ride count mode.\n",
      "suburban_ride_count.mode()\n",
      "43/47:\n",
      "# Rural cities' ride count mode.\n",
      "rural_ride_count.mode()\n",
      "43/48:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "43/49:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "43/50:\n",
      "# Read city data and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "city_data_df.head(10)\n",
      "43/51:\n",
      "# Read ride data and store it in a Pandas DataFrame.\n",
      "ride_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.head(10)\n",
      "43/52:\n",
      "# Explore Data in Pandas.\n",
      "# Inspect city_data_df.\n",
      "# Columns and rows not null, option 1, df.count().\n",
      "city_data_df.count()\n",
      "43/53:\n",
      "# Columns and rows not null, option 2, chaning, df.isnull().sum().\n",
      "city_data_df.isnull().sum()\n",
      "43/54:\n",
      "# Data types of each column.\n",
      "city_data_df.dtypes\n",
      "43/55:\n",
      "# Unique values of the type of city.\n",
      "city_data_df[\"type\"].unique()\n",
      "43/56:\n",
      "# Number of data points from the Urban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Urban\")\n",
      "43/57:\n",
      "# Number of data points from the Suburban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Suburban\")\n",
      "43/58:\n",
      "# Number of data points from the Rural cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Rural\")\n",
      "43/59:\n",
      "# Inspect ride_data_df.\n",
      "# Columns and the rows not null, .count().\n",
      "ride_data_df.count()\n",
      "43/60:\n",
      "# Columns and the rows not null, .sum().\n",
      "ride_data_df.isnull().sum()\n",
      "43/61:\n",
      "# Data types of each column.\n",
      "ride_data_df.dtypes\n",
      "43/62:\n",
      "# Merge DataFrames.\n",
      "# Combine data into a single dataset.\n",
      "# Syntax, new_df = pd.merge(leftdf, rightdf, on=[\"column_leftdf\", \"column_rightdf\"])\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "# Display DataFrame.\n",
      "pyber_data_df.head()\n",
      "43/63:\n",
      "# Create DataFrames for Each Type of City.\n",
      "# Create scatter plot/bubble chart with average fare versus total number of rides.\n",
      "# Urban, suburban, and rural.\n",
      "# Y-axis= average fare for each city type, mean().\n",
      "# X-axis= total number of rides for each city type, count().\n",
      "# Size of each marker to correlate with average number of drivers for each city type.\n",
      "# Get average [\"driver_count\"] for each city.\n",
      "43/64:\n",
      "# Create separate DataFrames for each City type.\n",
      "# Urban city DataFrame.\n",
      "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
      "#urban_cities_df.head()\n",
      "43/65:\n",
      "# Suburban city DataFrame.\n",
      "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
      "#suburban_cities_df\n",
      "43/66:\n",
      "# Rural city DataFrame.\n",
      "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
      "#rural_cities_df\n",
      "43/67:\n",
      "# Create Data Series for each step, cities' ride count, X-axis, groupby().\n",
      "# Get Number of Rides for Each City Type.\n",
      "# Urban cities' ride count.\n",
      "urban_ride_count = urban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "urban_ride_count.head()\n",
      "43/68:\n",
      "# Suburban cities' ride count.\n",
      "suburban_ride_count = suburban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "43/69:\n",
      "# Rural cities' ride count.\n",
      "rural_ride_count = rural_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "43/70:\n",
      "# Get Average Fare for Each City Type, Y-axis, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' average fare.\n",
      "urban_avg_fare = urban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "urban_avg_fare.head()\n",
      "43/71:\n",
      "# Suburban cities' average fare.\n",
      "suburban_avg_fare = suburban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "43/72:\n",
      "# Rural cities' average fare.\n",
      "rural_avg_fare = rural_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "43/73:\n",
      "# Get Average Number of Drivers for Each City Type, marker, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' driver count.\n",
      "urban_driver_count = urban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "urban_driver_count.head()\n",
      "43/74:\n",
      "# Suburban cities' diver count.\n",
      "suburban_driver_count = suburban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "43/75:\n",
      "# Rural cities' driver count.\n",
      "rural_driver_count = rural_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "43/76:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count,\n",
      "            urban_avg_fare,\n",
      "            s=10*urban_driver_count, c=\"coral\",\n",
      "            edgecolor=\"black\", linewidths=1,\n",
      "            alpha=0.8, label=\"Urban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()            \n",
      "plt.show()\n",
      "43/77:\n",
      "# Suburban cities scatter plot chart.\n",
      "# Build the scatter plots for suburban cities.\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show()\n",
      "43/78:\n",
      "# Rural Cities Bubble Chart.\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "43/79:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "plt.show()\n",
      "43/80:\n",
      "# Summary Statistics for Number of Rides by City Type.\n",
      "# Urban cities' summary statistics.\n",
      "urban_cities_df.describe()\n",
      "43/81:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "plt.show()\n",
      "43/82:\n",
      "# Summary Statistics for Number of Rides by City Type.\n",
      "# Urban cities' summary statistics.\n",
      "urban_cities_df.describe()\n",
      "43/83:\n",
      "# Suburban cities' summary statistics.\n",
      "suburban_cities_df.describe()\n",
      "43/84:\n",
      "# Rural cities' summary statistics.\n",
      "rural_cities_df.describe()\n",
      "43/85:\n",
      "# Urban cities' ride count summary statistics.\n",
      "urban_ride_count.describe()\n",
      "43/86:\n",
      "# Suburban cities' ride count summary statistics.\n",
      "suburban_ride_count.describe()\n",
      "43/87:\n",
      "# Rural cities' ride count summary statistics.\n",
      "rural_ride_count.describe()\n",
      "43/88:\n",
      "# Ride count mean for each city type.\n",
      "round(urban_ride_count.mean(),2), round(suburban_ride_count.mean(),2), round(rural_ride_count.mean(),2)\n",
      "43/89:\n",
      "# Ride count median for each city type.\n",
      "round(urban_ride_count.median(),2), round(suburban_ride_count.median(),2), round(rural_ride_count.median(),2)\n",
      "43/90:\n",
      "# Urban cities' ride count mode.\n",
      "urban_ride_count.mode()\n",
      "43/91:\n",
      "# Suburban cities' ride count mode.\n",
      "suburban_ride_count.mode()\n",
      "43/92:\n",
      "# Rural cities' ride count mode.\n",
      "rural_ride_count.mode()\n",
      "43/93:\n",
      "# Measures of central tendency (mean, median, mode), NumPy.\n",
      "# Measures of central tendency, urban cities' ride count.\n",
      "mean_urban_ride_count = np.mean(urban_ride_count)\n",
      "print(f\"The mean for the ride counts for urban trips is {mean_urban_ride_count:.2f}.\")\n",
      "\n",
      "median_urban_ride_count = np.median(urban_ride_count)\n",
      "print(f\"The median for the ride counts for urban trips is {median_urban_ride_count}.\")\n",
      "\n",
      "mode_urban_ride_count = sts.mode(urban_ride_count)\n",
      "print(f\"The mode for the ride counts for urban trips is {mode_urban_ride_count}.\")\n",
      "43/94:\n",
      "# Measures of central tendency, suburban cities' ride count.\n",
      "mean_suburban_ride_count = np.mean(suburban_ride_count)\n",
      "print(f\"The mean for the ride counts for suburban trips is {mean_suburban_ride_count:.2f}.\")\n",
      "\n",
      "median_suburban_ride_count = np.median(suburban_ride_count)\n",
      "print(f\"The median for the ride counts for urban trips is {median_suburban_ride_count}.\")\n",
      "\n",
      "mode_suburban_ride_count = sts.mode(suburban_ride_count)\n",
      "print(f\"The mode for the ride counts for urban trips is {mode_suburban_ride_count}.\")\n",
      "43/95:\n",
      "# Measures of central tendency, suburban cities' ride count.\n",
      "mean_suburban_ride_count = np.mean(suburban_ride_count)\n",
      "print(f\"The mean for the ride counts for suburban trips is {mean_suburban_ride_count:.2f}.\")\n",
      "\n",
      "median_suburban_ride_count = np.median(suburban_ride_count)\n",
      "print(f\"The median for the ride counts for suburban trips is {median_suburban_ride_count}.\")\n",
      "\n",
      "mode_suburban_ride_count = sts.mode(suburban_ride_count)\n",
      "print(f\"The mode for the ride counts for suburban trips is {mode_suburban_ride_count}.\")\n",
      "43/96:\n",
      "# Measures of central tendency, rural cities' ride count.\n",
      "mean_urban_ride_count = np.mean(urban_ride_count)\n",
      "print(f\"The mean for the ride counts for urban trips is {mean_urban_ride_count:.2f}.\")\n",
      "\n",
      "median_urban_ride_count = np.median(urban_ride_count)\n",
      "print(f\"The median for the ride counts for urban trips is {median_urban_ride_count}.\")\n",
      "\n",
      "mode_urban_ride_count = sts.mode(urban_ride_count)\n",
      "print(f\"The mode for the ride counts for urban trips is {mode_urban_ride_count}.\")\n",
      "43/97:\n",
      "# Measures of central tendency, rural cities' ride count.\n",
      "mean_rural_ride_count = np.mean(rural_ride_count)\n",
      "print(f\"The mean for the ride counts for rural trips is {mean_rural_ride_count:.2f}.\")\n",
      "\n",
      "median_rural_ride_count = np.median(rural_ride_count)\n",
      "print(f\"The median for the ride counts for rural trips is {median_rural_ride_count}.\")\n",
      "\n",
      "mode_rural_ride_count = sts.mode(rural_ride_count)\n",
      "print(f\"The mode for the ride counts for rural trips is {mode_rural_ride_count}.\")\n",
      "43/98:\n",
      "# Summary Statistics for Fare by City Type.\n",
      "# Get data from \"fare\" column in each city type DataFrame.\n",
      "# Urban cities' fares summary statistics.\n",
      "urban_fares_df.head()\n",
      "43/99:\n",
      "# Summary Statistics for Fare by City Type.\n",
      "# Get data from \"fare\" column in each city type DataFrame.\n",
      "# Urban cities' fares summary statistics.\n",
      "urban_fares.head()\n",
      "43/100:\n",
      "# Summary Statistics for Fare by City Type.\n",
      "# Get data from \"fare\" column in each city type DataFrame.\n",
      "# Urban cities' fares summary statistics.\n",
      "urban_fares = urban_cities_df[\"fare\"]\n",
      "urban_fares.head()\n",
      "43/101:\n",
      "# Measures of central tendency, urban cities' average fare.\n",
      "mean_urban_fares = np.mean(urban_fares)\n",
      "print(f\"The mean fare price for urban trips is ${mean_urban_fares:.2f}.\")\n",
      "\n",
      "median_urban_fares = np.median(urban_fares)\n",
      "print(f\"The median fare price for urban trips is ${median_urban_fares:.2f}.\")\n",
      "\n",
      "mode_urban_fares = sts.mode(urban_fares)\n",
      "print(f\"The mode fare price for urban trips is {mode_urban_fares}.\")\n",
      "43/102:\n",
      "# Measures of central tendency, suburban cities' average fare.\n",
      "mean_suburban_fares = np.mean(suburban_fares)\n",
      "print(f\"The mean fare price for suburban trips is ${mean_suburban_fares:.2f}.\")\n",
      "\n",
      "median_suburban_fares = np.median(suburban_fares)\n",
      "print(f\"The median fare price for suburban trips is ${median_suburban_fares:.2f}.\")\n",
      "\n",
      "mode_suburban_fares = sts.mode(suburban_fares)\n",
      "print(f\"The mode fare price for suburban trips is {mode_suburban_fares}.\")\n",
      "43/103:\n",
      "# Suburban cities' fares summary statistics.\n",
      "suburban_fares = suburban_cities_df[\"fare\"]\n",
      "suburban_fares.head()\n",
      "43/104:\n",
      "# Measures of central tendency, suburban cities' average fare.\n",
      "mean_suburban_fares = np.mean(suburban_fares)\n",
      "print(f\"The mean fare price for suburban trips is ${mean_suburban_fares:.2f}.\")\n",
      "\n",
      "median_suburban_fares = np.median(suburban_fares)\n",
      "print(f\"The median fare price for suburban trips is ${median_suburban_fares:.2f}.\")\n",
      "\n",
      "mode_suburban_fares = sts.mode(suburban_fares)\n",
      "print(f\"The mode fare price for suburban trips is {mode_suburban_fares}.\")\n",
      "43/105:\n",
      "# Rural cities' fares summary statistics.\n",
      "rural_fares = rural_cities_df[\"fare\"]\n",
      "rural_fares.head()\n",
      "43/106:\n",
      "# Measures of central tendency, rural cities' average fare.\n",
      "mean_rural_fares = np.mean(rural_fares)\n",
      "print(f\"The mean fare price for rural trips is ${mean_rural_fares:.2f}.\")\n",
      "\n",
      "median_rural_fares = np.median(rural_fares)\n",
      "print(f\"The median fare price for rural trips is ${median_rural_fares:.2f}.\")\n",
      "\n",
      "mode_rural_fares = sts.mode(rural_fares)\n",
      "print(f\"The mode fare price for rural trips is {mode_rural_fares}.\")\n",
      "43/107:\n",
      "# Rural cities' fares column data.\n",
      "rural_fares = rural_cities_df[\"fare\"]\n",
      "rural_fares.head()\n",
      "43/108:\n",
      "# Measures of central tendency, rural cities' average fare.\n",
      "mean_rural_fares = np.mean(rural_fares)\n",
      "print(f\"The mean fare price for rural trips is ${mean_rural_fares:.2f}.\")\n",
      "\n",
      "median_rural_fares = np.median(rural_fares)\n",
      "print(f\"The median fare price for rural trips is ${median_rural_fares:.2f}.\")\n",
      "\n",
      "mode_rural_fares = sts.mode(rural_fares)\n",
      "print(f\"The mode fare price for rural trips is {mode_rural_fares}.\")\n",
      "43/109:\n",
      "# Summary Statistics for Number of Drivers by City Type.\n",
      "# 1st, get data from \"driver_count\" column in each city type DataFrame.\n",
      "# Syntax, _cities_df[\"\"].\n",
      "# Urban cities' driver_count data.\n",
      "urban_drivers = urban_cities_df['driver_count']\n",
      "urban_drivers.head()\n",
      "43/110:\n",
      "# Measures of central tendency, urban cities' number of drivers.\n",
      "mean_urban_drivers = np.mean(urban_drivers)\n",
      "print(f\"The mean fare price for urban trips is ${mean_urban_drivers:.2f}.\")\n",
      "\n",
      "median_urban_drivers = np.median(urban_drivers)\n",
      "print(f\"The median fare price for urban trips is ${median_urban_drivers:.2f}.\")\n",
      "\n",
      "mode_urban_drivers = sts.mode(urban_drivers)\n",
      "print(f\"The mode fare price for urban trips is {mode_urban_drivers}.\")\n",
      "43/111:\n",
      "# suburban cities' \"driver_count\" data.\n",
      "suburban_drivers = suburban_cities_df['driver_count']\n",
      "suburban_drivers.head()\n",
      "43/112:\n",
      "# Measures of central tendency, suburban cities' number of drivers.\n",
      "mean_suburban_drivers = np.mean(suburban_drivers)\n",
      "print(f\"The mean fare price for suburban trips is ${mean_suburban_drivers:.2f}.\")\n",
      "\n",
      "median_suburban_drivers = np.median(suburban_drivers)\n",
      "print(f\"The median fare price for suburban trips is ${median_suburban_drivers:.2f}.\")\n",
      "\n",
      "mode_suburban_drivers = sts.mode(suburban_drivers)\n",
      "print(f\"The mode fare price for suburban trips is {mode_suburban_drivers}.\")\n",
      "43/113:\n",
      "# rural cities' \"driver_count\" data.\n",
      "rural_drivers = rural_cities_df['driver_count']\n",
      "rural_drivers.head()\n",
      "43/114:\n",
      "# Measures of central tendency, rural cities' number of drivers.\n",
      "mean_rural_drivers = np.mean(rural_drivers)\n",
      "print(f\"The mean fare price for rural trips is ${mean_rural_drivers:.2f}.\")\n",
      "\n",
      "median_rural_drivers = np.median(rural_drivers)\n",
      "print(f\"The median fare price for rural trips is ${median_rural_drivers:.2f}.\")\n",
      "\n",
      "mode_rural_drivers = sts.mode(rural_drivers)\n",
      "print(f\"The mode fare price for rural trips is {mode_rural_drivers}.\")\n",
      "43/115:\n",
      "# Measures of central tendency, urban cities' number of drivers.\n",
      "mean_urban_drivers = np.mean(urban_drivers)\n",
      "print(f\"The mean number of drivers for urban trips is ${mean_urban_drivers:.2f}.\")\n",
      "\n",
      "median_urban_drivers = np.median(urban_drivers)\n",
      "print(f\"The median number of drivers for urban trips is ${median_urban_drivers:.2f}.\")\n",
      "\n",
      "mode_urban_drivers = sts.mode(urban_drivers)\n",
      "print(f\"The mode number of drivers for urban trips is {mode_urban_drivers}.\")\n",
      "43/116:\n",
      "# Measures of central tendency, urban cities' number of drivers.\n",
      "mean_urban_drivers = np.mean(urban_drivers)\n",
      "print(f\"The mean number of drivers for urban trips is  {mean_urban_drivers:.2f}.\")\n",
      "\n",
      "median_urban_drivers = np.median(urban_drivers)\n",
      "print(f\"The median number of drivers for urban trips is  {median_urban_drivers:.2f}.\")\n",
      "\n",
      "mode_urban_drivers = sts.mode(urban_drivers)\n",
      "print(f\"The mode number of drivers for urban trips is {mode_urban_drivers}.\")\n",
      "43/117:\n",
      "# Measures of central tendency, urban cities' number of drivers.\n",
      "mean_urban_drivers = np.mean(urban_drivers)\n",
      "print(f\"The mean number of drivers for urban trips is {mean_urban_drivers:.2f}.\")\n",
      "\n",
      "median_urban_drivers = np.median(urban_drivers)\n",
      "print(f\"The median number of drivers for urban trips is {median_urban_drivers:.2f}.\")\n",
      "\n",
      "mode_urban_drivers = sts.mode(urban_drivers)\n",
      "print(f\"The mode number of drivers for urban trips is {mode_urban_drivers}.\")\n",
      "43/118:\n",
      "# Measures of central tendency, suburban cities' number of drivers.\n",
      "mean_suburban_drivers = np.mean(suburban_drivers)\n",
      "print(f\"The mean number of drivers for suburban trips is {mean_suburban_drivers:.2f}.\")\n",
      "\n",
      "median_suburban_drivers = np.median(suburban_drivers)\n",
      "print(f\"The median number of drivers for suburban trips is {median_suburban_drivers:.2f}.\")\n",
      "\n",
      "mode_suburban_drivers = sts.mode(suburban_drivers)\n",
      "print(f\"The mode number of drivers for suburban trips is {mode_suburban_drivers}.\")\n",
      "43/119:\n",
      "# rural cities' \"driver_count\" data.\n",
      "rural_drivers = rural_cities_df['driver_count']\n",
      "rural_drivers.head()\n",
      "43/120:\n",
      "# Measures of central tendency, rural cities' number of drivers.\n",
      "mean_rural_drivers = np.mean(rural_drivers)\n",
      "print(f\"The mean number of drivers for rural trips is ${mean_rural_drivers:.2f}.\")\n",
      "\n",
      "median_rural_drivers = np.median(rural_drivers)\n",
      "print(f\"The median number of drivers for rural trips is ${median_rural_drivers:.2f}.\")\n",
      "\n",
      "mode_rural_drivers = sts.mode(rural_drivers)\n",
      "print(f\"The mode number of drivers for rural trips is {mode_rural_drivers}.\")\n",
      "43/121:\n",
      "# Measures of central tendency, rural cities' number of drivers.\n",
      "mean_rural_drivers = np.mean(rural_drivers)\n",
      "print(f\"The mean number of drivers for rural trips is {mean_rural_drivers:.2f}.\")\n",
      "\n",
      "median_rural_drivers = np.median(rural_drivers)\n",
      "print(f\"The median number of drivers for rural trips is {median_rural_drivers:.2f}.\")\n",
      "\n",
      "mode_rural_drivers = sts.mode(rural_drivers)\n",
      "print(f\"The mode number of drivers for rural trips is {mode_rural_drivers}.\")\n",
      "43/122:\n",
      "# Create Box-and-Whisker Plots, ax.boxplot().\n",
      "# Urban cities' ride count box-and-whisker plot.\n",
      "x_labels = [\"Urban\"]\n",
      "fig, ax = plt.subplots()\n",
      "# .boxplot(data,labels)\n",
      "ax.boxplot(urban_ride_count, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Count Data (2019)')\n",
      "ax.set_ylabel('Number of Rides')\n",
      "ax.set_yticks(np.arange(10, 41, step=2.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "43/123:\n",
      "# Suburban cities' ride count box-and-whisker plot.\n",
      "x_labels = [\"suburban\"]\n",
      "fig, ax = plt.subplots()\n",
      "# .boxplot(data,labels)\n",
      "ax.boxplot(suburban_ride_count, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Count Data (2019)')\n",
      "ax.set_ylabel('Number of Rides')\n",
      "ax.set_yticks(np.arange(10, 41, step=2.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "43/124:\n",
      "# Rural cities' ride count box-and-whisker plot.\n",
      "x_labels = [\"rural\"]\n",
      "fig, ax = plt.subplots()\n",
      "# .boxplot(data,labels)\n",
      "ax.boxplot(rural_ride_count, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Count Data (2019)')\n",
      "ax.set_ylabel('Number of Rides')\n",
      "ax.set_yticks(np.arange(10, 41, step=2.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "43/125:\n",
      "# Add ALL ride count box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "ax.set_title('Ride Count Data (2019)',fontsize=20)\n",
      "ax.set_ylabel('Number of Rides',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(ride_count_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 45, step=3.0))\n",
      "ax.grid()\n",
      "# Save the figure.\n",
      "plt.savefig(\"analysis/Fig2.png\")\n",
      "plt.show()\n",
      "43/126:\n",
      "# Add ALL ride count box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Ride Count Data (2019)',fontsize=20)\n",
      "ax.set_ylabel('Number of Rides',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(ride_count_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 45, step=3.0))\n",
      "ax.grid()\n",
      "# Save the figure.\n",
      "plt.savefig(\"analysis/Fig2.png\")\n",
      "plt.show()\n",
      "43/127:\n",
      "# Find city with highest rider count.\n",
      "# Get the city that matches 39.\n",
      "urban_city_outlier = urban_ride_count[urban_ride_count==39].index[0]\n",
      "print(f\"{urban_city_outlier} has the highest rider count.\")\n",
      "43/128:\n",
      "# Box-and-Whisker Plots for Ride Fare Data.\n",
      "# Urban cities' fare data box-and-whisker plot.\n",
      "x_labels = [\"Urban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(urban_fares, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Fare Data (2019)')\n",
      "ax.set_ylabel('Fare($USD)')\n",
      "ax.set_yticks(np.arange(0, 51, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "urban_fares.describe()\n",
      "43/129:\n",
      "# Suburban cities' fare data box-and-whisker plot.\n",
      "x_labels = [\"suburban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(suburban_fares, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Fare Data (2019)')\n",
      "ax.set_ylabel('Fare($USD)')\n",
      "ax.set_yticks(np.arange(0, 51, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "suburban_fares.describe()\n",
      "43/130:\n",
      "# Rural cities' fare data box-and-whisker plot.\n",
      "x_labels = [\"rural\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(rural_fares, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Fare Data (2019)')\n",
      "ax.set_ylabel('Fare($USD)')\n",
      "ax.set_yticks(np.arange(0, 51, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "rural_fares.describe()\n",
      "43/131:\n",
      "# Add cities' fare data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "fares_data = [urban_fares, suburban_fares, rural_fares]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Ride Fare Data (2019)', fontsize=20)\n",
      "ax.set_ylabel('Fare($USD)',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(fares_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 45, step=3.0))\n",
      "ax.grid()\n",
      "#plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/132:\n",
      "# Add cities' fare data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "fares_data = [urban_fares, suburban_fares, rural_fares]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Ride Fare Data (2019)', fontsize=20)\n",
      "ax.set_ylabel('Fare($USD)',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(fares_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 60, step=5.0))\n",
      "ax.grid()\n",
      "#plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/133:\n",
      "# Add cities' fare data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "fares_data = [urban_fares, suburban_fares, rural_fares]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Ride Fare Data (2019)', fontsize=20)\n",
      "ax.set_ylabel('Fare($USD)',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(fares_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 60, step=5.0))\n",
      "ax.grid()\n",
      "plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/134:\n",
      "# Box-and-Whisker Plots for Driver Count Data.\n",
      "# Urban cities' driver count data box-and-whisker plot.\n",
      "x_labels = [\"Urban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(urban_drivers,labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Driver Count Data (2019)')\n",
      "ax.set_ylabel('Number of Drivers)')\n",
      "ax.set_yticks(np.arange(0, 90, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "urban_drivers.describe()\n",
      "43/135:\n",
      "# Suburban cities' driver count data box-and-whisker plot.\n",
      "x_labels = [\"suburban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(suburban_drivers,labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Driver Count Data (2019)')\n",
      "ax.set_ylabel('Number of Drivers)')\n",
      "ax.set_yticks(np.arange(0, 90, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "suburban_drivers.describe()\n",
      "43/136:\n",
      "# Rural cities' driver count data box-and-whisker plot.\n",
      "x_labels = [\"rural\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(rural_drivers,labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Driver Count Data (2019)')\n",
      "ax.set_ylabel('Number of Drivers)')\n",
      "ax.set_yticks(np.arange(0, 90, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "rural_drivers.describe()\n",
      "43/137:\n",
      "# Add cities' driver count data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "drivers_data = [urban_drivers, suburban_drivers, rural_drivers]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Driver Count (2019)', fontsize=20)\n",
      "ax.set_ylabel('Fare($USD)',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(drivers_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 75, step=5.0))\n",
      "ax.grid()\n",
      "#plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/138:\n",
      "# Add cities' driver count data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "drivers_data = [urban_drivers, suburban_drivers, rural_drivers]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Driver Count (2019)', fontsize=20)\n",
      "ax.set_ylabel('Number of Drivers',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(drivers_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 76, step=5.0))\n",
      "ax.grid()\n",
      "#plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/139:\n",
      "# Add cities' driver count data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "drivers_data = [urban_drivers, suburban_drivers, rural_drivers]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Driver Count (2019)', fontsize=20)\n",
      "ax.set_ylabel('Number of Drivers',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(drivers_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 76, step=5.0))\n",
      "ax.grid()\n",
      "plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/140:\n",
      "# Get Percentage of Fares for Each City Type.\n",
      "# 1, Get the total fares for each city type.\n",
      "# 2, Get the total for all the fares for all the city types.\n",
      "# 3, Calculate the percentage of the total fares for each city type.\n",
      "43/141:\n",
      "# Get the sum of the fares for each city type.\n",
      "sum_fares_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "sum_fares_by_type\n",
      "43/142:\n",
      "# Get the sum of ALL the fares.\n",
      "total_fares = pyber_data_df[\"fare\"].sum()\n",
      "total_fares\n",
      "43/143:\n",
      "# Calculate the percentage of \"fare\" for each city \"type\".\n",
      "type_percents = 100 * sum_fares_by_type / total_fares\n",
      "type_percents\n",
      "43/144:\n",
      "# Advanced syntax:\n",
      "# Calculate the percentage of fare for each city type.\n",
      "#type_percents = 100 * pyber_data_df.groupby([\"type\"]).sum()[\"fare\"] / pyber_data_df[\"fare\"].sum()\n",
      "#type_percents\n",
      "43/145:\n",
      "# Percentage of Fares Pie Chart by City Type, MATLAB approach, plt.pie().\n",
      "# Each pie wedge will represent a city and its percentage of the total fares.\n",
      "# The labels will be the city type.\n",
      "# Build the percentage of fares by city type pie chart.\n",
      "plt.pie(type_percents, labels=[\"Rural\", \"Suburban\", \"Urban\"])\n",
      "plt.show()\n",
      "43/146:\n",
      "# Percentage of Fares Pie Chart by City Type, MATLAB approach, plt.pie().\n",
      "# Each pie wedge will represent a city and its percentage of the total fares.\n",
      "# The labels will be the city type.\n",
      "# Build the percentage of fares by city type pie chart.\n",
      "plt.pie(type_percents,\n",
      "        labels=[\"Rural\", \"Suburban\", \"Urban\"]\n",
      "        colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "        explode=[0, 0, 0.1],\n",
      "        autopct='%1.1f%%',\n",
      "        shadow=True,\n",
      "        startangle=150)\n",
      "plt.title(\"% of Total Fares by City Type\")\n",
      "plt.show()\n",
      "43/147:\n",
      "# Matplotlib magic command.\n",
      "%matplotlib inline\n",
      "43/148:\n",
      "# Import dependencies.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "43/149:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "43/150:\n",
      "# Read city data and store it in a Pandas DataFrame.\n",
      "city_data_df=pd.read_csv(city_data_to_load)\n",
      "city_data_df.head(10)\n",
      "43/151:\n",
      "# Read ride data and store it in a Pandas DataFrame.\n",
      "ride_data_df=pd.read_csv(city_data_to_load)\n",
      "ride_data_df=pd.read_csv(ride_data_to_load)\n",
      "ride_data_df.head(10)\n",
      "43/152:\n",
      "# Explore Data in Pandas.\n",
      "# Inspect city_data_df.\n",
      "# Columns and rows not null, option 1, df.count().\n",
      "city_data_df.count()\n",
      "43/153:\n",
      "# Columns and rows not null, option 2, chaning, df.isnull().sum().\n",
      "city_data_df.isnull().sum()\n",
      "43/154:\n",
      "# Data types of each column.\n",
      "city_data_df.dtypes\n",
      "43/155:\n",
      "# Unique values of the type of city.\n",
      "city_data_df[\"type\"].unique()\n",
      "43/156:\n",
      "# Number of data points from the Urban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Urban\")\n",
      "43/157:\n",
      "# Number of data points from the Suburban cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Suburban\")\n",
      "43/158:\n",
      "# Number of data points from the Rural cities, sum().\n",
      "sum(city_data_df[\"type\"]==\"Rural\")\n",
      "43/159:\n",
      "# Inspect ride_data_df.\n",
      "# Columns and the rows not null, .count().\n",
      "ride_data_df.count()\n",
      "43/160:\n",
      "# Columns and the rows not null, .sum().\n",
      "ride_data_df.isnull().sum()\n",
      "43/161:\n",
      "# Data types of each column.\n",
      "ride_data_df.dtypes\n",
      "43/162:\n",
      "# Merge DataFrames.\n",
      "# Combine data into a single dataset.\n",
      "# Syntax, new_df = pd.merge(leftdf, rightdf, on=[\"column_leftdf\", \"column_rightdf\"])\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "# Display DataFrame.\n",
      "pyber_data_df.head()\n",
      "43/163:\n",
      "# Create DataFrames for Each Type of City.\n",
      "# Create scatter plot/bubble chart with average fare versus total number of rides.\n",
      "# Urban, suburban, and rural.\n",
      "# Y-axis= average fare for each city type, mean().\n",
      "# X-axis= total number of rides for each city type, count().\n",
      "# Size of each marker to correlate with average number of drivers for each city type.\n",
      "# Get average [\"driver_count\"] for each city.\n",
      "43/164:\n",
      "# Create separate DataFrames for each City type.\n",
      "# Urban city DataFrame.\n",
      "urban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Urban\"]\n",
      "#urban_cities_df.head()\n",
      "43/165:\n",
      "# Suburban city DataFrame.\n",
      "suburban_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Suburban\"]\n",
      "#suburban_cities_df\n",
      "43/166:\n",
      "# Rural city DataFrame.\n",
      "rural_cities_df = pyber_data_df[pyber_data_df[\"type\"] == \"Rural\"]\n",
      "#rural_cities_df\n",
      "43/167:\n",
      "# Create Data Series for each step, cities' ride count, X-axis, groupby().\n",
      "# Get Number of Rides for Each City Type.\n",
      "# Urban cities' ride count.\n",
      "urban_ride_count = urban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "urban_ride_count.head()\n",
      "43/168:\n",
      "# Suburban cities' ride count.\n",
      "suburban_ride_count = suburban_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "43/169:\n",
      "# Rural cities' ride count.\n",
      "rural_ride_count = rural_cities_df.groupby([\"city\"]).count()[\"ride_id\"]\n",
      "43/170:\n",
      "# Get Average Fare for Each City Type, Y-axis, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' average fare.\n",
      "urban_avg_fare = urban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "urban_avg_fare.head()\n",
      "43/171:\n",
      "# Suburban cities' average fare.\n",
      "suburban_avg_fare = suburban_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "43/172:\n",
      "# Rural cities' average fare.\n",
      "rural_avg_fare = rural_cities_df.groupby([\"city\"]).mean()[\"fare\"]\n",
      "43/173:\n",
      "# Get Average Number of Drivers for Each City Type, marker, .groupby([\"\"]).mean()[\"\"].\n",
      "# Urban cities' driver count.\n",
      "urban_driver_count = urban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "urban_driver_count.head()\n",
      "43/174:\n",
      "# Suburban cities' diver count.\n",
      "suburban_driver_count = suburban_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "43/175:\n",
      "# Rural cities' driver count.\n",
      "rural_driver_count = rural_cities_df.groupby([\"city\"]).mean()[\"driver_count\"]\n",
      "43/176:\n",
      "# Create Scatter plot/Bubble Charts.\n",
      "# Urban Cities Bubble Chart.\n",
      "plt.scatter(urban_ride_count,\n",
      "            urban_avg_fare,\n",
      "            s=10*urban_driver_count, c=\"coral\",\n",
      "            edgecolor=\"black\", linewidths=1,\n",
      "            alpha=0.8, label=\"Urban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()            \n",
      "plt.show()\n",
      "43/177:\n",
      "# Suburban cities scatter plot chart.\n",
      "# Build the scatter plots for suburban cities.\n",
      "plt.scatter(suburban_ride_count,\n",
      "      suburban_avg_fare,\n",
      "      s=10*suburban_driver_count, c=\"skyblue\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Suburban\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show()\n",
      "43/178:\n",
      "# Rural Cities Bubble Chart.\n",
      "plt.scatter(rural_ride_count,\n",
      "      rural_avg_fare,\n",
      "      s=10*rural_driver_count, c=\"gold\",\n",
      "      edgecolor=\"black\", linewidths=1,\n",
      "      alpha=0.8, label=\"Rural\")\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\")\n",
      "plt.ylabel(\"Average Fare ($)\")\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
      "plt.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "43/179:\n",
      "# Create Bubble Chart for All Cities.\n",
      "# Add the scatter charts for each city type.\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "\n",
      "plt.scatter(urban_ride_count,\n",
      "        urban_avg_fare,\n",
      "        s=10*urban_driver_count,\n",
      "        c=\"coral\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Urban\")\n",
      "\n",
      "plt.scatter(suburban_ride_count,\n",
      "        suburban_avg_fare,\n",
      "        s=10*suburban_driver_count,\n",
      "        c=\"skyblue\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Suburban\")\n",
      "\n",
      "plt.scatter(rural_ride_count,\n",
      "        rural_avg_fare,\n",
      "        s=10*rural_driver_count,\n",
      "        c=\"gold\",\n",
      "        edgecolor=\"black\",\n",
      "        linewidths=1,\n",
      "        alpha=0.8,\n",
      "        label=\"Rural\")\n",
      "\n",
      "# Add title, increase font size.\n",
      "plt.title(\"PyBer Ride-Sharing Data (2019)\", fontsize=20)\n",
      "\n",
      "# Add y-axis label, increase font size.\n",
      "plt.ylabel(\"Average Fare ($)\", fontsize=12)\n",
      "\n",
      "# Add x-axis label, increase font size.\n",
      "plt.xlabel(\"Total Number of Rides (Per City)\", fontsize=12)\n",
      "\n",
      "#Add grid.\n",
      "plt.grid(True)\n",
      "\n",
      "# Customize legend to scale all markers to same size, lgnd = plt.legend().\n",
      "# Expand legend horizontally, mode=.\n",
      "# Place legend where \"best\" fit for chart, loc=\"best\".\n",
      "lgnd = plt.legend(fontsize=\"12\",\n",
      "                  mode=\"Expanded\",\n",
      "                  scatterpoints=1,\n",
      "                  loc=\"best\",\n",
      "                  title=\"City Types\")\n",
      "\n",
      "# Add scatter point numbers legend for each marker to be 1, lgnd.legendHandles[]._sizes=[].\n",
      "lgnd.legendHandles[0]._sizes = [75]\n",
      "lgnd.legendHandles[1]._sizes = [75]\n",
      "lgnd.legendHandles[2]._sizes = [75]\n",
      "\n",
      "# Increase legend title's font size.\n",
      "lgnd.get_title().set_fontsize(12)\n",
      "\n",
      "# Add text label for circle size note, plt.text().\n",
      "plt.text(42, 35, \"Note: Circle size correlates with driver count per city.\", fontsize=\"12\")\n",
      "\n",
      "# Save the chart in folder and provide direct path to the folder and filename.\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "plt.savefig(\"analysis/Fig1.png\")\n",
      "\n",
      "plt.show()\n",
      "43/180:\n",
      "# Summary Statistics for Number of Rides by City Type.\n",
      "# Syntax, .describe(), DataFrame or Series\n",
      "# Urban cities' number of rides summary statistics.\n",
      "urban_cities_df.describe()\n",
      "43/181:\n",
      "# Suburban cities' number of rides summary statistics.\n",
      "suburban_cities_df.describe()\n",
      "43/182:\n",
      "# Rural cities' number of rides summary statistics.\n",
      "rural_cities_df.describe()\n",
      "43/183:\n",
      "# Urban cities' ride count summary statistics.\n",
      "urban_ride_count.describe()\n",
      "43/184:\n",
      "# Suburban cities' ride count summary statistics.\n",
      "suburban_ride_count.describe()\n",
      "43/185:\n",
      "# Rural cities' ride count summary statistics.\n",
      "rural_ride_count.describe()\n",
      "43/186:\n",
      "# Ride count mean for each city type.\n",
      "# Syntax, .mean(), .median(), .mode(), Series ONLY.\n",
      "round(urban_ride_count.mean(),2), round(suburban_ride_count.mean(),2), round(rural_ride_count.mean(),2)\n",
      "43/187:\n",
      "# Ride count median for each city type.\n",
      "round(urban_ride_count.median(),2), round(suburban_ride_count.median(),2), round(rural_ride_count.median(),2)\n",
      "43/188:\n",
      "# Urban cities' ride count mode.\n",
      "# Syntax, .mode(), series ONLY.\n",
      "urban_ride_count.mode()\n",
      "43/189:\n",
      "# Suburban cities' ride count mode.\n",
      "suburban_ride_count.mode()\n",
      "43/190:\n",
      "# Rural cities' ride count mode.\n",
      "rural_ride_count.mode()\n",
      "43/191:\n",
      "# Measures of central tendency for each city's ride count, (mean, median, mode), NumPy and SciPy.\n",
      "# This syntax is for Series ONLY.\n",
      "# Measures of central tendency, urban cities' ride count.\n",
      "mean_urban_ride_count = np.mean(urban_ride_count)\n",
      "print(f\"The mean for the ride counts for urban trips is {mean_urban_ride_count:.2f}.\")\n",
      "\n",
      "median_urban_ride_count = np.median(urban_ride_count)\n",
      "print(f\"The median for the ride counts for urban trips is {median_urban_ride_count}.\")\n",
      "\n",
      "mode_urban_ride_count = sts.mode(urban_ride_count)\n",
      "print(f\"The mode for the ride counts for urban trips is {mode_urban_ride_count}.\")\n",
      "# First attribute, mode, 22.\n",
      "# Second attribute, count, number of times mode occurs in dataset, 7.\n",
      "43/192:\n",
      "# Measures of central tendency, suburban cities' ride count.\n",
      "mean_suburban_ride_count = np.mean(suburban_ride_count)\n",
      "print(f\"The mean for the ride counts for suburban trips is {mean_suburban_ride_count:.2f}.\")\n",
      "\n",
      "median_suburban_ride_count = np.median(suburban_ride_count)\n",
      "print(f\"The median for the ride counts for suburban trips is {median_suburban_ride_count}.\")\n",
      "\n",
      "mode_suburban_ride_count = sts.mode(suburban_ride_count)\n",
      "print(f\"The mode for the ride counts for suburban trips is {mode_suburban_ride_count}.\")\n",
      "43/193:\n",
      "# Measures of central tendency, rural cities' ride count.\n",
      "mean_rural_ride_count = np.mean(rural_ride_count)\n",
      "print(f\"The mean for the ride counts for rural trips is {mean_rural_ride_count:.2f}.\")\n",
      "\n",
      "median_rural_ride_count = np.median(rural_ride_count)\n",
      "print(f\"The median for the ride counts for rural trips is {median_rural_ride_count}.\")\n",
      "\n",
      "mode_rural_ride_count = sts.mode(rural_ride_count)\n",
      "print(f\"The mode for the ride counts for rural trips is {mode_rural_ride_count}.\")\n",
      "43/194:\n",
      "# Summary Statistics for Average Fare by City Type.\n",
      "# 1st, get data from \"fare\" column in each city type DataFrame.\n",
      "# Syntax, _cities_df[\"\"].\n",
      "# Urban cities' \"fare\" data.\n",
      "urban_fares = urban_cities_df[\"fare\"]\n",
      "urban_fares.head()\n",
      "43/195:\n",
      "# Measures of central tendency, urban cities' average fare.\n",
      "mean_urban_fares = np.mean(urban_fares)\n",
      "print(f\"The mean fare price for urban trips is ${mean_urban_fares:.2f}.\")\n",
      "\n",
      "median_urban_fares = np.median(urban_fares)\n",
      "print(f\"The median fare price for urban trips is ${median_urban_fares:.2f}.\")\n",
      "\n",
      "mode_urban_fares = sts.mode(urban_fares)\n",
      "print(f\"The mode fare price for urban trips is {mode_urban_fares}.\")\n",
      "43/196:\n",
      "# Suburban cities' fares column data.\n",
      "suburban_fares = suburban_cities_df[\"fare\"]\n",
      "suburban_fares.head()\n",
      "43/197:\n",
      "# Measures of central tendency, suburban cities' average fare.\n",
      "mean_suburban_fares = np.mean(suburban_fares)\n",
      "print(f\"The mean fare price for suburban trips is ${mean_suburban_fares:.2f}.\")\n",
      "\n",
      "median_suburban_fares = np.median(suburban_fares)\n",
      "print(f\"The median fare price for suburban trips is ${median_suburban_fares:.2f}.\")\n",
      "\n",
      "mode_suburban_fares = sts.mode(suburban_fares)\n",
      "print(f\"The mode fare price for suburban trips is {mode_suburban_fares}.\")\n",
      "43/198:\n",
      "# Rural cities' fares column data.\n",
      "rural_fares = rural_cities_df[\"fare\"]\n",
      "rural_fares.head()\n",
      "43/199:\n",
      "# Measures of central tendency, rural cities' average fare.\n",
      "mean_rural_fares = np.mean(rural_fares)\n",
      "print(f\"The mean fare price for rural trips is ${mean_rural_fares:.2f}.\")\n",
      "\n",
      "median_rural_fares = np.median(rural_fares)\n",
      "print(f\"The median fare price for rural trips is ${median_rural_fares:.2f}.\")\n",
      "\n",
      "mode_rural_fares = sts.mode(rural_fares)\n",
      "print(f\"The mode fare price for rural trips is {mode_rural_fares}.\")\n",
      "43/200:\n",
      "# Summary Statistics for Number of Drivers by City Type.\n",
      "# 1st, get data from \"driver_count\" column in each city type DataFrame.\n",
      "# Syntax, _cities_df[\"\"].\n",
      "# Urban cities' \"driver_count\" data.\n",
      "urban_drivers = urban_cities_df['driver_count']\n",
      "urban_drivers.head()\n",
      "43/201:\n",
      "# Measures of central tendency, urban cities' number of drivers.\n",
      "mean_urban_drivers = np.mean(urban_drivers)\n",
      "print(f\"The mean number of drivers for urban trips is {mean_urban_drivers:.2f}.\")\n",
      "\n",
      "median_urban_drivers = np.median(urban_drivers)\n",
      "print(f\"The median number of drivers for urban trips is {median_urban_drivers:.2f}.\")\n",
      "\n",
      "mode_urban_drivers = sts.mode(urban_drivers)\n",
      "print(f\"The mode number of drivers for urban trips is {mode_urban_drivers}.\")\n",
      "43/202:\n",
      "# suburban cities' \"driver_count\" data.\n",
      "suburban_drivers = suburban_cities_df['driver_count']\n",
      "suburban_drivers.head()\n",
      "43/203:\n",
      "# Measures of central tendency, suburban cities' number of drivers.\n",
      "mean_suburban_drivers = np.mean(suburban_drivers)\n",
      "print(f\"The mean number of drivers for suburban trips is {mean_suburban_drivers:.2f}.\")\n",
      "\n",
      "median_suburban_drivers = np.median(suburban_drivers)\n",
      "print(f\"The median number of drivers for suburban trips is {median_suburban_drivers:.2f}.\")\n",
      "\n",
      "mode_suburban_drivers = sts.mode(suburban_drivers)\n",
      "print(f\"The mode number of drivers for suburban trips is {mode_suburban_drivers}.\")\n",
      "43/204:\n",
      "# rural cities' \"driver_count\" data.\n",
      "rural_drivers = rural_cities_df['driver_count']\n",
      "rural_drivers.head()\n",
      "43/205:\n",
      "# Measures of central tendency, rural cities' number of drivers.\n",
      "mean_rural_drivers = np.mean(rural_drivers)\n",
      "print(f\"The mean number of drivers for rural trips is {mean_rural_drivers:.2f}.\")\n",
      "\n",
      "median_rural_drivers = np.median(rural_drivers)\n",
      "print(f\"The median number of drivers for rural trips is {median_rural_drivers:.2f}.\")\n",
      "\n",
      "mode_rural_drivers = sts.mode(rural_drivers)\n",
      "print(f\"The mode number of drivers for rural trips is {mode_rural_drivers}.\")\n",
      "43/206:\n",
      "# Create Box-and-Whisker Plots, ax.boxplot().\n",
      "# Urban cities' ride count box-and-whisker plot.\n",
      "x_labels = [\"Urban\"]\n",
      "fig, ax = plt.subplots()\n",
      "# .boxplot(data,labels)\n",
      "ax.boxplot(urban_ride_count, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Count Data (2019)')\n",
      "ax.set_ylabel('Number of Rides')\n",
      "ax.set_yticks(np.arange(10, 41, step=2.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "43/207:\n",
      "# Suburban cities' ride count box-and-whisker plot.\n",
      "x_labels = [\"suburban\"]\n",
      "fig, ax = plt.subplots()\n",
      "# .boxplot(data,labels)\n",
      "ax.boxplot(suburban_ride_count, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Count Data (2019)')\n",
      "ax.set_ylabel('Number of Rides')\n",
      "ax.set_yticks(np.arange(10, 41, step=2.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "43/208:\n",
      "# Rural cities' ride count box-and-whisker plot.\n",
      "x_labels = [\"rural\"]\n",
      "fig, ax = plt.subplots()\n",
      "# .boxplot(data,labels)\n",
      "ax.boxplot(rural_ride_count, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Count Data (2019)')\n",
      "ax.set_ylabel('Number of Rides')\n",
      "ax.set_yticks(np.arange(10, 41, step=2.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "43/209:\n",
      "# Add ALL ride count box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "ride_count_data = [urban_ride_count, suburban_ride_count, rural_ride_count]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Ride Count Data (2019)',fontsize=20)\n",
      "ax.set_ylabel('Number of Rides',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(ride_count_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 45, step=3.0))\n",
      "ax.grid()\n",
      "# Save the figure.\n",
      "plt.savefig(\"analysis/Fig2.png\")\n",
      "plt.show()\n",
      "43/210:\n",
      "# Find city with highest rider count.\n",
      "# Get the city that matches 39.\n",
      "urban_city_outlier = urban_ride_count[urban_ride_count==39].index[0]\n",
      "print(f\"{urban_city_outlier} has the highest rider count.\")\n",
      "43/211:\n",
      "# Box-and-Whisker Plots for Ride Fare Data.\n",
      "# Urban cities' fare data box-and-whisker plot.\n",
      "x_labels = [\"Urban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(urban_fares, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Fare Data (2019)')\n",
      "ax.set_ylabel('Fare($USD)')\n",
      "ax.set_yticks(np.arange(0, 51, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "urban_fares.describe()\n",
      "43/212:\n",
      "# Suburban cities' fare data box-and-whisker plot.\n",
      "x_labels = [\"suburban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(suburban_fares, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Fare Data (2019)')\n",
      "ax.set_ylabel('Fare($USD)')\n",
      "ax.set_yticks(np.arange(0, 51, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "suburban_fares.describe()\n",
      "43/213:\n",
      "# Rural cities' fare data box-and-whisker plot.\n",
      "x_labels = [\"rural\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(rural_fares, labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Ride Fare Data (2019)')\n",
      "ax.set_ylabel('Fare($USD)')\n",
      "ax.set_yticks(np.arange(0, 51, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "rural_fares.describe()\n",
      "43/214:\n",
      "# Add cities' fare data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "fares_data = [urban_fares, suburban_fares, rural_fares]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Ride Fare Data (2019)', fontsize=20)\n",
      "ax.set_ylabel('Fare($USD)',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(fares_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 60, step=5.0))\n",
      "ax.grid()\n",
      "plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/215:\n",
      "# Box-and-Whisker Plots for Driver Count Data.\n",
      "# Urban cities' driver count data box-and-whisker plot.\n",
      "x_labels = [\"Urban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(urban_drivers,labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Driver Count Data (2019)')\n",
      "ax.set_ylabel('Number of Drivers)')\n",
      "ax.set_yticks(np.arange(0, 90, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "urban_drivers.describe()\n",
      "43/216:\n",
      "# Suburban cities' driver count data box-and-whisker plot.\n",
      "x_labels = [\"suburban\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(suburban_drivers,labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Driver Count Data (2019)')\n",
      "ax.set_ylabel('Number of Drivers)')\n",
      "ax.set_yticks(np.arange(0, 90, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "suburban_drivers.describe()\n",
      "43/217:\n",
      "# Rural cities' driver count data box-and-whisker plot.\n",
      "x_labels = [\"rural\"]\n",
      "fig, ax = plt.subplots()\n",
      "ax.boxplot(rural_drivers,labels=x_labels)\n",
      "# Add the title, y-axis label and grid.\n",
      "ax.set_title('Driver Count Data (2019)')\n",
      "ax.set_ylabel('Number of Drivers)')\n",
      "ax.set_yticks(np.arange(0, 90, step=5.0))\n",
      "ax.grid()\n",
      "plt.show()\n",
      "print(\"Summary Statistics\")\n",
      "rural_drivers.describe()\n",
      "43/218:\n",
      "# Add cities' driver count data box-and-whisker plots to the same graph.\n",
      "x_labels = [\"Urban\", \"Suburban\",\"Rural\"]\n",
      "drivers_data = [urban_drivers, suburban_drivers, rural_drivers]\n",
      "# Increase size chart.\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "# Increase font sizes.\n",
      "ax.set_title('Driver Count (2019)', fontsize=20)\n",
      "ax.set_ylabel('Number of Drivers',fontsize=14)\n",
      "ax.set_xlabel(\"City Types\",fontsize=14)\n",
      "ax.boxplot(drivers_data, labels=x_labels)\n",
      "ax.set_yticks(np.arange(0, 76, step=5.0))\n",
      "ax.grid()\n",
      "plt.savefig(\"analysis/Fig3.png\")\n",
      "plt.show()\n",
      "43/219:\n",
      "# Get Percentage of Fares for Each City Type.\n",
      "# 1, Get the total fares for each city type.\n",
      "# 2, Get the total for all the fares for all the city types.\n",
      "# 3, Calculate the percentage of the total fares for each city type.\n",
      "43/220:\n",
      "# Get the sum of the fares for each city type.\n",
      "sum_fares_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "sum_fares_by_type\n",
      "43/221:\n",
      "# Get the sum of ALL the fares.\n",
      "total_fares = pyber_data_df[\"fare\"].sum()\n",
      "total_fares\n",
      "43/222:\n",
      "# Calculate the percentage of \"fare\" for each city \"type\".\n",
      "type_percents = 100 * sum_fares_by_type / total_fares\n",
      "type_percents\n",
      "43/223:\n",
      "# Advanced syntax:\n",
      "# Calculate the percentage of fare for each city type.\n",
      "#type_percents = 100 * pyber_data_df.groupby([\"type\"]).sum()[\"fare\"] / pyber_data_df[\"fare\"].sum()\n",
      "#type_percents\n",
      "43/224:\n",
      "# Percentage of Fares Pie Chart by City Type, MATLAB approach, plt.pie().\n",
      "# Each pie wedge will represent a city and its percentage of the total fares.\n",
      "# The labels will be the city type.\n",
      "# Build the percentage of fares by city type pie chart.\n",
      "plt.pie(type_percents,\n",
      "        labels=[\"Rural\", \"Suburban\", \"Urban\"]\n",
      "        colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "        explode=[0, 0, 0.1],\n",
      "        autopct='%1.1f%%',\n",
      "        shadow=True,\n",
      "        startangle=150)\n",
      "plt.title(\"% of Total Fares by City Type\")\n",
      "plt.show()\n",
      "43/225:\n",
      "# Percentage of Fares Pie Chart by City Type, MATLAB approach, plt.pie().\n",
      "# Each pie wedge will represent a city and its percentage of the total fares.\n",
      "# The labels will be the city type.\n",
      "# Build the percentage of fares by city type pie chart.\n",
      "plt.pie(type_percents,\n",
      "        labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "        colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "        explode=[0, 0, 0.1],\n",
      "        autopct='%1.1f%%',\n",
      "        shadow=True,\n",
      "        startangle=150)\n",
      "plt.title(\"% of Total Fares by City Type\")\n",
      "plt.show()\n",
      "43/226:\n",
      "# Percentage of Fares Pie Chart by City Type, MATLAB approach, plt.pie().\n",
      "# Import mpl to change the plot configurations using rcParams.\n",
      "import matplotlib as mpl\n",
      "# Each pie wedge will represent a city and its percentage of the total fares.\n",
      "# The labels will be the city type.\n",
      "# Build the percentage of fares by city type pie chart.\n",
      "plt.pie(type_percents,\n",
      "        labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "        colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "        explode=[0, 0, 0.1],\n",
      "        autopct='%1.1f%%',\n",
      "        shadow=True,\n",
      "        startangle=150)\n",
      "plt.title(\"% of Total Fares by City Type\")\n",
      "# Change the default font size from 10 to 14.\n",
      "# Syntax, rcParams (must import matplotlib as mpl first) because there is no parameter for fontsize in pie charts.\n",
      "mpl.rcParams['font.size'] = 14\n",
      "# Save Figure\n",
      "#plt.savefig(\"analysis/Fig5.png\")\n",
      "plt.show()\n",
      "43/227:\n",
      "# Percentage of Fares Pie Chart by City Type, MATLAB approach, plt.pie().\n",
      "# Import mpl to change the plot configurations using rcParams.\n",
      "import matplotlib as mpl\n",
      "# Each pie wedge will represent a city and its percentage of the total fares.\n",
      "# The labels will be the city type.\n",
      "# Build percentage of fares by city type pie chart.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "plt.pie(type_percents,\n",
      "        labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "        colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "        explode=[0, 0, 0.1],\n",
      "        autopct='%1.1f%%',\n",
      "        shadow=True,\n",
      "        startangle=150)\n",
      "plt.title(\"% of Total Fares by City Type\")\n",
      "# Change the default font size from 10 to 14.\n",
      "# Syntax, rcParams (must import matplotlib as mpl first) because there is no parameter for fontsize in pie charts.\n",
      "mpl.rcParams['font.size'] = 14\n",
      "# Save Figure\n",
      "#plt.savefig(\"analysis/Fig5.png\")\n",
      "plt.show()\n",
      "43/228:\n",
      "# Percentage of Fares Pie Chart by City Type, MATLAB approach, plt.pie().\n",
      "# Import mpl to change the plot configurations using rcParams.\n",
      "import matplotlib as mpl\n",
      "# Each pie wedge will represent a city and its percentage of the total fares.\n",
      "# The labels will be the city type.\n",
      "# Build percentage of fares by city type pie chart.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "plt.pie(type_percents,\n",
      "        labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "        colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "        explode=[0, 0, 0.1],\n",
      "        autopct='%1.1f%%',\n",
      "        shadow=True,\n",
      "        startangle=150)\n",
      "plt.title(\"% of Total Fares by City Type\")\n",
      "# Change the default font size from 10 to 14.\n",
      "# Syntax, rcParams (must import matplotlib as mpl first) because there is no parameter for fontsize in pie charts.\n",
      "mpl.rcParams['font.size'] = 14\n",
      "# Save Figure\n",
      "plt.savefig(\"analysis/Fig5.png\")\n",
      "plt.show()\n",
      "43/229:\n",
      "# Calculate Ride Percentages.\n",
      "# 1, Get the total number of rides for each city type.\n",
      "# 2, Get the total for all the rides for all the city types.\n",
      "# 3, Calculate the percentage of the total rides for each city type.\n",
      "43/230:\n",
      "# To get the total rides for each type.\n",
      "# First, create a Series of data where the index is the type of city.\n",
      "# Group group pyber_data_df by the type of city column.\n",
      "# Syntax, _df.groupby([\"\"])\n",
      "pyber_data_df.groupby([\"type\"])\n",
      "# Second, make the column for the Series the number of the rides for the type of city.\n",
      "# Get the Series with the total number of rides for each city type.\n",
      "# Syntax, _df.groupby([\"\"]).count()[\"\"]\n",
      "pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "# Third, get the number of total rides, use .count(), on \"ride_id \" from pyber_data_df.\n",
      "pyber_data_df[\"ride_id\"].count()\n",
      "# Calculate the percentage of rides for each city type.\n",
      "# Divide the total number of rides for each city type by the total rides for all the cities and divide by 100.\n",
      "ride_percents = 100 * pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"] / pyber_data_df[\"ride_id\"].count()\n",
      "ride_percents\n",
      "43/231:\n",
      "# Calculate Ride Percentages.\n",
      "# 1, Get the total number of rides for each city type.\n",
      "# 2, Get the total for all the rides for all the city types.\n",
      "# 3, Calculate the percentage of the total rides for each city type.\n",
      "43/232:\n",
      "# To get the total rides for each type.\n",
      "# First, create a Series of data where the index is the type of city.\n",
      "# Group group pyber_data_df by the type of city column.\n",
      "# Syntax, _df.groupby([\"\"])\n",
      "pyber_data_df.groupby([\"type\"])\n",
      "43/233:\n",
      "# Second, make the column for the Series the number of the rides for the type of city.\n",
      "# Get the Series with the total number of rides for each city type.\n",
      "# Syntax, _df.groupby([\"\"]).count()[\"\"]\n",
      "pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "43/234:\n",
      "# Third, get the number of total rides, use .count(), on \"ride_id \" from pyber_data_df.\n",
      "pyber_data_df[\"ride_id\"].count()\n",
      "43/235:\n",
      "# Calculate the percentage of rides for each city type.\n",
      "# Divide the total number of rides for each city type by the total rides for all the cities and divide by 100.\n",
      "ride_percents = 100 * pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"] / pyber_data_df[\"ride_id\"].count()\n",
      "ride_percents\n",
      "43/236:\n",
      "# To get the total rides for each type.\n",
      "# First, create a Series of data where the index is the type of city.\n",
      "# Group group pyber_data_df by the type of city column.\n",
      "# Syntax, _df.groupby([\"\"])\n",
      "pyber_data_df.groupby([\"type\"])\n",
      "\n",
      "# Second, make the column for the Series the number of the rides for the type of city.\n",
      "# Get the Series with the total number of rides for each city type.\n",
      "# Syntax, _df.groupby([\"\"]).count()[\"\"]\n",
      "pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "43/237:\n",
      "# To get the total rides for each type.\n",
      "# First, create a Series of data where the index is the type of city.\n",
      "# Group group pyber_data_df by the type of city column.\n",
      "# Syntax, _df.groupby([\"\"])\n",
      "pyber_data_df.groupby([\"type\"])\n",
      "\n",
      "# Second, make the column for the Series the number of the rides for the type of city.\n",
      "# Get the Series with the total number of rides for each city type.\n",
      "# Syntax, _df.groupby([\"\"]).count()[\"\"]\n",
      "pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "43/238:\n",
      "# Third, get the number of total rides, use .count(), on \"ride_id \" from pyber_data_df.\n",
      "pyber_data_df[\"ride_id\"].count()\n",
      "43/239:\n",
      "# Calculate the percentage of rides for each city type.\n",
      "# Divide the total number of rides for each city type by the total rides for all the cities and divide by 100.\n",
      "ride_percents = 100 * pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"] / pyber_data_df[\"ride_id\"].count()\n",
      "ride_percents\n",
      "43/240:\n",
      "# Pie Chart for Percentage of Rides by City Type.\n",
      "# Build percentage of rides by city type pie chart.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "plt.pie(ride_percents,\n",
      "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "    explode=[0, 0, 0.1],\n",
      "    autopct='%1.1f%%',\n",
      "    shadow=True, startangle=150)\n",
      "plt.title(\"% of Total Rides by City Type\")\n",
      "# Change the default font size from 10 to 14.\n",
      "mpl.rcParams['font.size'] = 14\n",
      "# Save Figure\n",
      "plt.savefig(\"analysis/Fig6.png\")\n",
      "# Show Figure\n",
      "plt.show()\n",
      "43/241:\n",
      "# To get the total rides for each type.\n",
      "# First, create a Series of data where the index is the type of city.\n",
      "# Group group pyber_data_df by the type of city column.\n",
      "# Syntax, _df.groupby([\"\"])\n",
      "# pyber_data_df.groupby([\"type\"])\n",
      "# Second, add the column for the Series the number of the rides for the type of city.\n",
      "# Syntax, [\"ride_id\"]\n",
      "# Get the Series with the total number of rides for each city type.\n",
      "# Syntax, _df.groupby([\"\"]).count()[\"\"]\n",
      "pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "43/242:\n",
      "# Calculate Driver Percentages.\n",
      "# 1, Get the total number of drivers for each city type.\n",
      "# 2, Get the total drivers for all the city types.\n",
      "# 3, Calculate the percentage of the total drivers for each city type.\n",
      "43/243:\n",
      "# 1, Get the total number of drivers for each city type.\n",
      "# To get the Series with the total number of drivers for each city type:\n",
      "# Use .groupby() on city_data_df to group by \"type\" of city column.\n",
      "# Syntax, city_data_df.groupby([\"type\"])\n",
      "# Apply sum() on \"driver_count\" column.\n",
      "city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "43/244:\n",
      "# 2, Get the total number of drivers using sum() on the \"driver_count\" column from the city_data_df.\n",
      "city_data_df[\"driver_count\"].sum()\n",
      "43/245:\n",
      "# Calculate the percentage of drivers for each city type.\n",
      "# Divide the Series for the total number of drivers for each city type by the number of total drivers and multiply by 100.\n",
      "driver_percents = 100 *\n",
      "city_data_df.groupby([\"type\"]).sum()[\"driver_count\"] /\n",
      "city_data_df[\"driver_count\"].sum()\n",
      "driver_percents\n",
      "43/246:\n",
      "# Calculate the percentage of drivers for each city type.\n",
      "# Divide the Series for the total number of drivers for each city type by the number of total drivers and multiply by 100.\n",
      "driver_percents = 100 *city_data_df.groupby([\"type\"]).sum()[\"driver_count\"] /\n",
      "city_data_df[\"driver_count\"].sum()\n",
      "driver_percents\n",
      "43/247:\n",
      "# Calculate the percentage of drivers for each city type.\n",
      "# Divide the Series for the total number of drivers for each city type by the number of total drivers and multiply by 100.\n",
      "driver_percents =city_data_df.groupby([\"type\"]).sum()[\"driver_count\"] /\n",
      "city_data_df[\"driver_count\"].sum()*100\n",
      "driver_percents\n",
      "43/248:\n",
      "# Calculate the percentage of drivers for each city type.\n",
      "# Divide the Series for the total number of drivers for each city type by the number of total drivers and multiply by 100.\n",
      "driver_percents =100*city_data_df.groupby([\"type\"]).sum()[\"driver_count\"] /\n",
      "city_data_df[\"driver_count\"].sum()driver_percents\n",
      "43/249:\n",
      "# Calculate the percentage of drivers for each city type.\n",
      "# Divide the Series for the total number of drivers for each city type by the number of total drivers and multiply by 100.\n",
      "driver_percents =100*city_data_df.groupby([\"type\"]).sum()[\"driver_count\"] /city_data_df[\"driver_count\"].sum()driver_percents\n",
      "43/250:\n",
      "# Calculate the percentage of drivers for each city type.\n",
      "# Divide the Series for the total number of drivers for each city type by the number of total drivers and multiply by 100.\n",
      "driver_percents =100*city_data_df.groupby([\"type\"]).sum()[\"driver_count\"] /city_data_df[\"driver_count\"].sum()\n",
      "driver_percents\n",
      "43/251:\n",
      "# Pie Chart for the Percentage of Drivers for Each City Type.\n",
      "# Build percentage of rides by city type pie chart.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "plt.pie(driver_percents,\n",
      "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "    explode=[0, 0, 0.1],\n",
      "    autopct='%1.1f%%',\n",
      "    shadow=True, startangle=165)\n",
      "plt.title(\"% of Total Drivers by City Type\")\n",
      "# Change the default font size from 10 to 14.\n",
      "mpl.rcParams['font.size'] = 14\n",
      "# Save Figure\n",
      "#plt.savefig(\"analysis/Fig7.png\")\n",
      "# Show Figure\n",
      "plt.show()\n",
      "43/252:\n",
      "# Pie Chart for the Percentage of Drivers for Each City Type.\n",
      "# Build percentage of rides by city type pie chart.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "plt.pie(driver_percents,\n",
      "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "    explode=[0, 0, 0.1],\n",
      "    autopct='%1.1f%%',\n",
      "    shadow=True,\n",
      "    startangle=165)\n",
      "plt.title(\"% of Total Rides by City Type\")\n",
      "# Change the default font size from 10 to 14.\n",
      "mpl.rcParams['font.size'] = 14\n",
      "# Save Figure\n",
      "#plt.savefig(\"analysis/Fig7.png\")\n",
      "# Show Figure\n",
      "plt.show()\n",
      "43/253:\n",
      "# Pie Chart for the Percentage of Drivers for Each City Type.\n",
      "# Build percentage of rides by city type pie chart.\n",
      "plt.subplots(figsize=(10, 6))\n",
      "plt.pie(driver_percents,\n",
      "    labels=[\"Rural\", \"Suburban\", \"Urban\"],\n",
      "    colors=[\"gold\", \"lightskyblue\", \"lightcoral\"],\n",
      "    explode=[0, 0, 0.1],\n",
      "    autopct='%1.1f%%',\n",
      "    shadow=True,\n",
      "    startangle=165)\n",
      "plt.title(\"% of Total Rides by City Type\")\n",
      "# Change the default font size from 10 to 14.\n",
      "mpl.rcParams['font.size'] = 14\n",
      "# Save Figure\n",
      "plt.savefig(\"analysis/Fig7.png\")\n",
      "# Show Figure\n",
      "plt.show()\n",
      "51/1:\n",
      "#  1. Get the total rides for each city type\n",
      "rides_count = pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "rides_count\n",
      "51/2:\n",
      "#  1. Get the total rides for each city type\n",
      "rides_count_df= pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "rides_count_df\n",
      "51/3:\n",
      "#  1. Get the total rides for each city type\n",
      "total_rides_by_type= pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "rides_count_df\n",
      "51/4:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "51/5:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "51/6:\n",
      "#  1. Get the total rides for each city type\n",
      "total_rides_by_type= pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "rides_count_df\n",
      "51/7:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_rides_by_type= pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "total_rides_by_type\n",
      "51/8:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "51/9:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "51/10:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_rides_by_type = pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "total_rides_by_type\n",
      "51/11:\n",
      "# 2. Get the total drivers for each city type\n",
      "drivers_count = pyber_data_df.groupby([\"type\"].sum()[\"driver_count\"]\n",
      "drivers_count\n",
      "51/12: #  3. Get the total amount of fares for each city type\n",
      "51/13:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_rides_by_type = pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "total_rides_by_type.head()\n",
      "51/14:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_rides_by_type = pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "51/15:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "51/16:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "51/17:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_rides_by_type = pyber_data_df.groupby([\"type\"].count()[\"ride_id\"]\n",
      "51/18:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_rides_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_rides_by_type\n",
      "51/19:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_drivers_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_drivers_by_type\n",
      "51/20:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "51/21:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "51/22:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "51/23:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_city=total_fare_by_type/total_ride_by_type*100\n",
      "51/24:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = city_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "51/25:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "51/26:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "51/27:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "51/28:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "51/29:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = city_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "51/30:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "51/31:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "51/32:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_city=total_fare_by_type/total_ride_by_type*100\n",
      "avg_fare_per_city\n",
      "51/33:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_city=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_city\n",
      "51/34:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_ride=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_ride\n",
      "51/35:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "51/36:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "avg_fare_per_driver\n",
      "51/37:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "51/38:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.dataframe({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "51/39:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.DataFrame({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "51/40:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2}\".format)\n",
      "pyber_summary_df\n",
      "51/41:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "51/42:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:.2f}\".format)\n",
      "pyber_summary_df\n",
      "51/43:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:.1f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:.1f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:.1f}\".format)\n",
      "pyber_summary_df\n",
      "51/44:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:.1f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:.1f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:.1f}\".format)\n",
      "pyber_summary_df\n",
      "51/45:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "51/46:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "51/47:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "51/48:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "51/49:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "51/50:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "51/51:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_ride=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_ride\n",
      "51/52:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "avg_fare_per_driver\n",
      "51/53:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.DataFrame({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "51/54:\n",
      "#  7. Cleaning up the DataFrame. Delete the index name\n",
      "pyber_summary_df.index.name = None\n",
      "51/55:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "51/56:\n",
      "# 1. Read the merged DataFrame\n",
      "pyber_data.df\n",
      "51/57:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "51/58:\n",
      "# 1. Read the merged DataFrame\n",
      "pyber_data_df\n",
      "51/59:\n",
      "# 2. Using groupby() to create a new DataFrame showing the sum of the fares \n",
      "#  for each date where the indices are the city type and date.\n",
      "total_fare_by_date_df=pyber_data_df.groupby([\"type\",\"date\"]).sum()[\"fare\"]\n",
      "total_fare_by_date_df\n",
      "51/60:\n",
      "# 2. Using groupby() to create a new DataFrame showing the sum of the fares \n",
      "#  for each date where the indices are the city type and date.\n",
      "total_fare_by_date_df=pyber_data_df.groupby([\"type\",\"date\"]).sum()[\"fare\"]\n",
      "total_fare_by_date_df.head()\n",
      "51/61:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "51/62:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "51/63:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "51/64:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "51/65:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "51/66:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_ride=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_ride\n",
      "51/67:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "avg_fare_per_driver\n",
      "51/68:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.DataFrame({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "51/69:\n",
      "#  7. Cleaning up the DataFrame. Delete the index name\n",
      "pyber_summary_df.index.name = None\n",
      "51/70:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "51/71:\n",
      "# 1. Read the merged DataFrame\n",
      "pyber_data_df\n",
      "51/72:\n",
      "# 2. Using groupby() to create a new DataFrame showing the sum of the fares \n",
      "#  for each date where the indices are the city type and date.\n",
      "total_fare_by_date_df=pyber_data_df.groupby([\"type\",\"date\"]).sum()[\"fare\"]\n",
      "total_fare_by_date_df.head()\n",
      "51/73:\n",
      "# 2. Using groupby() to create a new DataFrame showing the sum of the fares \n",
      "#  for each date where the indices are the city type and date.\n",
      "total_fare_by_date_df=pyber_data_df.groupby([\"type\",\"date\"]).sum()[[\"fare\"]]\n",
      "total_fare_by_date_df.head()\n",
      "51/74:\n",
      "# 3. Reset the index on the DataFrame you created in #1. This is needed to use the 'pivot()' function.\n",
      "# df = df.reset_index()\n",
      "total_fare_by_date_df= df.reset_index()\n",
      "total_fare_by_date_df\n",
      "51/75:\n",
      "# 3. Reset the index on the DataFrame you created in #1. This is needed to use the 'pivot()' function.\n",
      "# df = df.reset_index()\n",
      "total_fare_by_date_df= total_fare_by_date_df.reset_index()\n",
      "total_fare_by_date_df\n",
      "51/76:\n",
      "# 2. Using groupby() to create a new DataFrame showing the sum of the fares \n",
      "#  for each date where the indices are the city type and date.\n",
      "total_fare_by_date_df=pyber_data_df.groupby([\"type\",\"date\"]).sum()[[\"fare\"]]\n",
      "total_fare_by_date_df\n",
      "51/77:\n",
      "# 3. Reset the index on the DataFrame you created in #1. This is needed to use the 'pivot()' function.\n",
      "# df = df.reset_index()\n",
      "total_fare_by_date_df= total_fare_by_date_df.reset_index()\n",
      "total_fare_by_date_df\n",
      "51/78:\n",
      "# 4. Create a pivot table with the 'date' as the index, the columns ='type', and values='fare' \n",
      "# to get the total fares for each type of city by the date. \n",
      "total_fare_by_date_table=total_fare_by_date.pivot(index=\"date\",columns=\"type\",values=\"fare\")\n",
      "total_fare_by_date_table\n",
      "51/79:\n",
      "# 4. Create a pivot table with the 'date' as the index, the columns ='type', and values='fare' \n",
      "# to get the total fares for each type of city by the date. \n",
      "total_fare_by_date_table=total_fare_by_date_df.pivot(index=\"date\",columns=\"type\",values=\"fare\")\n",
      "total_fare_by_date_table\n",
      "51/80:\n",
      "# 4. Create a pivot table with the 'date' as the index, the columns ='type', and values='fare' \n",
      "# to get the total fares for each type of city by the date. \n",
      "total_fare_by_date_table=total_fare_by_date_df.pivot(index=\"date\",columns=\"type\",values=\"fare\")\n",
      "total_fare_by_date_table.head()\n",
      "51/81:\n",
      "# 4. Create a pivot table with the 'date' as the index, the columns ='type', and values='fare' \n",
      "# to get the total fares for each type of city by the date. \n",
      "total_fare_by_date_table=total_fare_by_date_df.pivot(index=\"date\",columns=\"type\",values=\"fare\")\n",
      "total_fare_by_date_table.head(10)\n",
      "51/82:\n",
      "# 4. Create a pivot table with the 'date' as the index, the columns ='type', and values='fare' \n",
      "# to get the total fares for each type of city by the date. \n",
      "total_fare_by_date_pivot=total_fare_by_date_df.pivot(index=\"date\",columns=\"type\",values=\"fare\")\n",
      "total_fare_by_date_pivot.head(10)\n",
      "51/83:\n",
      "# 5. Create a new DataFrame from the pivot table DataFrame using loc on the given dates, '2019-01-01':'2019-04-29'.\n",
      "total_fare_by_date_pivot_df=total_fare_by_date_pivot.loc[(\"2019-01-01':'2019-04-29\")]\n",
      "total_fare_by_date_pivot_df\n",
      "51/84:\n",
      "# 5. Create a new DataFrame from the pivot table DataFrame using loc on the given dates, '2019-01-01':'2019-04-29'.\n",
      "total_fare_by_date_pivot_df=total_fare_by_date_pivot.loc[\"2019-01-01':'2019-04-29\"]\n",
      "total_fare_by_date_pivot_df\n",
      "51/85:\n",
      "# 5. Create a new DataFrame from the pivot table DataFrame using loc on the given dates, '2019-01-01':'2019-04-29'.\n",
      "total_fare_by_date_pivot_df=total_fare_by_date_pivot.loc[(\"2019-01-01\":\"2019-04-29\")]\n",
      "total_fare_by_date_pivot_df\n",
      "51/86:\n",
      "# 5. Create a new DataFrame from the pivot table DataFrame using loc on the given dates, '2019-01-01':'2019-04-29'.\n",
      "total_fare_by_date_pivot_df=total_fare_by_date_pivot.loc[\"2019-01-01\":\"2019-04-29\"]\n",
      "total_fare_by_date_pivot_df\n",
      "51/87:\n",
      "# 5. Create a new DataFrame from the pivot table DataFrame using loc on the given dates, '2019-01-01':'2019-04-29'.\n",
      "total_fare_by_date_pivot_df=total_fare_by_date_pivot.loc[\"2019-01-01\":\"2019-04-29\"]\n",
      "total_fare_by_date_pivot_df\n",
      "51/88:\n",
      "# 6. Set the \"date\" index to datetime datatype. This is necessary to use the resample() method in Step 8.\n",
      "# df.index = pd.to_datetime(df.index)\n",
      "total_fare_by_date_pivot_df.index=pd.to_datetime(df.index)\n",
      "51/89:\n",
      "# 5. Create a new DataFrame from the pivot table DataFrame using loc on the given dates, '2019-01-01':'2019-04-29'.\n",
      "total_fare_by_date_pivot_df=total_fare_by_date_pivot.loc[\"2019-01-01\":\"2019-04-29\"]\n",
      "total_fare_by_date_pivot_df\n",
      "51/90:\n",
      "# 6. Set the \"date\" index to datetime datatype. This is necessary to use the resample() method in Step 8.\n",
      "# df.index = pd.to_datetime(df.index)\n",
      "total_fare_by_date_pivot_df.index=pd.to_datetime(df.index)\n",
      "51/91:\n",
      "# 6. Set the \"date\" index to datetime datatype. This is necessary to use the resample() method in Step 8.\n",
      "# df.index = pd.to_datetime(df.index)\n",
      "total_fare_by_date_pivot_df.index=pd.to_datetime(total_fare_by_date_pivot_df.index)\n",
      "51/92: # 7. Check that the datatype for the index is datetime using df.info()\n",
      "51/93:\n",
      "# 6. Set the \"date\" index to datetime datatype. This is necessary to use the resample() method in Step 8.\n",
      "# df.index = pd.to_datetime(df.index)\n",
      "total_fare_by_date_pivot_df.index=pd.to_datetime(total_fare_by_date_pivot_df.index)\n",
      "total_fare_by_date_pivot_df\n",
      "51/94:\n",
      "# 7. Check that the datatype for the index is datetime using df.info()\n",
      "total_fare_by_date_pivot_df.info()\n",
      "51/95:\n",
      "# 8. Create a new DataFrame using the \"resample()\" function by week 'W' and get the sum of the fares for each week.\n",
      "total_fare_by_week_df=total_fare_by_date_pivot.resample(\"w\")\n",
      "total_fare_by_week_df\n",
      "51/96:\n",
      "# 8. Create a new DataFrame using the \"resample()\" function by week 'W' and get the sum of the fares for each week.\n",
      "total_fare_by_week_df=total_fare_by_date_pivot.resample(\"w\").sum()\n",
      "total_fare_by_week_df\n",
      "51/97:\n",
      "# 8. Create a new DataFrame using the \"resample()\" function by week 'W' and get the sum of the fares for each week.\n",
      "total_fare_by_week_df=total_fare_by_date_pivot_df.resample(\"w\").sum()\n",
      "total_fare_by_week_df\n",
      "51/98:\n",
      "# 8. Create a new DataFrame using the \"resample()\" function by week 'W' and get the sum of the fares for each week.\n",
      "total_fare_by_week_df=total_fare_by_date_pivot_df.resample(\"w\").sum()\n",
      "total_fare_by_week_df.head(11)\n",
      "51/99:\n",
      "# 8. Create a new DataFrame using the \"resample()\" function by week 'W' and get the sum of the fares for each week.\n",
      "total_fare_by_week_df=total_fare_by_date_pivot_df.resample(\"w\").sum()\n",
      "total_fare_by_week_df.head(10)\n",
      "51/100:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "fig, ax = plt.subplots()\n",
      "total_fare_by_week_df.plot(x_axis, \n",
      "                           y_axis,\n",
      "                           label=\"type\")\n",
      "                           #x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show\n",
      "51/101:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "fig, ax = plt.subplots()\n",
      "total_fare_by_week_df.plot(#x_axis, \n",
      "                           y_axis,\n",
      "                           label=\"type\")\n",
      "                           #x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show\n",
      "51/102:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "fig, ax = plt.subplots()\n",
      "total_fare_by_week_df.plot(#x_axis, \n",
      "                           #y_axis,\n",
      "                           label=\"type\")\n",
      "                           #x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show\n",
      "51/103:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "fig, ax = plt.subplots(figsize=(10,6))\n",
      "total_fare_by_week_df.plot(#x_axis, \n",
      "                           #y_axis,\n",
      "                           label=\"type\")\n",
      "                           #x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid(true)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "plt.show\n",
      "51/104:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "fig, ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "#total_fare_by_week_df.plot(#x_axis, \n",
      "                           #y_axis,\n",
      "                           #label=\"type\")\n",
      "                           #x_axis, y_axis, marker=\"d\", color=\"green\", linewidth=2, label=\"Boston\")\n",
      "# Create labels for the x and y axes.\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid(true)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/105:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "fig, ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid(true)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/106:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "fig, ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid(true)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/107:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "\n",
      "plt.xlabel(\"2019\")\n",
      "plt.ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "plt.ylim(0, 2500, step=500)\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid(true)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/108:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "fig, ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 2500, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid(true)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/109:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 2500, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid(true)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/110:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 2500, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "plt.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/111:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 2500, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid()\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/112:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(10,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 2500, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/113:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 2500, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/114:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show\n",
      "51/115:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "plt.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/116:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label\n",
      "ax.set_xlabel(\"2019\")\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y limit between 0 and 45.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "plt.title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/117:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"2019\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/118:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"2019\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(x,y, label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/119:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"2019\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/120:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "fig, ax = plt.subplots()\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"2019\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/121:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"2019\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/122:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"2019\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend(\"type\")\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/123:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"2019\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/124:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/125:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(18,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/126:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(18,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"line\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/127:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(20,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/128:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot(label=\"type\")\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "ax.legend()\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/129:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(label=\"type\")\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/130:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"type\")\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/131:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"City Type\", loc=best)\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/132:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"City Type\", loc=\"best\")\n",
      "# Syntax, plt.savefig(\"folder/filename\")\n",
      "#plt.savefig(\"analysis/Fig1.png\")\n",
      "plt.show()\n",
      "51/133:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(18,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"Type\", loc=\"best\")\n",
      "#plt.savefig(\"analysis/PyBer_fare_summary.png\")\n",
      "plt.show()\n",
      "51/134:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"Type\", loc=\"best\")\n",
      "#plt.savefig(\"analysis/PyBer_fare_summary.png\")\n",
      "plt.show()\n",
      "51/135:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(16,6))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($USD)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"Type\", loc=\"best\")\n",
      "#plt.savefig(\"analysis/PyBer_fare_summary.png\")\n",
      "plt.show()\n",
      "51/136:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(20,5))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($USD)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"Type\", loc=\"best\")\n",
      "#plt.savefig(\"analysis/PyBer_fare_summary.png\")\n",
      "plt.show()\n",
      "51/137:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(20,5))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($USD)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"Type\", loc=\"best\")\n",
      "plt.savefig(\"analysis/PyBer_fare_summary.png\")\n",
      "plt.show()\n",
      "54/1:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "54/2:\n",
      "import pandas as pd\n",
      "pandas.__version__\n",
      "54/3:\n",
      "import pandas as pd\n",
      "pd.__version__\n",
      "54/4:\n",
      "import matplotlib.pyplot as plt\n",
      "plt.__version__\n",
      "54/5:\n",
      "import numpy as np\n",
      "np.__version__\n",
      "54/6:\n",
      "import matplotlib\n",
      "matplotlib.__version__\n",
      "54/7: jupyter.__version__\n",
      "54/8: jupyternotebook.__version__\n",
      "54/9: notebook.__version__\n",
      "54/10: python.__version__\n",
      "54/11: pythondata.__version__\n",
      "54/12: sts.__version__\n",
      "54/13:\n",
      "import scipy.stats as sts\n",
      "sts.__version__\n",
      "54/14: anaconda.__version__\n",
      "54/15:\n",
      "import os\n",
      "os.__version__\n",
      "53/1:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "plt.savefig(\"analysis/PyBer_summary.png\")\n",
      "pyber_summary_df\n",
      "53/2:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "53/3:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "53/4:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "53/5:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "53/6:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "53/7:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_ride=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_ride\n",
      "53/8:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "avg_fare_per_driver\n",
      "53/9:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.DataFrame({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "53/10:\n",
      "#  7. Cleaning up the DataFrame. Delete the index name\n",
      "pyber_summary_df.index.name = None\n",
      "53/11:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "plt.savefig(\"analysis/PyBer_summary.png\")\n",
      "pyber_summary_df\n",
      "53/12:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "savefig(\"analysis/PyBer_summary.png\")\n",
      "53/13:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "plt.savefig(\"analysis/PyBer_summary.png\")\n",
      "53/14:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "53/15:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "53/16:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "53/17:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "53/18:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "53/19:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_ride=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_ride\n",
      "53/20:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "avg_fare_per_driver\n",
      "53/21:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.DataFrame({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "53/22:\n",
      "#  7. Cleaning up the DataFrame. Delete the index name\n",
      "pyber_summary_df.index.name = None\n",
      "53/23:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "plt.savefig(\"analysis/PyBer_summary.png\")\n",
      "53/24:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "plt.savefig(\"analysis/PyBer_summary.png\")\n",
      "pyber_summary_df\n",
      "53/25:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "53/26:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "53/27:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "53/28:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "53/29:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "53/30:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_ride=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_ride\n",
      "53/31:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "avg_fare_per_driver\n",
      "53/32:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.DataFrame({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "53/33:\n",
      "#  7. Cleaning up the DataFrame. Delete the index name\n",
      "pyber_summary_df.index.name = None\n",
      "53/34:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "plt.savefig(\"analysis/PyBer_summary.png\")\n",
      "pyber_summary_df\n",
      "53/35:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "53/36:\n",
      "# Add Matplotlib inline magic command\n",
      "%matplotlib inline\n",
      "# Dependencies and Setup\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy.stats as sts\n",
      "# Import os module to upload csv files via inderect path.\n",
      "import os\n",
      "\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "\n",
      "# Read the City and Ride Data\n",
      "city_data_df = pd.read_csv(city_data_to_load)\n",
      "ride_data_df = pd.read_csv(ride_data_to_load)\n",
      "53/37:\n",
      "# Combine the data into a single dataset\n",
      "pyber_data_df = pd.merge(ride_data_df, city_data_df, how=\"left\", on=[\"city\", \"city\"])\n",
      "\n",
      "# Display the data table for preview\n",
      "pyber_data_df.head()\n",
      "53/38:\n",
      "#  1. Get the total rides for each city type, Series\n",
      "total_ride_by_type = pyber_data_df.groupby([\"type\"]).count()[\"ride_id\"]\n",
      "total_ride_by_type\n",
      "53/39:\n",
      "# 2. Get the total drivers for each city type\n",
      "total_driver_by_type = city_data_df.groupby([\"type\"]).sum()[\"driver_count\"]\n",
      "total_driver_by_type\n",
      "53/40:\n",
      "#  3. Get the total amount of fares for each city type\n",
      "total_fare_by_type = pyber_data_df.groupby([\"type\"]).sum()[\"fare\"]\n",
      "total_fare_by_type\n",
      "53/41:\n",
      "#  4. Get the average fare per ride for each city type. \n",
      "avg_fare_per_ride=total_fare_by_type/total_ride_by_type\n",
      "avg_fare_per_ride\n",
      "53/42:\n",
      "# 5. Get the average fare per driver for each city type. \n",
      "avg_fare_per_driver=total_fare_by_type/total_driver_by_type\n",
      "avg_fare_per_driver\n",
      "53/43:\n",
      "#  6. Create a PyBer summary DataFrame, dictionay.\n",
      "pyber_summary_df=pd.DataFrame({\"Total Rides\": total_ride_by_type,\n",
      "                  \"Total Drivers\": total_driver_by_type,\n",
      "                  \"Total Fares\": total_fare_by_type,\n",
      "                  \"Average Fare per Ride\": avg_fare_per_ride,\n",
      "                  \"Average Fare per Driver\": avg_fare_per_driver})\n",
      "pyber_summary_df\n",
      "53/44:\n",
      "#  7. Cleaning up the DataFrame. Delete the index name\n",
      "pyber_summary_df.index.name = None\n",
      "53/45:\n",
      "#  8. Format the columns.\n",
      "pyber_summary_df[\"Total Rides\"]=pyber_summary_df[\"Total Rides\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Drivers\"]=pyber_summary_df[\"Total Drivers\"].map(\"{:,}\".format)\n",
      "pyber_summary_df[\"Total Fares\"]=pyber_summary_df[\"Total Fares\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Ride\"]=pyber_summary_df[\"Average Fare per Ride\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df[\"Average Fare per Driver\"]=pyber_summary_df[\"Average Fare per Driver\"].map(\"${:,.2f}\".format)\n",
      "pyber_summary_df\n",
      "53/46:\n",
      "# 1. Read the merged DataFrame\n",
      "pyber_data_df\n",
      "53/47:\n",
      "# 2. Using groupby() to create a new DataFrame showing the sum of the fares \n",
      "#  for each date where the indices are the city type and date.\n",
      "total_fare_by_date_df=pyber_data_df.groupby([\"type\",\"date\"]).sum()[[\"fare\"]]\n",
      "total_fare_by_date_df\n",
      "53/48:\n",
      "# 3. Reset the index on the DataFrame you created in #1. This is needed to use the 'pivot()' function.\n",
      "# df = df.reset_index()\n",
      "total_fare_by_date_df= total_fare_by_date_df.reset_index()\n",
      "total_fare_by_date_df\n",
      "53/49:\n",
      "# 4. Create a pivot table with the 'date' as the index, the columns ='type', and values='fare' \n",
      "# to get the total fares for each type of city by the date. \n",
      "total_fare_by_date_pivot=total_fare_by_date_df.pivot(index=\"date\",columns=\"type\",values=\"fare\")\n",
      "total_fare_by_date_pivot.head(10)\n",
      "53/50:\n",
      "# 5. Create a new DataFrame from the pivot table DataFrame using loc on the given dates, '2019-01-01':'2019-04-29'.\n",
      "total_fare_by_date_pivot_df=total_fare_by_date_pivot.loc[\"2019-01-01\":\"2019-04-29\"]\n",
      "total_fare_by_date_pivot_df\n",
      "53/51:\n",
      "# 6. Set the \"date\" index to datetime datatype. This is necessary to use the resample() method in Step 8.\n",
      "# df.index = pd.to_datetime(df.index)\n",
      "total_fare_by_date_pivot_df.index=pd.to_datetime(total_fare_by_date_pivot_df.index)\n",
      "total_fare_by_date_pivot_df\n",
      "53/52:\n",
      "# 7. Check that the datatype for the index is datetime using df.info()\n",
      "total_fare_by_date_pivot_df.info()\n",
      "53/53:\n",
      "# 8. Create a new DataFrame using the \"resample()\" function by week 'W' and get the sum of the fares for each week.\n",
      "total_fare_by_week_df=total_fare_by_date_pivot_df.resample(\"w\").sum()\n",
      "total_fare_by_week_df.head(10)\n",
      "53/54:\n",
      "# 8. Using the object-oriented interface method, plot the resample DataFrame using the df.plot() function. \n",
      "# Import the style from Matplotlib.\n",
      "from matplotlib import style\n",
      "# Use the graph style fivethirtyeight.\n",
      "style.use('fivethirtyeight')\n",
      "# Enlarge chart figure for more spaciousness.\n",
      "ax =total_fare_by_week_df.plot(figsize=(20,5))\n",
      "# Add x-axis label.\n",
      "ax.set_xlabel(\"Month\")\n",
      "# Add y-axis label.\n",
      "ax.set_ylabel(\"Fare($USD)\")\n",
      "# Add legends label.\n",
      "ax.plot()\n",
      "# Set the y-axis limit.\n",
      "ax.set_yticks(np.arange(0, 3000, step=500))\n",
      "# Create a title.\n",
      "ax.set_title(\"Total Fare by City Type\")\n",
      "# Add a grid.\n",
      "ax.grid(True)\n",
      "# Add the legend.\n",
      "lgnd=plt.legend(title=\"Type\", loc=\"best\")\n",
      "plt.savefig(\"analysis/PyBer_fare_summary.png\")\n",
      "plt.show()\n",
      "57/1:\n",
      "# Import the random module.\n",
      "import random\n",
      "randpm._version_\n",
      "57/2:\n",
      "# Import the random module.\n",
      "import random\n",
      "random._version_\n",
      "57/3:\n",
      "# Import the random module.\n",
      "import random\n",
      "57/4: random.randint(-90, 90)\n",
      "57/5:\n",
      "# Generate random latitudes, random.randint(-.., ..)\n",
      "x = 1\n",
      "latitudes = []\n",
      "while x < 11:\n",
      "    random_lat = random.randint(-90, 89) + random.random()\n",
      "    latitudes.append(random_lat)\n",
      "    x += 1\n",
      "57/6:\n",
      "# Generate random longitudes, random.randint(-.., ..)+random.randrange(-.., ..)\n",
      "x = 1\n",
      "latitudes = []\n",
      "while x < 11:\n",
      "    random_lat = random.randint(-90, 89) + random.random()\n",
      "    latitudes.append(random_lat)\n",
      "    x += 1\n",
      "57/7:\n",
      "# Import the random module.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "57/8:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = random.randint(-90, 90) + random.random()\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "%timeit latitudes(1500)\n",
      "57/9:\n",
      "# Import the random module.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "57/10:\n",
      "# Generate random latitudes, random.randint(-.., ..)random.randrange(-.., .., step=..)\n",
      "# Assign the variable x to 1.\n",
      "x = 1\n",
      "# Initialize latitudes empty list.\n",
      "latitudes = []\n",
      "# create a while loop to generate a random latitude.\n",
      "while x < 11:\n",
      "    random_lat = random.randint(-90, 89) + random.random()\n",
      "    # Add random latitude to latitude list.\n",
      "    latitudes.append(random_lat)\n",
      "    # Add 1 to X for each random latitude added to latitude list.\n",
      "    x += 1\n",
      "57/11:\n",
      "# Random options syntax.\n",
      "# random.randint(-.., ..)\n",
      "# random.randrange(-.., .., step=..)\n",
      "# random.random()\n",
      "# random.uniform(-..,..)\n",
      "# np.random.uniform(-10.000, 10.000, size=10)\n",
      "# %timeit tests how long a piece of code or () takes to run.\n",
      "57/12:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = random.randint(-90, 90) + random.random()\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "%timeit latitudes(1500)\n",
      "57/13:\n",
      "# Import the random module.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "57/14:\n",
      "# Generate random latitudes, random.randint(-.., ..)random.randrange(-.., .., step=..)\n",
      "# Assign the variable x to 1.\n",
      "x = 1\n",
      "# Initialize latitudes empty list.\n",
      "latitudes = []\n",
      "# create a while loop to generate a random latitude.\n",
      "while x < 11:\n",
      "    random_lat = random.randint(-90, 89) + random.random()\n",
      "    # Add random latitude to latitude list.\n",
      "    latitudes.append(random_lat)\n",
      "    # Add 1 to X for each random latitude added to latitude list.\n",
      "    x += 1\n",
      "57/15:\n",
      "# Random options syntax.\n",
      "# random.randint(-.., ..)\n",
      "# random.randrange(-.., .., step=..)\n",
      "# random.random()\n",
      "# random.uniform(-..,..)\n",
      "# np.random.uniform(-10.000, 10.000, size=10)\n",
      "# %timeit tests how long a piece of code or () takes to run.\n",
      "57/16:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = random.randint(-90, 90) + random.random()\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "%timeit latitudes(1500)\n",
      "57/17:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = random.randint(-90, 90) + random.random()\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "%timeit latitudes(1500)\n",
      "57/18:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "random_lat\n",
      "57/19:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "%timeit latitudes(1500)\n",
      "58/1:\n",
      "# Import the random module.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "58/2:\n",
      "# Generate random latitudes, random.randint(-.., ..)random.randrange(-.., .., step=..)\n",
      "# Assign the variable x to 1.\n",
      "x = 1\n",
      "# Initialize latitudes empty list.\n",
      "latitudes = []\n",
      "# create a while loop to generate a random latitude.\n",
      "while x < 11:\n",
      "    random_lat = random.randint(-90, 89) + random.random()\n",
      "    # Add random latitude to latitude list.\n",
      "    latitudes.append(random_lat)\n",
      "    # Add 1 to X for each random latitude added to latitude list.\n",
      "    x += 1\n",
      "58/3:\n",
      "# Random options syntax.\n",
      "# random.randint(-.., ..)\n",
      "# random.randrange(-.., .., step=..)\n",
      "# random.random()\n",
      "# random.uniform(-..,..)\n",
      "# np.random.uniform(-10.000, 10.000, size=10)\n",
      "# %timeit tests how long a piece of code or () takes to run.\n",
      "58/4:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = random.randint(-90, 90) + random.random()\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "%timeit latitudes(1500)\n",
      "58/5:\n",
      "\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "# %timeit latitudes(1500)\n",
      "58/6:\n",
      "\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "# %timeit latitudes(1500)\n",
      "random_lat\n",
      "58/7:\n",
      "# Skill Drill\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "58/8:\n",
      "# Skill Drill\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "58/9:\n",
      "# Skill Drill\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "58/10: %timeit (1500)\n",
      "58/11:\n",
      "# Skill Drill\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "%timeit (1500)\n",
      "58/12:\n",
      "# Import the random module.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "58/13:\n",
      "# Generate random latitudes, random.randint(-.., ..)random.randrange(-.., .., step=..)\n",
      "# Assign the variable x to 1.\n",
      "x = 1\n",
      "# Initialize latitudes empty list.\n",
      "latitudes = []\n",
      "# create a while loop to generate a random latitude.\n",
      "while x < 11:\n",
      "    random_lat = random.randint(-90, 89) + random.random()\n",
      "    # Add random latitude to latitude list.\n",
      "    latitudes.append(random_lat)\n",
      "    # Add 1 to X for each random latitude added to latitude list.\n",
      "    x += 1\n",
      "58/14:\n",
      "# Random options syntax.\n",
      "# random.randint(-.., ..)\n",
      "# random.randrange(-.., .., step=..)\n",
      "# random.random()\n",
      "# random.uniform(-..,..)\n",
      "# np.random.uniform(-10.000, 10.000, size=10)\n",
      "# %timeit tests how long a piece of code or () takes to run.\n",
      "58/15:\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = random.randint(-90, 90) + random.random()\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "%timeit latitudes(1500)\n",
      "58/16:\n",
      "# Skill Drill\n",
      "# Generate random longitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = %timeit np.random.uniform(-90.000, 90.000, size=1500)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "%timeit (1500)\n",
      "58/17:\n",
      "# Skill Drill: Refactor the code for the while loop with the %timeit magic command and write a for loop to generate 1,500 latitudes\n",
      "# Generate random longitudes.\n",
      "     latitudes=np.random.uniform(-90, 90, size=1500)\n",
      "# timeit\n",
      "58/18:\n",
      "# Skill Drill: Refactor the code for the while loop with the %timeit magic command and write a for loop to generate 1,500 latitudes\n",
      "# Generate random longitudes.\n",
      "latitudes=np.random.uniform(-90, 90, size=1500)\n",
      "# timeit\n",
      "58/19:\n",
      "# Skill Drill: Refactor the code for the while loop with the %timeit magic command and write a for loop to generate 1,500 latitudes\n",
      "# Generate random longitudes.\n",
      "latitudes=np.random.uniform(-90, 90, size=1500)\n",
      "# timeit \n",
      "%timeit latitudes(1500)\n",
      "58/20:\n",
      "# Skill Drill: Refactor the code for the while loop with the %timeit magic command and write a for loop to generate 1,500 latitudes\n",
      "# Generate random longitudes.\n",
      "# timeit \n",
      "%timeit np.random.uniform(-90, 90, size=1500)\n",
      "58/21:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "59/1:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "60/1:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "60/2:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "59/2:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "59/3:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "60/3:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "60/4:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "61/1:\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/2:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "61/3:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "61/4:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "61/5:\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/6:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "62/1:\n",
      "import csv\n",
      "import kdtree\n",
      "import os\n",
      "\n",
      "\n",
      "class City:\n",
      "    '''\n",
      "    City wraps up the info about a city, including its name, coordinates,\n",
      "    and belonging country.\n",
      "    '''\n",
      "    def __init__(self, city_name, country_code):\n",
      "        self.city_name = city_name\n",
      "        self.country_code = country_code\n",
      "\n",
      "\n",
      "# load the city data up\n",
      "_current_dir, _current_filename = os.path.split(__file__)\n",
      "_world_cities_csv_path = os.path.join(_current_dir, 'worldcities.csv')\n",
      "_world_cities_kdtree = kdtree.create(dimensions=2)\n",
      "WORLD_CITIES_DICT = {}\n",
      "\n",
      "with open(_world_cities_csv_path, 'r') as csv_file:\n",
      "    cities = csv.reader(csv_file)\n",
      "\n",
      "    # discard the headers\n",
      "    cities.__next__()\n",
      "\n",
      "    # populate geo points into kdtree\n",
      "    for city in cities:\n",
      "        city_coordinate_key = (float(city[2]), float(city[3]))\n",
      "        _world_cities_kdtree.add(city_coordinate_key)\n",
      "        c = City(city[1], city[0])\n",
      "        WORLD_CITIES_DICT[city_coordinate_key] = c\n",
      "\n",
      "\n",
      "def nearest_city(latitude, longitude):\n",
      "    nearest_city_coordinate = _world_cities_kdtree.search_nn((latitude, longitude, ))\n",
      "    return WORLD_CITIES_DICT[nearest_city_coordinate[0].data]\n",
      "61/7:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "61/8:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "61/9:\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/10:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "63/1:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "63/2:\n",
      "# Create a list for holding the cities.\n",
      "cities = []\n",
      "# Identify the nearest city for each latitude and longitude combination.\n",
      "for coordinate in coordinates:\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is unique, then we will add it to the cities list.\n",
      "    if city not in cities:\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "64/1:\n",
      "# Generate random latitudes.\n",
      "def latitudes(size):\n",
      "    latitudes = []\n",
      "    x = 0\n",
      "    while x < (size):\n",
      "        random_lat = random.randint(-90, 90) + random.random()\n",
      "        latitudes.append(random_lat)\n",
      "        x += 1\n",
      "    return latitudes\n",
      "# Call the function with 1500.\n",
      "#%timeit latitudes(1500)\n",
      "63/3:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "63/4:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "63/5:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "63/6:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "63/7:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "63/8:\n",
      "# Create a list for holding the cities.\n",
      "cities = []\n",
      "# Identify the nearest city for each latitude and longitude combination.\n",
      "for coordinate in coordinates:\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is unique, then we will add it to the cities list.\n",
      "    if city not in cities:\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "63/9:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "63/10:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "63/11:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "63/12:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "63/13:\n",
      "# Create a list for holding the cities.\n",
      "cities = []\n",
      "# Identify the nearest city for each latitude and longitude combination.\n",
      "for coordinate in coordinates:\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is unique, then we will add it to the cities list.\n",
      "    if city not in cities:\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "61/11:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/12:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "61/13:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/14:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "61/15:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "61/16:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "63/14:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "63/15:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "63/16:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "63/17:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "63/18:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "63/19:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "63/20:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "63/21:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "63/22:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "61/17:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/18:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "61/19:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "61/20:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "#for coordinate in coordinates:\n",
      "    #print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          #citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "63/23:\n",
      "# Import dependencies.\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "63/24:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "61/21:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/22:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "63/25:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "63/26:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "63/27:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "63/28:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "63/29:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "63/30:\n",
      "# Import dependencies.\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "63/31:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "65/1:\n",
      "# Import dependencies.\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "65/2:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "65/3:\n",
      "# Import dependencies.\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "65/4:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "66/1:\n",
      "# Import dependencies.\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "66/2:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "66/3:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "66/4:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "66/5:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "66/6:\n",
      "# Import citipy\n",
      "#from citipy import citipy\n",
      "66/7:\n",
      "# Create a list for holding the cities.\n",
      "cities = []\n",
      "# Identify the nearest city for each latitude and longitude combination.\n",
      "for coordinate in coordinates:\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is unique, then we will add it to the cities list.\n",
      "    if city not in cities:\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "66/8:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "66/9:\n",
      "# Create a list for holding the cities.\n",
      "cities = []\n",
      "# Identify the nearest city for each latitude and longitude combination.\n",
      "for coordinate in coordinates:\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is unique, then we will add it to the cities list.\n",
      "    if city not in cities:\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "61/23:\n",
      "# Import dependencies.\n",
      "import random\n",
      "import numpy as np\n",
      "import timeit\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/24:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "61/25:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "66/10:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "66/11:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "66/12:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "66/13:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "66/14:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "61/26:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "61/27:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "66/15:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "61/28:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "61/29:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "#coordinates = list(lat_lngs)\n",
      "61/30:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "#for coordinate in coordinates:\n",
      "    #print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          #citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "61/31:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          #citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "61/32:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "66/16:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "66/17:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "66/18:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "66/19:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "#lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "#lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "#lat_lngs = zip(lats, lngs)\n",
      "66/20:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "66/21:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "66/22:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "66/23:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "66/24:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "66/25:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "66/26:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "66/27:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "66/28:\n",
      "# Create a list for holding the cities.\n",
      "cities = []\n",
      "# Identify the nearest city for each latitude and longitude combination.\n",
      "for coordinate in coordinates:\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is unique, then we will add it to the cities list.\n",
      "    if city not in cities:\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "66/29:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "66/30:\n",
      "import requests\n",
      "requests._version_\n",
      "67/1:\n",
      "import requests\n",
      "requests._version_\n",
      "68/1:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/2:\n",
      "# Starting URL for Weather Map API Call.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/3:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/4:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/5:\n",
      "# Starting URL for Weather Map API Call.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/6:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/7:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/8:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/9:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/10:\n",
      "# Starting URL for Weather Map API Call.\n",
      "https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "#print(url)\n",
      "68/11:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/12:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/13:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "68/14:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/15:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/16:\n",
      "# Starting URL for Weather Map API Call.\n",
      "https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "#print(url)\n",
      "68/17:\n",
      "# Starting URL for Weather Map API Call.\n",
      "https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat=44.34&lon=10.99&appid={API key}\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "#print(url)\n",
      "68/18:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/19:\n",
      "# Starting URL for Weather Map API Call.\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "https://api.openweathermap.org/data/2.5/weather?lat=44.34&lon=10.99&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "#print(url)\n",
      "68/20:\n",
      "# Starting URL for Weather Map API Call.\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "https://api.openweathermap.org/data/2.5/weather?lat=44.34&lon=10.99&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/21:\n",
      "# Starting URL for Weather Map API Call.\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat=44.34&lon=10.99&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "api.openweathermap.org/data/2.5/weather?q=city&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/22:\n",
      "# Starting URL for Weather Map API Call.\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat=44.34&lon=10.99&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "http://api.openweathermap.org/data/2.5/weather?q=city&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "#print(url)\n",
      "68/23: http://api.openweathermap.org/geo/1.0/direct?q=London&limit=5&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "68/24:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/25:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/26:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "68/27:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/28:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/29:\n",
      "# Starting URL for Weather Map API Call.\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat=44.34&lon=10.99&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "#http://api.openweathermap.org/data/2.5/weather?q=city&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "#print(url)\n",
      "68/30: http://api.openweathermap.org/geo/1.0/direct?q=London&limit=5&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "68/31: https://api.openweathermap.org/geo/1.0/direct?q=London&limit=5&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "68/32: https://api.openweathermap.org/geo/1.0/direct?q=London&limit=5&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "68/33: api.openweathermap.org/geo/1.0/direct?q=London&limit=5&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "68/34: api.openweathermap.org/data/2.5/weather?q=gat&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "68/35: api.openweathermap.org/data/2.5/weather?q=london&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "68/36: https://api.openweathermap.org/data/2.5/weather?q=london&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "68/37:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/38:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/39:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "68/40:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/41:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/42:\n",
      "# Starting URL for Weather Map API Call.\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat={lats}&lon={lngs}&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#https://api.openweathermap.org/data/2.5/weather?lat=44.34&lon=10.99&appid={5b839d0b57ecfbc7d49ff71f15b5bc3a}\n",
      "#http://api.openweathermap.org/data/2.5/weather?q=city&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "#url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "#print(url)\n",
      "68/43: https://api.openweathermap.org/data/2.5/weather?q=london&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\n",
      "68/44:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/45: https://api.openweathermap.org/data/2.5/weather?q=london&appid=weather_api_key\n",
      "68/46: https://api.openweathermap.org/data/2.5/weather?q=london&appid={weather_api_key}\n",
      "68/47: http://api.openweathermap.org/data/2.5/weather?q=london&appid={weather_api_key}\n",
      "68/48: http://api.openweathermap.org/data/2.5/weather?q=london&appid=weather_api_key\n",
      "68/49:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/50: url=\"https://api.openweathermap.org/data/2.5/weather?q=london&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\"\n",
      "68/51:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/52:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/53:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "68/54:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/55:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/56: url=\"https://api.openweathermap.org/data/2.5/weather?q=london&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\"\n",
      "68/57:\n",
      "# Starting URL for Weather Map API Call.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/58:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/59:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/60:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/61:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "68/62:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/63:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/64: url=\"https://api.openweathermap.org/data/2.5/weather?q=london&appid=5b839d0b57ecfbc7d49ff71f15b5bc3a\"\n",
      "68/65:\n",
      "# Starting URL for Weather Map API Call.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/66:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/67: query_url=url+\"appid=\"+api_key+\"&=\"+city\n",
      "68/68:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/69:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/70:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "68/71:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/72:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/73: #url=\"https://api.openweathermap.org/data/2.5/weather?q=london&appid=\"\n",
      "68/74:\n",
      "# Starting URL for Weather Map API Call.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/75:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/76: query_url=url+\"appid=\"+api_key+\"&=\"+city\n",
      "68/77: query_url=url+\"appid=\"+weather_api_key+\"&=\"+city\n",
      "68/78: query_url=url+\"appid=\"+weather_api_key+\"&=\"+city_url\n",
      "68/79:\n",
      "weather_response=requests.get(query_url)\n",
      "weather_json=weather_response.json()\n",
      "68/80: weather_json.keys()\n",
      "68/81:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/82:\n",
      "# Make a 'Get' request for the city weather.\n",
      "city_weather = requests.get(city_url)\n",
      "city_weather\n",
      "68/83: city_weather.status_code\n",
      "68/84:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "city_weather\n",
      "68/85:\n",
      "# Get the text of the 'Get' request.\n",
      "city_weather.text\n",
      "68/86:\n",
      "# Get the JSON text of the 'Get' request.\n",
      "city_weather.json()\n",
      "68/87:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "if city_weather.status_code == 200:\n",
      "    print(f\"City Weather found.\")\n",
      "else:\n",
      "    print(f\"City weather not found.\")\n",
      "68/88:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Bston\"\n",
      "city_weather = requests.get(city_url)\n",
      "if city_weather.status_code == 200:\n",
      "    print(f\"City Weather found.\")\n",
      "else:\n",
      "    print(f\"City weather not found.\")\n",
      "68/89:\n",
      "# Check if response is valid.\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "if city_weather.status_code == 200:\n",
      "    print(f\"City Weather found.\")\n",
      "else:\n",
      "    print(f\"City weather not found.\")\n",
      "68/90:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "city_weather.json()\n",
      "68/91:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "city_weather.json()\n",
      "68/92:\n",
      "# Get the JSON data.\n",
      "boston_data = city_weather.json()\n",
      "68/93: boston_data['sys']\n",
      "68/94: boston_data['sys'][\"country\"]\n",
      "68/95: boston_data['dt']\n",
      "68/96:\n",
      "lat = boston_data[\"coord\"][\"lat\"]\n",
      "lng = boston_data[\"coord\"][\"lon\"]\n",
      "max_temp = boston_data[\"main\"][\"temp_max\"]\n",
      "humidity = boston_data[\"main\"][\"humidity\"]\n",
      "clouds = boston_data[\"clouds\"][\"all\"]\n",
      "wind = boston_data[\"wind\"][\"speed\"]\n",
      "print(lat, lng, max_temp, humidity, clouds, wind)\n",
      "68/97:\n",
      "# Import the datetime module from the datetime library.\n",
      "from datetime import datetime\n",
      "# Get the date from the JSON file.\n",
      "date = boston_data[\"dt\"]\n",
      "# Convert the UTC date to a date format with year, month, day, hours, minutes, and seconds.\n",
      "datetime.utcfromtimestamp(date)\n",
      "68/98:\n",
      "# Import dependencies.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "# Use the citipy module to determine city based on latitude and longitude.\n",
      "from citipy import citipy\n",
      "68/99:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "68/100:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "68/101:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "# Iterate through the coordinates' unzipped tuple.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "68/102:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "68/103: #url=\"https://api.openweathermap.org/data/2.5/weather?q=london&appid=\"\n",
      "68/104:\n",
      "# Starting URL for Weather Map API Call.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "print(url)\n",
      "68/105:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "print(city_url)\n",
      "68/106:\n",
      "# Make a city weather 'Get' request.\n",
      "city_weather = requests.get(city_url)\n",
      "city_weather\n",
      "68/107:\n",
      "# Use 'status_code' to get a direct call response for city weather.\n",
      "city_weather.status_code\n",
      "68/108:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "city_weather\n",
      "68/109:\n",
      "# Get the text output of the 'Get' request.\n",
      "city_weather.text\n",
      "68/110:\n",
      "# Get the JSON text of the 'Get' request.\n",
      "city_weather.json()\n",
      "68/111:\n",
      "# Check if response is valid.\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "if city_weather.status_code == 200:\n",
      "    print(f\"City Weather found.\")\n",
      "else:\n",
      "    print(f\"City weather not found.\")\n",
      "68/112:\n",
      "# Create an endpoint URL for a city.\n",
      "city_url = url + \"&q=\" + \"Boston\"\n",
      "city_weather = requests.get(city_url)\n",
      "city_weather.json()\n",
      "68/113:\n",
      "# Get the JSON data.\n",
      "boston_data = city_weather.json()\n",
      "68/114: boston_data['sys']\n",
      "68/115: boston_data['sys']['country']\n",
      "68/116: boston_data['dt']\n",
      "68/117:\n",
      "lat = boston_data[\"coord\"][\"lat\"]\n",
      "lng = boston_data[\"coord\"][\"lon\"]\n",
      "max_temp = boston_data[\"main\"][\"temp_max\"]\n",
      "humidity = boston_data[\"main\"][\"humidity\"]\n",
      "clouds = boston_data[\"clouds\"][\"all\"]\n",
      "wind = boston_data[\"wind\"][\"speed\"]\n",
      "print(lat, lng, max_temp, humidity, clouds, wind)\n",
      "68/118:\n",
      "# Import the datetime module from the datetime library.\n",
      "from datetime import datetime\n",
      "# Get the date from the JSON file.\n",
      "date = boston_data[\"dt\"]\n",
      "# Convert the UTC date to a date format with year, month, day, hours, minutes, and seconds.\n",
      "datetime.utcfromtimestamp(date)\n",
      "68/119:\n",
      "# Convert this datetime format to 2019-10-21 17:24:35.\n",
      "datetime.utcfromtimestamp(date).strftime('%Y-%m-%d %H:%M:%S')\n",
      "69/1:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "69/2:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        set_count += 1\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "    # Loop through all the cities in the list.\n",
      "    for i, city in enumerate(cities):\n",
      "\n",
      "        # Group cities in sets of 50 for logging purposes.\n",
      "        # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "        if (i % 50 == 0 and i >= 50):\n",
      "            # Increment set_count by 1.\n",
      "            set_count += 1\n",
      "            # Increment record_count by 1.\n",
      "            record_count = 1\n",
      "            # 60 second pause to prevent time-out errors.\n",
      "            time.sleep(60)\n",
      "\n",
      "        # Create endpoint URL with each city.\n",
      "        # Remove the blank spaces in the city name and concatenate the city name.\n",
      "        city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "        # Log the URL, record, and set numbers and the city.\n",
      "        print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "        # Add 1 to the record count.\n",
      "        record_count += 1 \n",
      "        \n",
      " # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "69/3:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "69/4:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "69/5:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "69/6:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "69/7:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "69/8:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "69/9:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "69/10:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "69/11:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        set_count += 1\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "    # Loop through all the cities in the list.\n",
      "    for i, city in enumerate(cities):\n",
      "\n",
      "        # Group cities in sets of 50 for logging purposes.\n",
      "        # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "        if (i % 50 == 0 and i >= 50):\n",
      "            # Increment set_count by 1.\n",
      "            set_count += 1\n",
      "            # Increment record_count by 1.\n",
      "            record_count = 1\n",
      "            # 60 second pause to prevent time-out errors.\n",
      "            time.sleep(60)\n",
      "\n",
      "        # Create endpoint URL with each city.\n",
      "        # Remove the blank spaces in the city name and concatenate the city name.\n",
      "        city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "        # Log the URL, record, and set numbers and the city.\n",
      "        print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "        # Add 1 to the record count.\n",
      "        record_count += 1 \n",
      "        \n",
      " # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "69/12:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "69/13:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "69/14:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "69/15:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "69/16:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "69/17:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "69/18:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "69/19:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "69/20:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "69/21:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "69/22:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        set_count += 1\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "    # Loop through all the cities in the list.\n",
      "    for i, city in enumerate(cities):\n",
      "\n",
      "        # Group cities in sets of 50 for logging purposes.\n",
      "        # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "        if (i % 50 == 0 and i >= 50):\n",
      "            # Increment set_count by 1.\n",
      "            set_count += 1\n",
      "            # Increment record_count by 1.\n",
      "            record_count = 1\n",
      "            # 60 second pause to prevent time-out errors.\n",
      "            time.sleep(60)\n",
      "\n",
      "        # Create endpoint URL with each city.\n",
      "        # Remove the blank spaces in the city name and concatenate the city name.\n",
      "        city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "        # Log the URL, record, and set numbers and the city.\n",
      "        print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "        # Add 1 to the record count.\n",
      "        record_count += 1 \n",
      "        \n",
      " # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "69/23:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "69/24:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "69/25:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "69/26:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "lat_lngs = zip(lats, lngs)\n",
      "69/27:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "69/28:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(coordinate[0], coordinate[1])\n",
      "69/29:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "for coordinate in coordinates:\n",
      "    print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "69/30:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "69/31:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "69/32:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "69/33:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "69/34:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "69/35:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        set_count += 1\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "    # Loop through all the cities in the list.\n",
      "    for i, city in enumerate(cities):\n",
      "\n",
      "        # Group cities in sets of 50 for logging purposes.\n",
      "        # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "        if (i % 50 == 0 and i >= 50):\n",
      "            # Increment set_count by 1.\n",
      "            set_count += 1\n",
      "            # Increment record_count by 1.\n",
      "            record_count = 1\n",
      "            # 60 second pause to prevent time-out errors.\n",
      "            time.sleep(60)\n",
      "\n",
      "        # Create endpoint URL with each city.\n",
      "        # Remove the blank spaces in the city name and concatenate the city name.\n",
      "        city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "        # Log the URL, record, and set numbers and the city.\n",
      "        print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "        # Add 1 to the record count.\n",
      "        record_count += 1 \n",
      "        \n",
      " # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "69/36:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "69/37:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "69/38:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "#lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "#lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "#lat_lngs = zip(lats, lngs)\n",
      "69/39:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "69/40:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(coordinate[0], coordinate[1])\n",
      "69/41:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          #citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "69/42:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "69/43:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "69/44:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "69/45:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "69/46:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "69/47:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        set_count += 1\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "    # Loop through all the cities in the list.\n",
      "    for i, city in enumerate(cities):\n",
      "\n",
      "        # Group cities in sets of 50 for logging purposes.\n",
      "        # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "        if (i % 50 == 0 and i >= 50):\n",
      "            # Increment set_count by 1.\n",
      "            set_count += 1\n",
      "            # Increment record_count by 1.\n",
      "            record_count = 1\n",
      "            # 60 second pause to prevent time-out errors.\n",
      "            time.sleep(60)\n",
      "\n",
      "        # Create endpoint URL with each city.\n",
      "        # Remove the blank spaces in the city name and concatenate the city name.\n",
      "        city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "        # Log the URL, record, and set numbers and the city.\n",
      "        print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "        # Add 1 to the record count.\n",
      "        record_count += 1 \n",
      "        \n",
      " # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "70/1:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "70/2:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "70/3:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "#lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "#lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "#lat_lngs = zip(lats, lngs)\n",
      "70/4:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "70/5:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(coordinate[0], coordinate[1])\n",
      "70/6:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          #citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "70/7:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "70/8:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "70/9:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "70/10:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "70/11:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "70/12:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        set_count += 1\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "    # Loop through all the cities in the list.\n",
      "    for i, city in enumerate(cities):\n",
      "\n",
      "        # Group cities in sets of 50 for logging purposes.\n",
      "        # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "        if (i % 50 == 0 and i >= 50):\n",
      "            # Increment set_count by 1.\n",
      "            set_count += 1\n",
      "            # Increment record_count by 1.\n",
      "            record_count = 1\n",
      "            # 60 second pause to prevent time-out errors.\n",
      "            time.sleep(60)\n",
      "\n",
      "        # Create endpoint URL with each city.\n",
      "        # Remove the blank spaces in the city name and concatenate the city name.\n",
      "        city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "        # Log the URL, record, and set numbers and the city.\n",
      "        print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "        # Add 1 to the record count.\n",
      "        record_count += 1 \n",
      "        \n",
      " # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "70/13:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "70/14:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "70/15:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "#lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "#lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "#lat_lngs = zip(lats, lngs)\n",
      "70/16:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "70/17:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(coordinate[0], coordinate[1])\n",
      "70/18:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          #citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "70/19:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "70/20:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "70/21:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "70/22:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "70/23:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "70/24:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        set_count += 1\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "    # Loop through all the cities in the list.\n",
      "    for i, city in enumerate(cities):\n",
      "\n",
      "        # Group cities in sets of 50 for logging purposes.\n",
      "        # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "        if (i % 50 == 0 and i >= 50):\n",
      "            # Increment set_count by 1.\n",
      "            set_count += 1\n",
      "            # Increment record_count by 1.\n",
      "            record_count = 1\n",
      "            # 60 second pause to prevent time-out errors.\n",
      "            time.sleep(60)\n",
      "\n",
      "        # Create endpoint URL with each city.\n",
      "        # Remove the blank spaces in the city name and concatenate the city name.\n",
      "        city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "        # Log the URL, record, and set numbers and the city.\n",
      "        print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "        # Add 1 to the record count.\n",
      "        record_count += 1 \n",
      "        \n",
      " # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "70/25:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "70/26:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "70/27:\n",
      "# Create a practice set of random latitude and longitude combinations.\n",
      "#lats = [25.12903645, 25.92017388, 26.62509167, -59.98969384, 37.30571269]\n",
      "#lngs = [-67.59741259, 11.09532135, 74.84233102, -76.89176677, -61.13376282]\n",
      "#lat_lngs = zip(lats, lngs)\n",
      "70/28:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "70/29:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(coordinate[0], coordinate[1])\n",
      "70/30:\n",
      "# Use the print() function to display the latitude and longitude combinations.\n",
      "#for coordinate in coordinates:\n",
      "    #print(citipy.nearest_city(coordinate[0], coordinate[1]).city_name,\n",
      "          #citipy.nearest_city(coordinate[0], coordinate[1]).country_code)\n",
      "70/31:\n",
      "# Import citipy\n",
      "from citipy import citipy\n",
      "70/32:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "70/33:\n",
      "# Import the requests library.\n",
      "import requests\n",
      "\n",
      "# Import the API key.\n",
      "from config import weather_api_key\n",
      "70/34:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "70/35:\n",
      "# Import the time library and the datetime module from the datetime library \n",
      "import time\n",
      "from datetime import datetime\n",
      "70/36:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "# Loop through all the cities in our list.\n",
      "#for i in range(len(cities)):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    #if (i % 50 == 0 and i >= 50):\n",
      "        #set_count += 1\n",
      "        #record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        #time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    #city_url = url + \"&q=\" + cities[i]\n",
      "    # Iterate through the list of cities and retrieve both the index, and the city from the list.    \n",
      "# Loop through all the cities in the list.\n",
      "for i, city in enumerate(cities):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        # Increment set_count by 1.\n",
      "        set_count += 1\n",
      "        # Increment record_count by 1.\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    # Remove the blank spaces in the city name and concatenate the city name.\n",
      "    city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "    # Log the URL, record, and set numbers and the city.\n",
      "    print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "    # Add 1 to the record count.\n",
      "    record_count += 1 \n",
      "        \n",
      "    # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Country\": city_country,\n",
      "                          \"Date\": city_date})\n",
      "\n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "70/37:\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "70/38:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "70/39:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/40:\n",
      "# Reorder the Columns of the DataFrame\n",
      "new_column_order = [\"City\", \"Country\", \"Date\", \"Lat\", \"Lng\", \"Max Temp\", \"Humidity\", \"Cloudiness\", \"Wind Speed\"]\n",
      "\n",
      "city_data_df = city_data_df[new_column_order]\n",
      "city_data_df.head(10)\n",
      "70/41:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/42:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import requests\n",
      "from config import weather_api_key\n",
      "from datetime import datetime\n",
      "70/43:\n",
      "# Import dependencies.\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import requests\n",
      "from config import weather_api_key\n",
      "from datetime import datetime\n",
      "70/44:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "71/1:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/45:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/46:\n",
      "# Reorder the Columns of the DataFrame\n",
      "new_column_order = [\"City\", \"Country\", \"Date\", \"Lat\", \"Lng\", \"Max Temp\", \"Humidity\", \"Cloudiness\", \"Wind Speed\"]\n",
      "\n",
      "city_data_df = city_data_df[new_column_order]\n",
      "city_data_df.head(10)\n",
      "70/47:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "71/2:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/48:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "#city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/49:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "#city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/50:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/51:\n",
      "# Create the output file (CSV).\n",
      "#output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/52:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/WeatherPy_Database.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/53:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_database/WeatherPy_Database.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/54:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/55:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(r'output_data_file', index_label=\"City_ID\")\n",
      "70/56:\n",
      "# Extract relevant fields from the DataFrame for plotting.\n",
      "lats = city_data_df[\"Lat\"]\n",
      "max_temps = city_data_df[\"Max Temp\"]\n",
      "humidity = city_data_df[\"Humidity\"]\n",
      "cloudiness = city_data_df[\"Cloudiness\"]\n",
      "wind_speed = city_data_df[\"Wind Speed\"]\n",
      "68/120:\n",
      "# Import the time module.\n",
      "import time\n",
      "# Get today's date in seconds.\n",
      "today = time.time()\n",
      "today\n",
      "68/121:\n",
      "# Format today's date in seconds.\n",
      "# Syntax string format: strftime(), format for today: \"%x\"\n",
      "today = time.strftime(\"%x\")\n",
      "today\n",
      "70/57:\n",
      "# Import time module\n",
      "import time\n",
      "\n",
      "# Build the scatter plot for latitude vs. max temperature.\n",
      "plt.scatter(lats,\n",
      "            max_temps,\n",
      "            edgecolor=\"black\", linewidths=1, marker=\"o\",\n",
      "            alpha=0.8, label=\"Cities\")\n",
      "\n",
      "# Incorporate the other graph properties.\n",
      "plt.title(f\"City Latitude vs. Max Temperature \"+ time.strftime(\"%x\"))\n",
      "plt.ylabel(\"Max Temperature (F)\")\n",
      "plt.xlabel(\"Latitude\")\n",
      "plt.grid(True)\n",
      "\n",
      "# Save the figure.\n",
      "plt.savefig(\"weather_data/Fig1.png\")\n",
      "\n",
      "# Show plot.\n",
      "plt.show()\n",
      "70/58:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(r'output_data_file', index_label=\"City_ID\")\n",
      "70/59:\n",
      "# Create the output file (CSV).\n",
      "output_data_file = \"weather_data/cities.csv\"\n",
      "# Export the City_Data into a CSV.\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "70/60:\n",
      "# Extract relevant fields from the DataFrame for plotting.\n",
      "lats = city_data_df[\"Lat\"]\n",
      "max_temps = city_data_df[\"Max Temp\"]\n",
      "humidity = city_data_df[\"Humidity\"]\n",
      "cloudiness = city_data_df[\"Cloudiness\"]\n",
      "wind_speed = city_data_df[\"Wind Speed\"]\n",
      "70/61:\n",
      "# Import time module\n",
      "import time\n",
      "\n",
      "# Build the scatter plot for latitude vs. max temperature.\n",
      "plt.scatter(lats,\n",
      "            max_temps,\n",
      "            edgecolor=\"black\", linewidths=1, marker=\"o\",\n",
      "            alpha=0.8, label=\"Cities\")\n",
      "\n",
      "# Incorporate the other graph properties.\n",
      "plt.title(f\"City Latitude vs. Max Temperature \"+ time.strftime(\"%x\"))\n",
      "plt.ylabel(\"Max Temperature (F)\")\n",
      "plt.xlabel(\"Latitude\")\n",
      "plt.grid(True)\n",
      "\n",
      "# Save the figure.\n",
      "plt.savefig(\"weather_data/Fig1.png\")\n",
      "\n",
      "# Show plot.\n",
      "plt.show()\n",
      "70/62:\n",
      "#latitude vs. humidity.\n",
      "plt.scatter(lats,\n",
      "            humidity,\n",
      "            edgecolor=\"black\", linewidths=1, marker=\"o\",\n",
      "            alpha=0.8, label=\"Cities\")\n",
      "\n",
      "# Incorporate the other graph properties.\n",
      "plt.title(f\"City Latitude vs. Humidity \"+ time.strftime(\"%x\"))\n",
      "plt.ylabel(\"Humidity (%)\")\n",
      "plt.xlabel(\"Latitude\")\n",
      "plt.grid(True)\n",
      "# Save the figure.\n",
      "plt.savefig(\"weather_data/Fig2.png\")\n",
      "# Show plot.\n",
      "plt.show()\n",
      "70/63:\n",
      "# Latitude vs. Cloudiness\n",
      "# Build the scatter plots for latitude vs. cloudiness.\n",
      "plt.scatter(lats,\n",
      "            cloudiness,\n",
      "            edgecolor=\"black\", linewidths=1, marker=\"o\",\n",
      "            alpha=0.8, label=\"Cities\")\n",
      "\n",
      "# Incorporate the other graph properties.\n",
      "plt.title(f\"City Latitude vs. Cloudiness (%) \"+ time.strftime(\"%x\"))\n",
      "plt.ylabel(\"Cloudiness (%)\")\n",
      "plt.xlabel(\"Latitude\")\n",
      "plt.grid(True)\n",
      "# Save the figure.\n",
      "plt.savefig(\"weather_data/Fig3.png\")\n",
      "# Show plot.\n",
      "plt.show()\n",
      "70/64:\n",
      "# latitude vs. wind speed.\n",
      "plt.scatter(lats,\n",
      "            wind_speed,\n",
      "            edgecolor=\"black\", linewidths=1, marker=\"o\",\n",
      "            alpha=0.8, label=\"Cities\")\n",
      "\n",
      "# Incorporate the other graph properties.\n",
      "plt.title(f\"City Latitude vs. Wind Speed \"+ time.strftime(\"%x\"))\n",
      "plt.ylabel(\"Wind Speed (mph)\")\n",
      "plt.xlabel(\"Latitude\")\n",
      "plt.grid(True)\n",
      "# Save the figure.\n",
      "plt.savefig(\"weather_data/Fig4.png\")\n",
      "# Show plot.\n",
      "plt.show()\n",
      "73/1:\n",
      "# Import linear regression from the SciPy stats module.\n",
      "from scipy.stats import linregress\n",
      "73/2:\n",
      "# Create an equal number of latitudes and temperatures.\n",
      "lats = [42.5, 43.9, 8.1, 36.8, 79.9, 69.1, 25.7, 15.3, 12.7, 64.5]\n",
      "temps = [80.5, 75.3, 90.9, 90.0, 40.4, 62.3, 85.4, 79.6, 72.5, 72.0]\n",
      "73/3:\n",
      "# Perform linear regression.\n",
      "(slope, intercept, r_value, p_value, std_err) = linregress(lats, temps)\n",
      "# Get the equation of the line.\n",
      "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
      "print(line_eq)\n",
      "print(f\"The p-value is: {p_value:.3f}\")\n",
      "73/4:\n",
      "# Calculate the regression line \"y values\" from the slope and intercept.\n",
      "regress_values = [(lat * slope + intercept) for lat in lats]\n",
      "73/5:\n",
      "# Import Matplotlib.\n",
      "import matplotlib.pyplot as plt\n",
      "# Create a scatter plot of the x and y values.\n",
      "plt.scatter(lats,temps)\n",
      "# Plot the regression line with the x-values and the y coordinates based on the intercept and slope.\n",
      "plt.plot(lats,regress_values,\"r\")\n",
      "# Annotate the text for the line equation and add its coordinates.\n",
      "plt.annotate(line_eq, (10,40), fontsize=15, color=\"red\")\n",
      "plt.xlabel('Latitude')\n",
      "plt.ylabel('Temp')\n",
      "plt.show()\n",
      "70/65:\n",
      "# latitude vs. maximum temperature\n",
      "# Import time module\n",
      "import time\n",
      "\n",
      "# Build the scatter plot for latitude vs. max temperature.\n",
      "plt.scatter(lats,\n",
      "            max_temps,\n",
      "            edgecolor=\"black\", linewidths=1, marker=\"o\",\n",
      "            alpha=0.8, label=\"Cities\")\n",
      "\n",
      "# Incorporate the other graph properties.\n",
      "plt.title(f\"City Latitude vs. Max Temperature \"+ time.strftime(\"%x\"))\n",
      "plt.ylabel(\"Max Temperature (F)\")\n",
      "plt.xlabel(\"Latitude\")\n",
      "plt.grid()\n",
      "\n",
      "# Save the figure.\n",
      "plt.savefig(\"weather_data/Fig1.png\")\n",
      "\n",
      "# Show plot.\n",
      "plt.show()\n",
      "70/66:\n",
      "# latitude vs. maximum temperature\n",
      "# Import time module\n",
      "import time\n",
      "\n",
      "# Build the scatter plot for latitude vs. max temperature.\n",
      "plt.scatter(lats,\n",
      "            max_temps,\n",
      "            edgecolor=\"black\", linewidths=1, marker=\"o\",\n",
      "            alpha=0.8, label=\"Cities\")\n",
      "\n",
      "# Incorporate the other graph properties.\n",
      "plt.title(f\"City Latitude vs. Max Temperature \"+ time.strftime(\"%x\"))\n",
      "plt.ylabel(\"Max Temperature (F)\")\n",
      "plt.xlabel(\"Latitude\")\n",
      "plt.grid(True)\n",
      "\n",
      "# Save the figure.\n",
      "plt.savefig(\"weather_data/Fig1.png\")\n",
      "\n",
      "# Show plot.\n",
      "plt.show()\n",
      "70/67:\n",
      "# Import linregress\n",
      "from scipy.stats import linregress\n",
      "\n",
      "# Create a function to create perform linear regression on the weather data\n",
      "# and plot a regression line and the equation with the data.\n",
      "def plot_linear_regression(x_values, y_values, title, y_label, text_coordinates):\n",
      "\n",
      "    # Run regression on hemisphere weather data.\n",
      "    (slope, intercept, r_value, p_value, std_err) = linregress(x_values, y_values)\n",
      "\n",
      "    # Calculate the regression line \"y values\" from the slope and intercept.\n",
      "    regress_values = x_values * slope + intercept\n",
      "    # Get the equation of the line.\n",
      "    line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
      "    # Create a scatter plot and plot the regression line.\n",
      "    plt.scatter(x_values,y_values)\n",
      "    plt.plot(x_values,regress_values,\"r\")\n",
      "    # Annotate the text for the line equation.\n",
      "    plt.annotate(line_eq, text_coordinates, fontsize=15, color=\"red\")\n",
      "    plt.title(title)\n",
      "    plt.xlabel('Latitude')\n",
      "    plt.ylabel(y_label)\n",
      "    plt.show()\n",
      "70/68:\n",
      "# Import linregress\n",
      "from scipy.stats import linregress\n",
      "\n",
      "# Extract relevant fields from the DataFrame for plotting.\n",
      "lats = city_data_df[\"Lat\"]\n",
      "max_temps = city_data_df[\"Max Temp\"]\n",
      "humidity = city_data_df[\"Humidity\"]\n",
      "cloudiness = city_data_df[\"Cloudiness\"]\n",
      "wind_speed = city_data_df[\"Wind Speed\"]\n",
      "\n",
      "# Create a function to create perform linear regression on the weather data\n",
      "# and plot a regression line and the equation with the data.\n",
      "def plot_linear_regression(x_values, y_values, title, y_label, text_coordinates):\n",
      "\n",
      "    # Run regression on hemisphere weather data.\n",
      "    (slope, intercept, r_value, p_value, std_err) = linregress(x_values, y_values)\n",
      "\n",
      "    # Calculate the regression line \"y values\" from the slope and intercept.\n",
      "    regress_values = x_values * slope + intercept\n",
      "    # Get the equation of the line.\n",
      "    line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
      "    # Create a scatter plot and plot the regression line.\n",
      "    plt.scatter(x_values,y_values)\n",
      "    plt.plot(x_values,regress_values,\"r\")\n",
      "    # Annotate the text for the line equation.\n",
      "    plt.annotate(line_eq, text_coordinates, fontsize=15, color=\"red\")\n",
      "    plt.title(title)\n",
      "    plt.xlabel('Latitude')\n",
      "    plt.ylabel(y_label)\n",
      "    plt.show()\n",
      "70/69:\n",
      "# Create the Hemisphere DataFrames.\n",
      "# Use loc[] to create a new df from objects in an existing df.\n",
      "# Syntax row = _df.loc[row_index].\n",
      "index13 = city_data_df.loc[13]\n",
      "index13\n",
      "70/70:\n",
      "# Retreive latitudes greater than or equal to 0.\n",
      "city_data_df[\"Lat\"] >= 0\n",
      "70/71:\n",
      "# Retreive all parameters for latitudes >= 0 from city_data_df.\n",
      "city_data_df.loc[(city_data_df[\"Lat\"] >= 0)].head()\n",
      "70/72:\n",
      "# Assign variables and create dataframes.\n",
      "northern_hemi_df = city_data_df.loc[(city_data_df[\"Lat\"] >= 0)]\n",
      "southern_hemi_df = city_data_df.loc[(city_data_df[\"Lat\"] < 0)]\n",
      "70/73:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\\n",
      "                        for Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/74:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\n\n",
      "                        for Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/75:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \"\\n\"\n",
      "                        for Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/76:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere\\n\n",
      "                        for Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/77:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere'\\n\n",
      "                        'for Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/78:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere',\\n\n",
      "                        'for Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/79:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       f'Linear Regression on the Northern Hemisphere\\n\n",
      "                        for Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/80:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       f'Linear Regression on the Northern Hemisphere \\nfor Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/81:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \n",
      "                       \\nfor Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/82:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Maximum Temperature', 'Max Temp',(10,40))\n",
      "70/83:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Maximum Temperature', 'Max Temp',(-20,40))\n",
      "70/84:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Maximum Temperature', 'Max Temp',(0,40))\n",
      "70/85:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Maximum Temperature', 'Max Temp',(10,-20))\n",
      "70/86:\n",
      "# Linear Regression on Maximum Temperature for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to maximum temperature column.\n",
      "y_values = northern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Maximum Temperature',\n",
      "                       # text_coordinates are (x,y)\n",
      "                       'Max Temp',(10,-20))\n",
      "70/87:\n",
      "# Linear regression on Maximum Temperature for Southern Hemisphere\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Max Temp\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor Maximum Temperature', \n",
      "                       'Max Temp',(-50,90))\n",
      "70/88:\n",
      "# Linear Regression on the Percent Humidity for the Northern Hemisphere.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "y_values = northern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(40,10))\n",
      "70/89:\n",
      "# Linear Regression on the Percent Humidity for the Northern Hemisphere.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "y_values = northern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(40,0))\n",
      "70/90:\n",
      "# Linear Regression on the Percent Humidity for the Northern Hemisphere.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "y_values = northern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(40,10))\n",
      "70/91:\n",
      "# Linear Regression on the Percent Humidity for the Northern Hemisphere.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "y_values = northern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(50,10))\n",
      "70/92:\n",
      "# Linear Regression on the Percent Humidity for the Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(-50,15))\n",
      "70/93:\n",
      "# Linear Regression on the Percent Humidity for the Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(-50,0))\n",
      "70/94:\n",
      "# Linear Regression on the Percent Humidity for the Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(-60,30))\n",
      "70/95:\n",
      "# Linear Regression on the Percent Humidity for the Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(-55,30))\n",
      "70/96:\n",
      "# Linear Regression on the Percent Humidity for the Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(-57,30))\n",
      "70/97:\n",
      "# Linear Regression on the Percent Humidity for the Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(-57,25))\n",
      "70/98:\n",
      "# Linear Regression on the Percent Humidity for the Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Humidity\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Humidity',\n",
      "                       '% Humidity',(-57,27))\n",
      "70/99:\n",
      "## Finding:\n",
      "#The correlation between the latitude and percent humidity is very low \n",
      "#because the r-value is less than 0.04 for BOTH the Northern and Southern Hemispheres.\n",
      "#This means that percent humidity is unpredictable due to changing weather patterns that can increase or decrease percent humidity.\n",
      "70/100:\n",
      "# Correlation Between Latitude and Percent Cloudiness.\n",
      "# Linear Regression on Percent Cloudiness for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to Cloudiness column.\n",
      "y_values = northern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Cloudiness',\n",
      "                       # text_coordinates are (x,y)\n",
      "                       'Cloudiness',(10,-20))\n",
      "70/101:\n",
      "# Correlation Between Latitude and Percent Cloudiness.\n",
      "# Linear Regression on Percent Cloudiness for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to Cloudiness column.\n",
      "y_values = northern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Cloudiness',\n",
      "                       # text_coordinates are (x,y)\n",
      "                       '% Cloudiness',(10,-20))\n",
      "70/102:\n",
      "# Correlation Between Latitude and Percent Cloudiness.\n",
      "# Linear Regression on Percent Cloudiness for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to Cloudiness column.\n",
      "y_values = northern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Cloudiness',\n",
      "                       # text_coordinates are (x,y)\n",
      "                       '% Cloudiness',(25,42))\n",
      "70/103:\n",
      "# Correlation Between Latitude and Percent Cloudiness.\n",
      "# Linear Regression on Percent Cloudiness for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to Cloudiness column.\n",
      "y_values = northern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Cloudiness',\n",
      "                       # text_coordinates are (x,y)\n",
      "                       '% Cloudiness',(20,42))\n",
      "70/104:\n",
      "# Correlation Between Latitude and Percent Cloudiness.\n",
      "# Linear Regression on Percent Cloudiness for Northern Hemisphere.\n",
      "# Set x values equal to latitude column.\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "# Set  y values equal to Cloudiness column.\n",
      "y_values = northern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor % Cloudiness',\n",
      "                       # text_coordinates are (x,y)\n",
      "                       '% Cloudiness',(15,42))\n",
      "70/105:\n",
      "#Linear Regression on Percent Cloudiness for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Cloudiness',\n",
      "                       '% Cloudiness',(-50,60))\n",
      "70/106:\n",
      "#Linear Regression on Percent Cloudiness for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Cloudiness',\n",
      "                       '% Cloudiness',(-50,80))\n",
      "70/107:\n",
      "#Linear Regression on Percent Cloudiness for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Cloudiness',\n",
      "                       '% Cloudiness',(-50,81))\n",
      "70/108:\n",
      "#Linear Regression on Percent Cloudiness for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Cloudiness',\n",
      "                       '% Cloudiness',(-55,80))\n",
      "70/109:\n",
      "#Linear Regression on Percent Cloudiness for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Cloudiness',\n",
      "                       '% Cloudiness',(-55,79))\n",
      "70/110:\n",
      "#Linear Regression on Percent Cloudiness for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Cloudiness\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor % Cloudiness',\n",
      "                       '% Cloudiness',(-55,78))\n",
      "70/111:\n",
      "# Correlation Between Latitude and Wind Speed.\n",
      "# Linear regression on Maximum Temperature for Northern Hemisphere\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Wind Speed\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Wind Speed', \n",
      "                       'Wind Speed',(-50,90))\n",
      "70/112:\n",
      "# Correlation Between Latitude and Wind Speed.\n",
      "# Linear regression on Maximum Temperature for Northern Hemisphere\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "y_values = northern_hemi_df[\"Wind Speed\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Wind Speed', \n",
      "                       'Wind Speed (mph)',(-50,90))\n",
      "70/113:\n",
      "# Correlation Between Latitude and Wind Speed.\n",
      "# Linear regression on Maximum Temperature for Northern Hemisphere\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "y_values = northern_hemi_df[\"Wind Speed\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Wind Speed', \n",
      "                       'Wind Speed (mph)',(0,30))\n",
      "70/114:\n",
      "# Correlation Between Latitude and Wind Speed.\n",
      "# Linear regression on Maximum Temperature for Northern Hemisphere\n",
      "x_values = northern_hemi_df[\"Lat\"]\n",
      "y_values = northern_hemi_df[\"Wind Speed\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Northern Hemisphere \\nfor Wind Speed', \n",
      "                       'Wind Speed (mph)',(0,25))\n",
      "70/115:\n",
      "# Linear Regression on Wind Speed for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Wind Speed\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor Wind Speed',\n",
      "                       'Wind Speed (mph)',(-50,35))\n",
      "70/116:\n",
      "# Linear Regression on Wind Speed for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Wind Speed\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor Wind Speed',\n",
      "                       'Wind Speed (mph)',(-50,25))\n",
      "70/117:\n",
      "# Linear Regression on Wind Speed for Southern Hemisphere.\n",
      "x_values = southern_hemi_df[\"Lat\"]\n",
      "y_values = southern_hemi_df[\"Wind Speed\"]\n",
      "# Call the function.\n",
      "plot_linear_regression(x_values, y_values,\n",
      "                       'Linear Regression on the Southern Hemisphere \\nfor Wind Speed',\n",
      "                       'Wind Speed (mph)',(-50,27))\n",
      "74/1:\n",
      "# Create Heatmaps for Weather Parameters.\n",
      "# Import the dependencies.\n",
      "import pandas as pd\n",
      "import gmaps\n",
      "import requests\n",
      "# Import the API key.\n",
      "from config import g_key\n",
      "74/2:\n",
      "# create df to read and store CSV.\n",
      "city_data_df = pd.read_csv(\"weather_data/cities.csv\")\n",
      "city_data_df.head()\n",
      "74/3:\n",
      "# Get df data types.\n",
      "city_data_df.dtypes\n",
      "74/4:\n",
      "# Configure gmaps to use Google API key.\n",
      "gmaps.configure(api_key=g_key)\n",
      "74/5:\n",
      "# Configure gmaps to use Google API key.\n",
      "gmaps.configure(api_key=g_key)\n",
      "74/6:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# 4. Assign the heatmap_layer variable to the heatmap_layer attribute and add in the locations.\n",
      "heatmap_layer = gmaps.heatmap_layer(locations, weights=temperatures)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heatmap_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "74/7:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# 4. Assign the heatmap_layer variable to the heatmap_layer attribute and add in the locations.\n",
      "heatmap_layer = gmaps.heatmap_layer(locations, weights=max_temp)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heatmap_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "74/8:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=max_temp)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "74/9:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heat_layer(locations, weights=max_temp)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "74/10:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=max_temp)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "74/11:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "74/12:\n",
      "# Get the maximum temperature.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "temps = []\n",
      "74/13:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "74/14:\n",
      "# Create Heatmaps for Weather Parameters.\n",
      "# Import the dependencies.\n",
      "import pandas as pd\n",
      "import gmaps\n",
      "import requests\n",
      "# Import the API key.\n",
      "from config import g_key\n",
      "# When using gmaps: Data used for any mapping must be either int or float.\n",
      "74/15:\n",
      "###Steps:\n",
      "# Import the dependencies.\n",
      "# Use Panads to create df to read and store CSV.\n",
      "# Configure gmaps to use Google API key.\n",
      "# Create maps\n",
      "74/16:\n",
      "# create df to read and store CSV.\n",
      "city_data_df = pd.read_csv(\"weather_data/cities.csv\")\n",
      "city_data_df.head()\n",
      "74/17:\n",
      "# Get df data types.\n",
      "city_data_df.dtypes\n",
      "74/18:\n",
      "# Configure gmaps to use Google API key.\n",
      "gmaps.configure(api_key=g_key)\n",
      "74/19:\n",
      "# Google heatmaps do not plot negative numbers.\n",
      "\n",
      "# Option 1, Use for loop to iterate through max_temp and add temperatures that are > 0 °F to a new list.\n",
      "# Get the maximum temperature.\n",
      "#max_temp = city_data_df[\"Max Temp\"]\n",
      "#temps = []\n",
      "#for temp in max_temp:\n",
      "    # max() gets the largest value between the temp and 0.\n",
      "    #temps.append(max(temp, 0))\n",
      "    \n",
      "# Option 2, Perform a list comprehension within the heatmap_layer() function.\n",
      "# Replace temps with this code for the list comprehension:\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "74/20:\n",
      "# Get the maximum temperature.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "temps = []\n",
      "74/21:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/1:\n",
      "# Create Heatmaps for Weather Parameters.\n",
      "# Import the dependencies.\n",
      "import pandas as pd\n",
      "import gmaps\n",
      "import requests\n",
      "# Import the API key.\n",
      "from config import g_key\n",
      "# When using gmaps: Data used for any mapping must be either int or float.\n",
      "77/2:\n",
      "###Steps:\n",
      "# Import the dependencies.\n",
      "# Use Panads to create df to read and store CSV.\n",
      "# Configure gmaps to use Google API key.\n",
      "# Create maps\n",
      "77/3:\n",
      "# create df to read and store CSV.\n",
      "city_data_df = pd.read_csv(\"weather_data/cities.csv\")\n",
      "city_data_df.head()\n",
      "77/4:\n",
      "# Get df data types.\n",
      "city_data_df.dtypes\n",
      "77/5:\n",
      "# Configure gmaps to use Google API key.\n",
      "gmaps.configure(api_key=g_key)\n",
      "77/6:\n",
      "# Google heatmaps do not plot negative numbers.\n",
      "\n",
      "# Option 1, Use for loop to iterate through max_temp and add temperatures that are > 0 °F to a new list.\n",
      "# Get the maximum temperature.\n",
      "#max_temp = city_data_df[\"Max Temp\"]\n",
      "#temps = []\n",
      "#for temp in max_temp:\n",
      "    # max() gets the largest value between the temp and 0.\n",
      "    #temps.append(max(temp, 0))\n",
      "    \n",
      "# Option 2, Perform a list comprehension within the heatmap_layer() function.\n",
      "# Replace temps with this code for the list comprehension:\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "77/7:\n",
      "# Get the maximum temperature.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "temps = []\n",
      "77/8:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "fig = gmaps.figure()\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/9:\n",
      "# Adjust Heatmap Zoom, Intensity, and Point Radius\n",
      "# 1, Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "77/10:\n",
      "# Adjust Heatmap Zoom, Intensity, and Point Radius\n",
      "# 1, Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "fig\n",
      "77/11:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/12:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1)\n",
      "# Assign the heatmap variable.\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/13:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/14:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=0.5)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/15:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/16:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/17:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.3)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/18:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.4)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/19:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/20:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/21:\n",
      "# Create heatmap for the maximum temperature.\n",
      "# 1. Assign the locations to an array of latitude and longitude pairs.\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "# 2. Assign the weights variable to some values.\n",
      "# The array length must be equal to the locations array length.\n",
      "max_temp = city_data_df[\"Max Temp\"]\n",
      "# 3. Assign the figure variable to the gmaps.figure() attribute.\n",
      "#fig = gmaps.figure()\n",
      "# Add geographic center of Earth in form of latitude and longitude (30.0° N and 31.0° E).\n",
      "# Also, add a zoom level so that only one map of Earth is shown.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.4)\n",
      "# Assign the heatmap variable.\n",
      "#heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp])\n",
      "# Adjust dissipation option hor better heat display\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=[max(temp, 0) for temp in max_temp], dissipating=False, max_intensity=300, point_radius=4)\n",
      "# 5. Add the heatmap layer.\n",
      "fig.add_layer(heat_layer)\n",
      "# 6. Call the figure to plot the data.\n",
      "fig\n",
      "77/22:\n",
      "# Create Percent Humidity Heatmap\n",
      "# Heatmap of percent humidity\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "humidity = city_data_df[\"Humidity\"]\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=humidity, dissipating=False, max_intensity=300, point_radius=4)\n",
      "\n",
      "fig.add_layer(heat_layer)\n",
      "# Call the figure to plot the data.\n",
      "fig\n",
      "77/23:\n",
      "# Percent cloudiness heatmap\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "clouds = city_data_df[\"Cloudiness\"]\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=clouds, dissipating=False, max_intensity=300, point_radius=4)\n",
      "\n",
      "fig.add_layer(heat_layer)\n",
      "# Call the figure to plot the data.\n",
      "fig\n",
      "77/24:\n",
      "# Wind Speed Heatmap\n",
      "locations = city_data_df[[\"Lat\", \"Lng\"]]\n",
      "wind = city_data_df[\"Wind Speed\"]\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=wind, dissipating=False, max_intensity=300, point_radius=4)\n",
      "\n",
      "fig.add_layer(heat_layer)\n",
      "# Call the figure to plot the data.\n",
      "fig\n",
      "77/25:\n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "77/26:\n",
      "# Create df that contains all cities that meet temperature criteria.\n",
      "preferred_cities_df = city_data_df.loc[(city_data_df[\"Max Temp\"] <= max_temp) & \\\n",
      "                                       (city_data_df[\"Max Temp\"] >= min_temp)]\n",
      "preferred_cities_df.head(10)\n",
      "77/27:\n",
      "# Look for null values.\n",
      "# Options: \n",
      "# preferred_cities_df.isnull().sum()\n",
      "# preferred_cities_df.notnull().sum()\n",
      "preferred_cities_df.count()\n",
      "77/28:\n",
      "# Map Vacation Criteria.\n",
      "# Get Travel Destinations.\n",
      "# Make coppy, .copy() of preferred_cities_df, rename it, edit the columns.\n",
      "hotel_df = preferred_cities_df[[\"City\", \"Country\", \"Max Temp\", \"Lat\", \"Lng\"]].copy()\n",
      "hotel_df[\"Hotel Name\"] = \"\"\n",
      "hotel_df.head(10)\n",
      "77/29:\n",
      "# Set parameters to search for a hotel.\n",
      "params = {\n",
      "    \"radius\": 5000,\n",
      "    \"type\": \"lodging\",\n",
      "    \"key\": g_key\n",
      "}\n",
      "77/30:\n",
      "# Import the API key.\n",
      "from config import g_key\n",
      "# Set parameters to search for a hotel.\n",
      "params = {\n",
      "    \"radius\": 5000,\n",
      "    \"type\": \"lodging\",\n",
      "    \"key\": g_key\n",
      "}\n",
      "78/1:\n",
      "# Dependencies and Setup\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "78/2:\n",
      "# Set the parameters to search for a hotel in Paris.\n",
      "params = {\n",
      "    \"radius\": 5000,\n",
      "    \"types\": \"lodging\",\n",
      "    \"key\": g_key,\n",
      "    \"location\": \"48.8566, 2.3522\"}\n",
      "# Use base URL to search for hotels in Paris.\n",
      "base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "# Make request and get the JSON data from the search.\n",
      "hotels = requests.get(base_url, params=params).json()\n",
      "\n",
      "hotels\n",
      "78/3:\n",
      "# Get all hotels in the results dictionary.\n",
      "len(hotels[\"results\"])\n",
      "77/31:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "    try:\n",
      "    hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "    print(\"Hotel not found... skipping.\")\n",
      "77/32:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/33:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/34:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/35:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "except (IndexError, NewError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/36:\n",
      "# Import the API key.\n",
      "from config import g_key\n",
      "# Set parameters to search for a hotel.\n",
      "params = {\"radius\": 5000,\n",
      "        \"type\": \"lodging\",\n",
      "        \"key\": g_key}\n",
      "77/37:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "except (IndexError, NewError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/38:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError, NewError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/39:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/40:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "hotel_df.head(10)\n",
      "77/41:\n",
      "# ouput of hotel_df.head\n",
      "hotel_df.head(10)\n",
      "77/42:\n",
      "# Iterate through df.\n",
      "# Use iterrows() to perform iteration.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "\n",
      "    # Add latitude and longitude to location key for the params dictionary.\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # Use the search term: \"lodging\" and our latitude and longitude.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "    # Make request and get the JSON data from the search.\n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "    # Grab the first hotel from the results and store the name.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "77/43:\n",
      "# Maximum Temperature Heatmap from a hotel_df.\n",
      "locations = hotel_df[[\"Lat\", \"Lng\"]]\n",
      "max_temp = hotel_df[\"Max Temp\"]\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=max_temp, dissipating=False,\n",
      "             max_intensity=300, point_radius=4)\n",
      "# Assign variable for markers to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations)\n",
      "fig.add_layer(heat_layer)\n",
      "# Add markers on top of heatmap.\n",
      "fig.add_layer(marker_layer)\n",
      "# Call the figure to plot the data.\n",
      "fig\n",
      "77/44:\n",
      "# Add pop-up marker for each city displaying hotel name, city name, country, maximum temperature.\n",
      "# 1, Add info_box_template.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Max Temp</dt><dd>{Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 2, Set the hotel_info equal to the info_box_content...\n",
      "# 2a, Find hotel information by iterating through hotel_df, using iterrows().\n",
      "# Assign variable.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in hotel_df.iterrows()]\n",
      "77/45:\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "locations = hotel_df[[\"Lat\", \"Lng\"]]\n",
      "max_temp = hotel_df[\"Max Temp\"]\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=max_temp, dissipating=False,\n",
      "             max_intensity=300, point_radius=4)\n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig.add_layer(heat_layer)\n",
      "# Add markers on top of heatmap.\n",
      "fig.add_layer(marker_layer)\n",
      "# Call the figure to plot the data.\n",
      "fig\n",
      "84/1:\n",
      "# RECREATED STARTER CODE FROM (https://github.com/UCF-Coding-Boot-Camp/UCF-VIRT-DATA-PT-06-2022-U-B/blob/main/06-APIs/Challenge_Solution/Weather_Database/Weather_Database_Challenge.ipynb).\n",
      "# AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "84/2:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "84/3:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config.py import weather_api_key\n",
      "84/4:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "84/5:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "#from config import weather_api_key\n",
      "84/6:\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "84/7:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "84/8:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "#from config import weather_api_key\n",
      "85/1:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "# RECREATED STARTER CODE FROM (https://github.com/UCF-Coding-Boot-Camp/UCF-VIRT-DATA-PT-06-2022-U-B/blob/main/06-APIs/Challenge_Solution/Weather_Database/Weather_Database_Challenge.ipynb).\n",
      "# AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "85/2:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "#from config import weather_api_key\n",
      "85/3:\n",
      "# Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "85/4:\n",
      "# Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=2000)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=2000)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "85/5:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "85/6:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "85/7:\n",
      "# Import your OpenWeatherMap's API key and assemble the API call URL as a string variable. Recall to edit the config.py file to add your API key; also, it's critical to avoid publishing your API key on your GitHub repository.\n",
      "\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "85/8:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "85/9:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "85/10:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "85/11:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "97/1:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "# RECREATED STARTER CODE FROM (https://github.com/UCF-Coding-Boot-Camp/UCF-VIRT-DATA-PT-06-2022-U-B/blob/main/06-APIs/Challenge_Solution/Weather_Database/Weather_Database_Challenge.ipynb).\n",
      "# AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "97/2:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "97/3:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "#from config import weather_api_key\n",
      "97/4:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "# RECREATED STARTER CODE FROM (https://github.com/UCF-Coding-Boot-Camp/UCF-VIRT-DATA-PT-06-2022-U-B/blob/main/06-APIs/Challenge_Solution/Weather_Database/Weather_Database_Challenge.ipynb).\n",
      "# AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "97/5:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "#from config import weather_api_key\n",
      "97/6:\n",
      "# Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=2000)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=2000)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "97/7:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "97/8:\n",
      "# Use the citipy module to get the nearest city for each latitude and longitude combination.\n",
      "\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "97/9:\n",
      "# Import your OpenWeatherMap's API key and assemble the API call URL as a string variable. Recall to edit the config.py file to add your API key; also, it's critical to avoid publishing your API key on your GitHub repository.\n",
      "\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "97/10:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "# RECREATED STARTER CODE FROM (https://github.com/UCF-Coding-Boot-Camp/UCF-VIRT-DATA-PT-06-2022-U-B/blob/main/06-APIs/Challenge_Solution/Weather_Database/Weather_Database_Challenge.ipynb).\n",
      "# AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "97/11:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "97/12:\n",
      "# Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=2000)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=2000)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "97/13:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "97/14:\n",
      "# Use the citipy module to get the nearest city for each latitude and longitude combination.\n",
      "\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "97/15:\n",
      "# Import your OpenWeatherMap's API key and assemble the API call URL as a string variable. Recall to edit the config.py file to add your API key; also, it's critical to avoid publishing your API key on your GitHub repository.\n",
      "\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "97/16:\n",
      "# Retrieve the following information from the API call:\n",
      "# Latitude and longitude\n",
      "\n",
      "# Maximum temperature\n",
      "\n",
      "# Percent humidity\n",
      "\n",
      "# Percent cloudiness\n",
      "\n",
      "# Wind speed\n",
      "\n",
      "# Weather description (for example, clouds, fog, light rain, clear sky)\n",
      "97/17:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "\n",
      "# Loop through all the cities in the list.\n",
      "for i, city in enumerate(cities):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        # Increment set_count by 1.\n",
      "        set_count += 1\n",
      "        # Increment record_count by 1.\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    # Remove the blank spaces in the city name and concatenate the city name.\n",
      "    city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "    # Log the URL, record, and set numbers and the city.\n",
      "    print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "    # Add 1 to the record count.\n",
      "    record_count += 1 \n",
      "    \n",
      "    # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "       \n",
      "        city_weather_description=city_weather[\"weather\"][0][\"description\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Country\": city_country,\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Current Description\": city_weather_description})\n",
      "        \n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "97/18:\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "97/19:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "WeatherPy_Database_df = pd.DataFrame(WeatherPy_Database)\n",
      "WeatherPy_Database_df.head(10)\n",
      "97/20:\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(WeatherPy_Database)\n",
      "97/21:\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(city_data)\n",
      "97/22:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "97/23:\n",
      "# Format the \"Lat\"'s decimal separator.\n",
      "city_data_df[\"Lat\"] = city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "# Format the \"Lng\"'s decimal separator.\n",
      "city_data_df[\"Lng\"] = city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "97/24:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/25:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/26:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=[# Format the \"Lat\"'s decimal separator.\n",
      "    city_data_df[\"Lat\"] = city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    city_data_df[\"Lng\"] = city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/27:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=[# Format the \"Lat\"'s decimal separator.\n",
      "    city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/28:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=[# Format the \"Lat\"'s decimal separator.\n",
      "    city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/29:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=[# Format the \"Lat\"'s decimal separator.\n",
      "    (city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    city_data_df[\"Lng\"].map(\"{:.2f}\".format))]\n",
      "city_data_df=city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/30:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=[(# Format the \"Lat\"'s decimal separator.\n",
      "    city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    city_data_df[\"Lng\"].map(\"{:.2f}\".format))]\n",
      "city_data_df=city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/31:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=[(# Format the \"Lat\"'s decimal separator.\n",
      "    (city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    (city_data_df[\"Lng\"].map(\"{:.2f}\".format))]\n",
      "city_data_df=city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/32:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=(# Format the \"Lat\"'s decimal separator.\n",
      "    (city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    (city_data_df[\"Lng\"].map(\"{:.2f}\".format))\n",
      "city_data_df=city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/33:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=(# Format the \"Lat\"'s decimal separator.\n",
      "    (city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    (city_data_df[\"Lng\"].map(\"{:.2f}\".format))\n",
      "city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/34:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=(# Format the \"Lat\"'s decimal separator.\n",
      "    (city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    (city_data_df[\"Lng\"].map(\"{:.2f}\".format))\n",
      "city_data_df= city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/35:\n",
      "# Format Lat and Lng columns\n",
      "new_lat_long_format=(# Format the \"Lat\"'s decimal separator.\n",
      "    (city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    (city_data_df[\"Lng\"].map(\"{:.2f}\".format))\n",
      "city_data_df = city_data_df[new_lat_long_format]\n",
      "city_data_df.head(10)\n",
      "97/36:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/37:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/38:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "97/39:\n",
      "# Format Lat and Lng columns\n",
      "#new_lat_long_format=(# Format the \"Lat\"'s decimal separator.\n",
      "    #(city_data_df[\"Lat\"].map(\"{:.2f}\".format),\n",
      "    # Format the \"Lng\"'s decimal separator.\n",
      "    #(city_data_df[\"Lng\"].map(\"{:.2f}\".format))\n",
      "#city_data_df = city_data_df[new_lat_long_format]\n",
      "#city_data_df.head(10)\n",
      "97/40: # Export the DataFrame as a CSV file, and save it as WeatherPy_Database.csv in the Weather_Database folder.\n",
      "97/41:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/42:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df =city_data_df[\"Lat\"].map(\"{:.2f}\".format\n",
      "city_data_df=city_data_df[\"Lng\"].map(\"{:.2f}\".format\n",
      "city_data_df.head(10)\n",
      "97/43:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df =city_data_df[\"Lat\"].map(\"{:.2f}\".format\n",
      "city_data_df =city_data_df[\"Lng\"].map(\"{:.2f}\".format\n",
      "city_data_df.head(10)\n",
      "97/44:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format\n",
      "city_data_df.head(10)\n",
      "97/45:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format\n",
      "city_data_df.head(10)\n",
      "97/46:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "97/47:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/48:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "\n",
      "# RECREATED STARTER CODE FROM AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "97/49:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "97/50: # Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "97/51:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=2000)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=2000)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "97/52:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "97/53: # Use the citipy module to get the nearest city for each latitude and longitude combination.\n",
      "97/54:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "97/55: # Import your OpenWeatherMap's API key and assemble the API call URL as a string variable. Recall to edit the config.py file to add your API key; also, it's critical to avoid publishing your API key on your GitHub repository.\n",
      "97/56:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "97/57:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/58:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "97/59:\n",
      "# Create the output File (CSV)\n",
      "output_data_file_one = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file_one, index_label=\"City_ID\")\n",
      "97/60:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/1:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "\n",
      "# RECREATED STARTER CODE FROM AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "99/2:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "99/3: # Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "99/4:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=2000)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=2000)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "99/5:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "99/6: # Use the citipy module to get the nearest city for each latitude and longitude combination.\n",
      "99/7:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "99/8: # Import your OpenWeatherMap's API key and assemble the API call URL as a string variable. Recall to edit the config.py file to add your API key; also, it's critical to avoid publishing your API key on your GitHub repository.\n",
      "99/9:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "99/10:\n",
      "# Retrieve the following information from the API call:\n",
      "# Latitude and longitude\n",
      "\n",
      "# Maximum temperature\n",
      "\n",
      "# Percent humidity\n",
      "\n",
      "# Percent cloudiness\n",
      "\n",
      "# Wind speed\n",
      "\n",
      "# Weather description (for example, clouds, fog, light rain, clear sky)\n",
      "99/11:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "\n",
      "# Loop through all the cities in the list.\n",
      "for i, city in enumerate(cities):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        # Increment set_count by 1.\n",
      "        set_count += 1\n",
      "        # Increment record_count by 1.\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    # Remove the blank spaces in the city name and concatenate the city name.\n",
      "    city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "    # Log the URL, record, and set numbers and the city.\n",
      "    print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "    # Add 1 to the record count.\n",
      "    record_count += 1 \n",
      "    \n",
      "    # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "       \n",
      "        city_weather_description=city_weather[\"weather\"][0][\"description\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Country\": city_country,\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Current Description\": city_weather_description})\n",
      "        \n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "99/12:\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(city_data)\n",
      "99/13: # Add the weather data to a new DataFrame.\n",
      "99/14:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "99/15:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "99/16: # Export the DataFrame as a CSV file, and save it as WeatherPy_Database.csv in the Weather_Database folder.\n",
      "99/17:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/18:\n",
      "import matplotlib.pyplot as plt\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "99/19:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/20:\n",
      "\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "99/21:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "99/22:\n",
      "\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "99/23:\n",
      "import matplotlib.pyplot as plt\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "99/24:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "99/25:\n",
      "import matplotlib.pyplot as plt\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df.head(10)\n",
      "99/26: # Export the DataFrame as a CSV file, and save it as WeatherPy_Database.csv in the Weather_Database folder.\n",
      "99/27:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/28:\n",
      "\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "#city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "#city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "#city_data_df.head(10)\n",
      "99/29:\n",
      "new_column_format=[\"{:.2f}\"]\n",
      "city_data_df=city_data_df[new_column_format]\n",
      "city_data_df.head(10)\n",
      "99/30:\n",
      "new_column_format=[[\"Lat\"].map(\"{:.2f}\".format), [\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_column_format]\n",
      "city_data_df.head(10)\n",
      "99/31:\n",
      "new_latlng_format=[city_data_df[\"Lat\"].map(\"{:.2f}\".format), city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_latlng_format]\n",
      "city_data_df.head(10)\n",
      "99/32:\n",
      "new_latlng_format=[f'city_data_df[\"Lat\"].map(\"{:.2f}\".format), city_data_df[\"Lng\"].map(\"{:.2f}\".format)']\n",
      "city_data_df=city_data_df[new_latlng_format]\n",
      "city_data_df.head(10)\n",
      "99/33:\n",
      "new_latlng_format=[city_data_df[\"Lat\"].map(\"{:.2f}\".format), city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_latlng_format]\n",
      "city_data_df.head(10)\n",
      "99/34:\n",
      "new_latlng_format=[city_data_df[\"Lat\"].map_f(\"{:.2f}\".format), city_data_df[\"Lng\"].map_f(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_latlng_format]\n",
      "city_data_df.head(10)\n",
      "99/35:\n",
      "new_latlng_format=[city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format), city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_latlng_format]\n",
      "city_data_df.head(10)\n",
      "99/36:\n",
      "new_latlng_format=[city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format), city_data_df[\"Lng\"]=city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_latlng_format]\n",
      "city_data_df.head(10)\n",
      "99/37: # Export the DataFrame as a CSV file, and save it as WeatherPy_Database.csv in the Weather_Database folder.\n",
      "99/38:\n",
      "\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df=city_data_df\n",
      "city_data_df.head(10)\n",
      "99/39:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "99/40:\n",
      "\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df=city_data_df\n",
      "city_data_df.head(10)\n",
      "99/41:\n",
      "new_latlng_format=[city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format), city_data_df[\"Lng\"]=city_data_df[\"Lng\"].map(\"{:.2f}\".format)]\n",
      "city_data_df=city_data_df[new_latlng_format]\n",
      "city_data_df.head(10)\n",
      "99/42: # Export the DataFrame as a CSV file, and save it as WeatherPy_Database.csv in the Weather_Database folder.\n",
      "99/43:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/44:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "99/45:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df=city_data_df\n",
      "city_data_df.head(10)\n",
      "99/46: # Export the DataFrame as a CSV file, and save it as WeatherPy_Database.csv in the Weather_Database folder.\n",
      "99/47:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/48:\n",
      "# Create the output File (CSV)\n",
      "output_data_file = \"Weather_Database/WeatherPy_Database.csv\"\n",
      "# Export the city_data into a csv\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/49:\n",
      "output_data_file=\"Weather_database/WeatherPy_Database.csv\"\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "99/50:\n",
      "output_data_file=\"./WeatherPy_Database.csv\"\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "102/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "102/2:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "102/3:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "102/4:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"Weather_Database/WeatherPy_database.csv\")\n",
      "city_data_df.head()\n",
      "102/5:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"Weather_Database/WeatherPy_database.csv\")\n",
      "city_data_df.head()\n",
      "102/6:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_database.csv\")\n",
      "city_data_df.head()\n",
      "102/7:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "102/8:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_database.csv\")\n",
      "city_data_df.head()\n",
      "102/9:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "102/10:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"http://localhost:8888/tree/World_Weather_Analysis/Weather_Database/WeatherPy_database.csv\")\n",
      "city_data_df.head()\n",
      "102/11:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"Weather_Database/WeatherPy_database.csv\")\n",
      "city_data_df.head()\n",
      "102/12:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"http://localhost:8888/edit/World_Weather_Analysis/Weather_Database/WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "102/13:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"Weather_Database/WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "102/14:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "102/15:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "102/16:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "102/17:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "102/18:\n",
      "# 2. Prompt the user to enter minimum and maximum temperature criteria \n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "102/19:\n",
      "# 3. Filter the city_data_df DataFrame using the input statements to create a new DataFrame using the loc method.\n",
      "# Create df that contains all cities that meet temperature criteria.\n",
      "preferred_cities_df = city_data_df.loc[(city_data_df[\"Max Temp\"] <= max_temp) & \\\n",
      "                                       (city_data_df[\"Max Temp\"] >= min_temp)]\n",
      "preferred_cities_df.head(10)\n",
      "102/20:\n",
      "# 2. Prompt the user to enter minimum and maximum temperature criteria \n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "102/21:\n",
      "# 3. Filter the city_data_df DataFrame using the input statements to create a new DataFrame using the loc method.\n",
      "# Create df that contains all cities that meet temperature criteria.\n",
      "preferred_cities_df = city_data_df.loc[(city_data_df[\"Max Temp\"] <= max_temp) & \\\n",
      "                                       (city_data_df[\"Max Temp\"] >= min_temp)]\n",
      "preferred_cities_df.head(10)\n",
      "102/22:\n",
      "# 4a. Determine if there are any empty rows.\n",
      "# Look for null values.\n",
      "preferred_cities_df.isnull().sum()\n",
      "102/23:\n",
      "# 5a. Create DataFrame called hotel_df to store hotel names along with city, country, max temp, and coordinates.\n",
      "hotel_df = clean_df[[\"City\", \"Country\", \"Max Temp\", \"Current Description\", \"Lat\", \"Lng\"]].copy()\n",
      "\n",
      "# 5b. Create a new column \"Hotel Name\"\n",
      "hotel_df[\"Hotel Name\"] = \"\"\n",
      "hotel_df.head(10)\n",
      "102/24:\n",
      "# 5a. Create DataFrame called hotel_df to store hotel names along with city, country, max temp, and coordinates.\n",
      "hotel_df = clean_df[[\"City\", \"Country\", \"Max Temp\", \"Current Description\", \"Lat\", \"Lng\"]].copy()\n",
      "\n",
      "# 5b. Create a new column \"Hotel Name\"\n",
      "hotel_df[\"Hotel Name\"] = \" \"\n",
      "hotel_df.head(10)\n",
      "102/25: len(preferred_cities_df)\n",
      "102/26:\n",
      "# 4b. Drop any empty rows and create a new DataFrame that doesn’t have empty rows.\n",
      "clean_travel_cities=preferred_cities_df.dropna()\n",
      "102/27:\n",
      "# 4b. Drop any empty rows and create a new DataFrame that doesn’t have empty rows.\n",
      "clean_travel_cities_df=preferred_cities_df.dropna()\n",
      "102/28: len(clean_travel_cities_df)\n",
      "102/29:\n",
      "# 5a. Create DataFrame called hotel_df to store hotel names along with city, country, max temp, and coordinates.\n",
      "hotel_df = clean_df[[\"City\", \"Country\", \"Max Temp\", \"Current Description\", \"Lat\", \"Lng\"]].copy()\n",
      "\n",
      "# 5b. Create a new column \"Hotel Name\"\n",
      "hotel_df[\"Hotel Name\"] = \" \"\n",
      "hotel_df.head(10)\n",
      "102/30:\n",
      "# 5a. Create DataFrame called hotel_df to store hotel names along with city, country, max temp, and coordinates.\n",
      "hotel_df = clean_travel_cities_df[[\"City\", \"Country\", \"Max Temp\", \"Current Description\", \"Lat\", \"Lng\"]].copy()\n",
      "\n",
      "# 5b. Create a new column \"Hotel Name\"\n",
      "hotel_df[\"Hotel Name\"] = \" \"\n",
      "hotel_df.head(10)\n",
      "102/31:\n",
      "# 6a. Set parameters to search for hotels with 5000 meters.\n",
      "params = {\n",
      "    \"radius\": 5000,\n",
      "    \"type\": \"lodging\",\n",
      "    \"key\": g_key\n",
      "}\n",
      "\n",
      "# 6b. Iterate through the hotel DataFrame.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "    \n",
      "    # 6c. Get latitude and longitude from DataFrame\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # 6d. Set up the base URL for the Google Directions API to get JSON data.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "\n",
      "    # 6e. Make request and retrieve the JSON data from the search. \n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "   \n",
      "    # 6f. Get the first hotel from the results and store the name, if a hotel isn't found skip the city.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "102/32:\n",
      "# 7. Drop the rows where there is no Hotel Name.\n",
      "hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "102/33:\n",
      "# 7. Drop the rows where there is no Hotel Name.\n",
      "clean_hotel_df = hotel_df[hotel_df[\"Hotel Name\"]!=\" \"]\n",
      "clean_hotel_df.head()\n",
      "102/34:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"Vacation_Search/clean_hotel_df.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "102/35:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"./clean_hotel_df.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "102/36:\n",
      "# 9. Using the template add city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "Current Description\n",
      "# 10a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "102/37:\n",
      "# 9. Using the template add city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "102/38:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=max_temp, dissipating=False,\n",
      "             max_intensity=300, point_radius=4)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/39:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"./clean_hotel_df.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "102/40:\n",
      "# 9. Using the template add city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "102/41:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=max_temp, dissipating=False,\n",
      "             max_intensity=300, point_radius=4)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/42:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure()\n",
      "heat_layer = gmaps.heatmap_layer(locations, weights=max_temp, dissipating=False,\n",
      "             max_intensity=300, point_radius=4)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/43:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure()\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/44:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=1.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/45:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/46:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(20.0, 31.0), zoom_level=2)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/47:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(20.0, 21.0), zoom_level=2)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/48:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(35.0, 36.0), zoom_level=2)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/49:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(35.0, 36.0), zoom_level=0.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/50:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(35.0, 36.0), zoom_level=3)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/51:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(20.0, 21.0), zoom_level=3)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/52:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(20.0, 21.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/53:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/54:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(40.0, 41.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/55:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(50.0, 51.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/56:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(40.0, 60.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/57:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(40.0, 70.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/58:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/59:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/60:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/61:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/62:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/63:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure()\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/64:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.5)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "102/65:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "105/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "105/2:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "105/3:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/4:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/5:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/6:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "106/1:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"Vacation_Search/WheatherPy_vacation.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "106/2:\n",
      "# 7. Drop the rows where there is no Hotel Name.\n",
      "clean_hotel_df = hotel_df[hotel_df[\"Hotel Name\"]!=\" \"]\n",
      "clean_hotel_df.head()\n",
      "107/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "107/2:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "107/3:\n",
      "# 2. Prompt the user to enter minimum and maximum temperature criteria \n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "108/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "108/2:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "108/3:\n",
      "# 2. Prompt the user to enter minimum and maximum temperature criteria \n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "108/4:\n",
      "# 3. Filter the city_data_df DataFrame using the input statements to create a new DataFrame using the loc method.\n",
      "# Create df that contains all cities that meet temperature criteria.\n",
      "preferred_cities_df = city_data_df.loc[(city_data_df[\"Max Temp\"] <= max_temp) & \\\n",
      "                                       (city_data_df[\"Max Temp\"] >= min_temp)]\n",
      "preferred_cities_df.head(10)\n",
      "108/5:\n",
      "# 3. Filter the city_data_df DataFrame using the input statements to create a new DataFrame using the loc method.\n",
      "# Create df that contains all cities that meet temperature criteria.\n",
      "preferred_cities_df = city_data_df.loc[(city_data_df[\"Max Temp\"] <= max_temp) & \\\n",
      "                                       (city_data_df[\"Max Temp\"] >= min_temp)]\n",
      "preferred_cities_df.head(10)\n",
      "108/6: len(preferred_cities_df)\n",
      "108/7:\n",
      "# 4a. Determine if there are any empty rows.\n",
      "# Look for null values.\n",
      "preferred_cities_df.isnull().sum()\n",
      "108/8:\n",
      "# 4b. Drop any empty rows and create a new DataFrame that doesn’t have empty rows.\n",
      "clean_travel_cities_df=preferred_cities_df.dropna()\n",
      "108/9: len(clean_travel_cities_df)\n",
      "108/10:\n",
      "# 5a. Create DataFrame called hotel_df to store hotel names along with city, country, max temp, and coordinates.\n",
      "hotel_df = clean_travel_cities_df[[\"City\", \"Country\", \"Max Temp\", \"Current Description\", \"Lat\", \"Lng\"]].copy()\n",
      "\n",
      "# 5b. Create a new column \"Hotel Name\"\n",
      "hotel_df[\"Hotel Name\"] = \" \"\n",
      "hotel_df.head(10)\n",
      "108/11:\n",
      "# 6a. Set parameters to search for hotels with 5000 meters.\n",
      "params = {\n",
      "    \"radius\": 5000,\n",
      "    \"type\": \"lodging\",\n",
      "    \"key\": g_key\n",
      "}\n",
      "\n",
      "# 6b. Iterate through the hotel DataFrame.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "    \n",
      "    # 6c. Get latitude and longitude from DataFrame\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # 6d. Set up the base URL for the Google Directions API to get JSON data.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "\n",
      "    # 6e. Make request and retrieve the JSON data from the search. \n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "   \n",
      "    # 6f. Get the first hotel from the results and store the name, if a hotel isn't found skip the city.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "108/12:\n",
      "# 7. Drop the rows where there is no Hotel Name.\n",
      "clean_hotel_df = hotel_df[hotel_df[\"Hotel Name\"]!=\" \"]\n",
      "clean_hotel_df.head()\n",
      "108/13:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"Vacation_Search/WheatherPy_vacation.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "108/14:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"./WheatherPy_vacation.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "108/15:\n",
      "# 9. Using the template add city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "108/16:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "105/7:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "105/8:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/9:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/10:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "105/11:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "105/12:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/13:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "105/14:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "105/15:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/16:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "105/17:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "105/18:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "105/19:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "111/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "111/2:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "111/3:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"../Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "111/4:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/2:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "114/1:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "\n",
      "# RECREATED STARTER CODE FROM AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "114/2:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "114/3: # Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "114/4:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=2000)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=2000)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "114/5:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "114/6: # Use the citipy module to get the nearest city for each latitude and longitude combination.\n",
      "114/7:\n",
      "# Create a list to store city names.\n",
      "cities = []\n",
      "# Iterate through the coordinates()\n",
      "for coordinate in coordinates:\n",
      "    # Retrieve the nearest city using the latitude and longitude pair.\n",
      "    city = citipy.nearest_city(coordinate[0], coordinate[1]).city_name\n",
      "\n",
      "    # If the city is not in cities[]...\n",
      "    if city not in cities:\n",
      "        # Add it to the cities list.\n",
      "        cities.append(city)\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(cities)\n",
      "114/8: # Import your OpenWeatherMap's API key and assemble the API call URL as a string variable. Recall to edit the config.py file to add your API key; also, it's critical to avoid publishing your API key on your GitHub repository.\n",
      "114/9:\n",
      "# Build the basic URL for the OpenWeatherMap with your weather_api_key added to the URL.\n",
      "url = \"http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=\" + weather_api_key\n",
      "114/10:\n",
      "# Retrieve the following information from the API call:\n",
      "# Latitude and longitude\n",
      "\n",
      "# Maximum temperature\n",
      "\n",
      "# Percent humidity\n",
      "\n",
      "# Percent cloudiness\n",
      "\n",
      "# Wind speed\n",
      "\n",
      "# Weather description (for example, clouds, fog, light rain, clear sky)\n",
      "114/11:\n",
      "# Create an empty list to hold the weather data.\n",
      "city_data = []\n",
      "# Print the beginning of the logging.\n",
      "print(\"Beginning Data Retrieval     \")\n",
      "print(\"-----------------------------\")\n",
      "\n",
      "# Create counters to start at 1.\n",
      "record_count = 1\n",
      "set_count = 1\n",
      "\n",
      "# Loop through all the cities in the list.\n",
      "for i, city in enumerate(cities):\n",
      "\n",
      "    # Group cities in sets of 50 for logging purposes.\n",
      "    # If the remainder of the index divided by 50 is equal to 0 and greater than 50.\n",
      "    if (i % 50 == 0 and i >= 50):\n",
      "        # Increment set_count by 1.\n",
      "        set_count += 1\n",
      "        # Increment record_count by 1.\n",
      "        record_count = 1\n",
      "        # 60 second pause to prevent time-out errors.\n",
      "        time.sleep(60)\n",
      "\n",
      "    # Create endpoint URL with each city.\n",
      "    # Remove the blank spaces in the city name and concatenate the city name.\n",
      "    city_url = url + \"&q=\" + city.replace(\" \",\"+\")\n",
      "\n",
      "    # Log the URL, record, and set numbers and the city.\n",
      "    print(f\"Processing Record {record_count} of Set {set_count} | {city}\")\n",
      "    # Add 1 to the record count.\n",
      "    record_count += 1 \n",
      "    \n",
      "    # Run an API request for each of the cities.\n",
      "    try:\n",
      "        # Parse the JSON and retrieve data.\n",
      "        city_weather = requests.get(city_url).json()\n",
      "        # Parse out the needed data.\n",
      "        #Assign variables for each piece of data we need.\n",
      "        city_country = city_weather[\"sys\"][\"country\"]\n",
      "        city_lat = city_weather[\"coord\"][\"lat\"]\n",
      "        city_lng = city_weather[\"coord\"][\"lon\"]\n",
      "        city_max_temp = city_weather[\"main\"][\"temp_max\"]\n",
      "        city_humidity = city_weather[\"main\"][\"humidity\"]\n",
      "        city_clouds = city_weather[\"clouds\"][\"all\"]\n",
      "        city_wind = city_weather[\"wind\"][\"speed\"]\n",
      "       \n",
      "        city_weather_description=city_weather[\"weather\"][0][\"description\"]\n",
      "        # Convert the date to ISO standard.\n",
      "        city_date = datetime.utcfromtimestamp(city_weather[\"dt\"]).strftime('%Y-%m-%d %H:%M:%S')\n",
      "        # Append the city information into city_data list in a dictionary format.\n",
      "        city_data.append({\"City\": city.title(),\n",
      "                          \"Country\": city_country,\n",
      "                          \"Lat\": city_lat,\n",
      "                          \"Lng\": city_lng,\n",
      "                          \"Max Temp\": city_max_temp,\n",
      "                          \"Humidity\": city_humidity,\n",
      "                          \"Cloudiness\": city_clouds,\n",
      "                          \"Wind Speed\": city_wind,\n",
      "                          \"Current Description\": city_weather_description})\n",
      "        \n",
      "# If an error is experienced, skip the city.\n",
      "    except:\n",
      "        print(\"City not found. Skipping...\")\n",
      "        pass\n",
      "\n",
      "# Indicate that Data Loading is complete.\n",
      "print(\"-----------------------------\")\n",
      "print(\"Data Retrieval Complete      \")\n",
      "print(\"-----------------------------\")\n",
      "113/3:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/4:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/5:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "113/6:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/7:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/8:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "113/9:\n",
      "# 4a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 4b. Display the figure\n",
      "fig\n",
      "113/10:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[]\n",
      "vacation_end = vacation_df.loc[]\n",
      "vacation_stop1 = vacation_df.loc[]\n",
      "vacation_stop2 = vacation_df.loc[] \n",
      "vacation_stop3 = vacation_df.loc[]\n",
      "114/12:\n",
      "# Print the city count to confirm sufficient count.\n",
      "len(city_data)\n",
      "114/13: # Add the weather data to a new DataFrame.\n",
      "114/14:\n",
      "# Convert the array of dictionaries to a Pandas DataFrame.\n",
      "city_data_df = pd.DataFrame(city_data)\n",
      "city_data_df.head(10)\n",
      "114/15:\n",
      "# Format Lat and Lng columns' decimal separators.\n",
      "city_data_df[\"Lat\"]=city_data_df[\"Lat\"].map(\"{:.2f}\".format)\n",
      "city_data_df[\"Lng\"] =city_data_df[\"Lng\"].map(\"{:.2f}\".format)\n",
      "city_data_df=city_data_df\n",
      "city_data_df.head(10)\n",
      "114/16: # Export the DataFrame as a CSV file, and save it as WeatherPy_Database.csv in the Weather_Database folder.\n",
      "114/17:\n",
      "output_data_file=\"WeatherPy_Database.csv\"\n",
      "city_data_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "113/11:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/12:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/13:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/14:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "115/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "115/2:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "115/3:\n",
      "# 2. Prompt the user to enter minimum and maximum temperature criteria \n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "116/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "116/2:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "116/3:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "116/4:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"./WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "116/5:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"..//Weather_Database/WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "116/6:\n",
      "# 2. Prompt the user to enter minimum and maximum temperature criteria \n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "116/7:\n",
      "# 3. Filter the city_data_df DataFrame using the input statements to create a new DataFrame using the loc method.\n",
      "# Create df that contains all cities that meet temperature criteria.\n",
      "preferred_cities_df = city_data_df.loc[(city_data_df[\"Max Temp\"] <= max_temp) & \\\n",
      "                                       (city_data_df[\"Max Temp\"] >= min_temp)]\n",
      "preferred_cities_df.head(10)\n",
      "116/8: len(preferred_cities_df)\n",
      "116/9:\n",
      "# 4a. Determine if there are any empty rows.\n",
      "# Look for null values.\n",
      "preferred_cities_df.isnull().sum()\n",
      "116/10:\n",
      "# 4b. Drop any empty rows and create a new DataFrame that doesn’t have empty rows.\n",
      "clean_travel_cities_df=preferred_cities_df.dropna()\n",
      "116/11: len(clean_travel_cities_df)\n",
      "116/12:\n",
      "# 5a. Create DataFrame called hotel_df to store hotel names along with city, country, max temp, and coordinates.\n",
      "hotel_df = clean_travel_cities_df[[\"City\", \"Country\", \"Max Temp\", \"Current Description\", \"Lat\", \"Lng\"]].copy()\n",
      "\n",
      "# 5b. Create a new column \"Hotel Name\"\n",
      "hotel_df[\"Hotel Name\"] = \" \"\n",
      "hotel_df.head(10)\n",
      "116/13:\n",
      "# 6a. Set parameters to search for hotels with 5000 meters.\n",
      "params = {\n",
      "    \"radius\": 5000,\n",
      "    \"type\": \"lodging\",\n",
      "    \"key\": g_key\n",
      "}\n",
      "\n",
      "# 6b. Iterate through the hotel DataFrame.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "    \n",
      "    # 6c. Get latitude and longitude from DataFrame\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # 6d. Set up the base URL for the Google Directions API to get JSON data.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "\n",
      "    # 6e. Make request and retrieve the JSON data from the search. \n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "   \n",
      "    # 6f. Get the first hotel from the results and store the name, if a hotel isn't found skip the city.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "116/14:\n",
      "# 7. Drop the rows where there is no Hotel Name.\n",
      "clean_hotel_df = hotel_df[hotel_df[\"Hotel Name\"]!=\" \"]\n",
      "clean_hotel_df.head()\n",
      "116/15:\n",
      "# 7. Drop the rows where there is no Hotel Name.\n",
      "clean_hotel_df = hotel_df[hotel_df[\"Hotel Name\"]!=\" \"]\n",
      "clean_hotel_df.head()\n",
      "116/16:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"./WheatherPy_vacation.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "116/17:\n",
      "# 9. Using the template add city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "116/18:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "113/15:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/16:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/17:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/18:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"../Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/19:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "113/20:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/21:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"./WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "117/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "117/2:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"..//Weather_Database/WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "113/22:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "113/23:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/1:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "118/2:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/3:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"../Vacation_Search/WeatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/4:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"http://localhost:8888/edit/World_Weather_Analysis/Vacation_Search/WheatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/5:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"/World_Weather_Analysis/Vacation_Search/WheatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/6:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"/Vacation_Search/WheatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/7:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"../Vacation_Search/WheatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/8:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "118/9:\n",
      "# 4a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 4b. Display the figure\n",
      "fig\n",
      "118/10:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Agadir\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Dakar\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Bonthe\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Axim\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Omboue\"]\n",
      "118/11:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "vacation_itinerary = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/12:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Agadir\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Dakar\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Bonthe\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Axim\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Omboue\"]\n",
      "118/13:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/14:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "vacation_itinerary = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/15:\n",
      "# 8. To create a marker layer map between the four cities.\n",
      "#  Combine the four city DataFrames into one DataFrame using the concat() function.\n",
      "itinerary_df = pd.concat([vacation_start, vacation_stop1, vacation_stop2, vacation_stop3, vacation_end],ignore_index=True)\n",
      "itinerary_df\n",
      "118/16:\n",
      "# 9 Using the template add city name, the country code, the weather description and maximum temperature for the city. \n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in itinerary_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = itinerary_df[[\"Lat\", \"Lng\"]]\n",
      "118/17:\n",
      "# 11a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "118/18:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "vacation_itinerary = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'WALKING'OR'BIKING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/19:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "vacation_itinerary = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'WALKING'or'BIKING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/20:\n",
      "# 8. To create a marker layer map between the four cities.\n",
      "#  Combine the four city DataFrames into one DataFrame using the concat() function.\n",
      "itinerary_df = pd.concat([vacation_start, vacation_stop1, vacation_stop2, vacation_stop3, vacation_end],ignore_index=True)\n",
      "itinerary_df\n",
      "118/21:\n",
      "# 9 Using the template add city name, the country code, the weather description and maximum temperature for the city. \n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in itinerary_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = itinerary_df[[\"Lat\", \"Lng\"]]\n",
      "118/22:\n",
      "# 9 Using the template add city name, the country code, the weather description and maximum temperature for the city. \n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in itinerary_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = itinerary_df[[\"Lat\", \"Lng\"]]\n",
      "118/23:\n",
      "# 11a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "118/24:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/25:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Dickinson\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Rockport\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Acapulco\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Camperico\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Iralaya\"]\n",
      "118/26:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/27:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/28:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Dickinson\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Iralaya\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Acapulco\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Camperico\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Rockport\"]\n",
      "118/29:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/30:\n",
      "# 4a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 4b. Display the figure\n",
      "fig\n",
      "118/31:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Dickinson\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Iralaya\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Acapulco\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Camperico\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Rockport\"]\n",
      "118/32:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/33:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[5], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/34:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[5], vacation_stop2[\"Lng\"].to_numpy()[5]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/35:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/36:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "118/37:\n",
      "# 4a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 4b. Display the figure\n",
      "fig\n",
      "118/38:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Mazagao\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Soure\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Alta Floresta\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Maraba\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Carutapera\"]\n",
      "118/39:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/40:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/41:\n",
      "# 8. To create a marker layer map between the four cities.\n",
      "#  Combine the four city DataFrames into one DataFrame using the concat() function.\n",
      "itinerary_df = pd.concat([vacation_start, vacation_stop1, vacation_stop2, vacation_stop3, vacation_end],ignore_index=True)\n",
      "itinerary_df\n",
      "118/42:\n",
      "# 9 Using the template add city name, the country code, the weather description and maximum temperature for the city. \n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in itinerary_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = itinerary_df[[\"Lat\", \"Lng\"]]\n",
      "118/43:\n",
      "# 11a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "114/18:\n",
      "# Deliverable 1. Retrieve Weather Data.\n",
      "\n",
      "# RECREATED STARTER CODE FROM AS UNABLE TO UPLOAD (https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-online/module_6/Weather_Database_starter_code.ipynb).\n",
      "114/19:\n",
      "# Import dependencies.\n",
      "from citipy import citipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "# Import libraries.\n",
      "import requests\n",
      "import time\n",
      "# Import datetime module from datetime library.\n",
      "from datetime import datetime\n",
      "# Import API key.\n",
      "from config import weather_api_key\n",
      "114/20: # Use the np.random.uniform function to generate a new set of 2,000 random latitudes and 2,000 longitudes.\n",
      "114/21:\n",
      "# Create a set of random latitude and longitude combinations.\n",
      "lats = np.random.uniform(low=-90.000, high=90.000, size=2000)\n",
      "lngs = np.random.uniform(low=-180.000, high=180.000, size=2000)\n",
      "lat_lngs = zip(lats, lngs)\n",
      "lat_lngs\n",
      "114/22:\n",
      "# Add the latitudes and longitudes to a list.\n",
      "coordinates = list(lat_lngs)\n",
      "117/3:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config import g_key\n",
      "\n",
      "# Configure gmaps API key\n",
      "gmaps.configure(api_key=g_key)\n",
      "117/4:\n",
      "# 1. Import the WeatherPy_database.csv file. \n",
      "city_data_df = pd.read_csv(\"..//Weather_Database/WeatherPy_Database.csv\")\n",
      "city_data_df.head()\n",
      "117/5:\n",
      "# 2. Prompt the user to enter minimum and maximum temperature criteria \n",
      "# Vacation Criteria\n",
      "# Input statements\n",
      "# Ask the customer to add a minimum and maximum temperature value.\n",
      "min_temp = float(input(\"What is the minimum temperature you would like for your trip? \"))\n",
      "max_temp = float(input(\"What is the maximum temperature you would like for your trip? \"))\n",
      "117/6:\n",
      "# 3. Filter the city_data_df DataFrame using the input statements to create a new DataFrame using the loc method.\n",
      "# Create df that contains all cities that meet temperature criteria.\n",
      "preferred_cities_df = city_data_df.loc[(city_data_df[\"Max Temp\"] <= max_temp) & \\\n",
      "                                       (city_data_df[\"Max Temp\"] >= min_temp)]\n",
      "preferred_cities_df.head(10)\n",
      "117/7: len(preferred_cities_df)\n",
      "117/8:\n",
      "# 4a. Determine if there are any empty rows.\n",
      "# Look for null values.\n",
      "preferred_cities_df.isnull().sum()\n",
      "117/9:\n",
      "# 4b. Drop any empty rows and create a new DataFrame that doesn’t have empty rows.\n",
      "clean_travel_cities_df=preferred_cities_df.dropna()\n",
      "117/10: len(clean_travel_cities_df)\n",
      "117/11:\n",
      "# 5a. Create DataFrame called hotel_df to store hotel names along with city, country, max temp, and coordinates.\n",
      "hotel_df = clean_travel_cities_df[[\"City\", \"Country\", \"Max Temp\", \"Current Description\", \"Lat\", \"Lng\"]].copy()\n",
      "\n",
      "# 5b. Create a new column \"Hotel Name\"\n",
      "hotel_df[\"Hotel Name\"] = \" \"\n",
      "hotel_df.head(10)\n",
      "117/12:\n",
      "# 6a. Set parameters to search for hotels with 5000 meters.\n",
      "params = {\n",
      "    \"radius\": 5000,\n",
      "    \"type\": \"lodging\",\n",
      "    \"key\": g_key\n",
      "}\n",
      "\n",
      "# 6b. Iterate through the hotel DataFrame.\n",
      "for index, row in hotel_df.iterrows():\n",
      "    # Get the latitude and longitude.\n",
      "    lat = row[\"Lat\"]\n",
      "    lng = row[\"Lng\"]\n",
      "    \n",
      "    # 6c. Get latitude and longitude from DataFrame\n",
      "    params[\"location\"] = f\"{lat},{lng}\"\n",
      "\n",
      "    # 6d. Set up the base URL for the Google Directions API to get JSON data.\n",
      "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
      "\n",
      "    # 6e. Make request and retrieve the JSON data from the search. \n",
      "    hotels = requests.get(base_url, params=params).json()\n",
      "   \n",
      "    # 6f. Get the first hotel from the results and store the name, if a hotel isn't found skip the city.\n",
      "    try:\n",
      "        hotel_df.loc[index, \"Hotel Name\"] = hotels[\"results\"][0][\"name\"]\n",
      "    except (IndexError):\n",
      "        print(\"Hotel not found... skipping.\")\n",
      "117/13:\n",
      "# 7. Drop the rows where there is no Hotel Name.\n",
      "clean_hotel_df = hotel_df[hotel_df[\"Hotel Name\"]!=\" \"]\n",
      "clean_hotel_df.head()\n",
      "117/14:\n",
      "# 8a. Create the output File (CSV)\n",
      "output_data_file=\"./WheatherPy_vacation.csv\"\n",
      "# 8b. Export the City_Data into a csv\n",
      "clean_hotel_df.to_csv(output_data_file, index_label=\"City_ID\")\n",
      "117/15:\n",
      "# 9. Using the template add city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in clean_hotel_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = clean_hotel_df[[\"Lat\", \"Lng\"]]\n",
      "117/16:\n",
      "# 11a. Add a marker layer for each city to the map. \n",
      "# Assign variable for pop-up marker to be placed on each city.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "\n",
      "# Maximum Temperature Heatmap from a hotel_df with pop-up markers.\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "118/44:\n",
      "# Dependencies and Setup\n",
      "import pandas as pd\n",
      "import requests\n",
      "import gmaps\n",
      "\n",
      "# Import API key\n",
      "from config1 import g_key\n",
      "\n",
      "# Configure gmaps\n",
      "gmaps.configure(api_key=g_key)\n",
      "118/45:\n",
      "# 1. Read the WeatherPy_vacation.csv into a DataFrame.\n",
      "vacation_df = pd.read_csv(\"../Vacation_Search/WheatherPy_vacation.csv\")\n",
      "vacation_df.head()\n",
      "118/46:\n",
      "# 2. Using the template add the city name, the country code, the weather description and maximum temperature for the city.\n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 3a. Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in vacation_df.iterrows()]\n",
      "\n",
      "# 3b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = vacation_df[[\"Lat\", \"Lng\"]]\n",
      "118/47:\n",
      "# 4a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 4b. Display the figure\n",
      "fig\n",
      "118/48:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Lompoc\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Isla Vista\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Salinas\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Half Moon Bay\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Saint George\"]\n",
      "118/49:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/50:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/51:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'TRANSIT')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/52:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING)\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/53:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(vacation_itinerary)\n",
      "fig\n",
      "118/54:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(direction_layer)\n",
      "fig\n",
      "118/55:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(direction_layer_map)\n",
      "fig\n",
      "118/56:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING')\n",
      "\n",
      "fig.add_layer(direction_layer_map)\n",
      "fig\n",
      "118/57:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Lompoc\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Lompoc\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Salinas\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Half Moon Bay\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Isla Vista\"]\n",
      "118/58:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/59:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(direction_layer_map)\n",
      "fig\n",
      "118/60:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"Lompoc\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"Lompoc\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Salinas\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Half Moon Bay\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Saint George\"]\n",
      "118/61:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/62:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(direction_layer_map)\n",
      "fig\n",
      "118/63:\n",
      "# From the map above pick 4 cities and create a vacation itinerary route to travel between the four cities. \n",
      "# 5. Create DataFrames for each city by filtering the 'vacation_df' using the loc method. \n",
      "# Hint: The starting and ending city should be the same city.\n",
      "\n",
      "vacation_start = vacation_df.loc[vacation_df[\"City\"]==\"La Palma\"]\n",
      "vacation_end = vacation_df.loc[vacation_df[\"City\"]==\"La Palma\"]\n",
      "vacation_stop1 = vacation_df.loc[vacation_df[\"City\"]==\"Sonoita\"]\n",
      "vacation_stop2 = vacation_df.loc[vacation_df[\"City\"]==\"Meadow Lake\"] \n",
      "vacation_stop3 = vacation_df.loc[vacation_df[\"City\"]==\"Saint George\"]\n",
      "118/64:\n",
      "# 6. Get the latitude-longitude pairs as tuples from each city DataFrame using the to_numpy function and list indexing.\n",
      "start = vacation_start[\"Lat\"].to_numpy()[0], vacation_start[\"Lng\"].to_numpy()[0]\n",
      "end = vacation_end[\"Lat\"].to_numpy()[0], vacation_end[\"Lng\"].to_numpy()[0]\n",
      "stop1 = vacation_stop1[\"Lat\"].to_numpy()[0], vacation_stop1[\"Lng\"].to_numpy()[0]\n",
      "stop2 = vacation_stop2[\"Lat\"].to_numpy()[0], vacation_stop2[\"Lng\"].to_numpy()[0]\n",
      "stop3 = vacation_stop3[\"Lat\"].to_numpy()[0], vacation_stop3[\"Lng\"].to_numpy()[0]\n",
      "118/65:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(direction_layer_map)\n",
      "fig\n",
      "118/66:\n",
      "# 8. To create a marker layer map between the four cities.\n",
      "#  Combine the four city DataFrames into one DataFrame using the concat() function.\n",
      "itinerary_df = pd.concat([vacation_start, vacation_stop1, vacation_stop2, vacation_stop3, vacation_end],ignore_index=True)\n",
      "itinerary_df\n",
      "118/67:\n",
      "# 8. To create a marker layer map between the four cities.\n",
      "#  Combine the four city DataFrames into one DataFrame using the concat() function.\n",
      "itinerary_df = pd.concat([vacation_start, vacation_stop1, vacation_stop2, vacation_stop3, vacation_end],ignore_index=True)\n",
      "itinerary_df\n",
      "118/68:\n",
      "# 9 Using the template add city name, the country code, the weather description and maximum temperature for the city. \n",
      "info_box_template = \"\"\"\n",
      "<dl>\n",
      "<dt>Hotel Name</dt><dd>{Hotel Name}</dd>\n",
      "<dt>City</dt><dd>{City}</dd>\n",
      "<dt>Country</dt><dd>{Country}</dd>\n",
      "<dt>Current Weather</dt><dd>{Current Description} and {Max Temp} °F</dd>\n",
      "</dl>\n",
      "\"\"\"\n",
      "\n",
      "# 10a Get the data from each row and add it to the formatting template and store the data in a list.\n",
      "hotel_info = [info_box_template.format(**row) for index, row in itinerary_df.iterrows()]\n",
      "\n",
      "# 10b. Get the latitude and longitude from each row and store in a new DataFrame.\n",
      "locations = itinerary_df[[\"Lat\", \"Lng\"]]\n",
      "118/69:\n",
      "# 11a. Add a marker layer for each city to the map.\n",
      "marker_layer = gmaps.marker_layer(locations, info_box_content=hotel_info)\n",
      "fig = gmaps.figure(center=(30.0, 31.0), zoom_level=2.0)\n",
      "fig.add_layer(marker_layer)\n",
      "# 11b. Display the figure\n",
      "fig\n",
      "118/70:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(direction_layer_map)\n",
      "fig\n",
      "118/71:\n",
      "# 7. Create a direction layer map using the start and end latitude-longitude pairs,\n",
      "# and stop1, stop2, and stop3 as the waypoints. The travel_mode should be \"DRIVING\", \"BICYCLING\", or \"WALKING\".\n",
      "\n",
      "fig = gmaps.figure()\n",
      "direction_layer_map = gmaps.directions_layer(\n",
      "        start, end, waypoints=[stop1, stop2, stop3],\n",
      "        travel_mode='DRIVING'or'BICYCLING'or'WALKING')\n",
      "\n",
      "fig.add_layer(direction_layer_map)\n",
      "fig\n",
      "120/1:\n",
      "# Import dependencies\n",
      "import json\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "120/2:\n",
      "# Retrieve JSON file\n",
      "file_dir = '\"C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class\\ETL_Classwork\\wikipedia-movies.json\"'\n",
      "120/3:\n",
      "# Retrieve JSON file\n",
      "file_dir = '\"C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class\\ETL_Classwork\\movies.json\"'\n",
      "120/4:\n",
      "# Retrieve JSON file\n",
      "file_dir = \"C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class\\ETL_Classwork\\movies\"\n",
      "120/5:\n",
      "# Retrieve JSON file\n",
      "file_dir = \"C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class\\ETL_Classwork\\movies\"\n",
      "120/6:\n",
      "# Retrieve JSON file\n",
      "file_dir = \"Users\\joshua toussaint&FAM\\Desktop\\Data Class\\ETL_Classwork\\movies\"\n",
      "120/7:\n",
      "# Open JSON file, save data as file\n",
      "with open(f'{file_dir}/wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "120/8:\n",
      "# Open JSON file, save data as file\n",
      "with open('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "120/9:\n",
      "# Open JSON file, save data as file\n",
      "with open('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "120/10:\n",
      "# Retrieve JSON file\n",
      "f'{file_dir}\"Users\\joshua toussaint&FAM\\Desktop\\Data Class\\ETL_Classwork\\movies\"\n",
      "120/11:\n",
      "# Open JSON file, save data as file\n",
      "with open('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "120/12:\n",
      "# Import dependencies\n",
      "import json\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "120/13:\n",
      "file_dir = os.path.join(\"ETL_classwork\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "120/14:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "120/15:\n",
      "# Records length\n",
      "len(wiki_movies_raw)\n",
      "120/16:\n",
      "# Reasonability check, 7311 movies over 30 yrs.\n",
      "# Rount 7300/30=240/52=4\n",
      "# 4 movies per week is reasonable considering indie films\n",
      "120/17:\n",
      "# Inspect data in slices\n",
      "# First 5 records\n",
      "wiki_movies_raw[:5]\n",
      "120/18:\n",
      "# Inspect data in slices\n",
      "# Last 5 records\n",
      "wiki_movies_raw[-5:]\n",
      "120/19:\n",
      "# Inspect data in slices\n",
      "# Some records in the middle\n",
      "wiki_movies_raw[3600:3605]\n",
      "121/1: import pandas as pd\n",
      "121/2:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "121/3:\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "121/4:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"Resources\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "\n",
      "# Extract ratings dataset\n",
      "ratings_csv = os.path.join(\"Resources\", \"ratings.csv\")\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "121/5:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "121/6:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"Resources\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "\n",
      "# Extract ratings dataset\n",
      "ratings_csv = os.path.join(\"Resources\", \"ratings.csv\")\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "121/7:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "\n",
      "# Extract ratings dataset\n",
      "ratings_csv = os.path.join(\"ETL_classwork\", \"ratings.csv\")\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "121/8:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "\n",
      "# Extract ratings dataset\n",
      "ratings_csv = os.path.join(\"ETL_classwork\", \"ratings.csv\")\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "121/9:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "121/10:\n",
      "# Extract ratings dataset\n",
      "ratings_csv = os.path.join(\"ETL_classwork\", \"ratings.csv\")\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "121/11:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "121/12:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "121/13:\n",
      "# Extract ratings dataset\n",
      "ratings_csv = os.path.join(\"ETL_classwork\", \"ratings.csv\")\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "120/20:\n",
      "# Retrieve JSON file\n",
      "f'{file_dir}\"Users\\joshua toussaint&FAM\\Desktop\\Data Class\\ETL_Classwork\\movies\"\n",
      "120/21:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "120/22:\n",
      "# Import dependencies\n",
      "import json\n",
      "import os\n",
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "120/23:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"ETL_classwork\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "120/24:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "120/25:\n",
      "# Records length\n",
      "len(wiki_movies_raw)\n",
      "120/26:\n",
      "# Reasonability check, 7311 movies over 30 yrs.\n",
      "# Rount 7300/30=240/52=4\n",
      "# 4 movies per week is reasonable considering indie films\n",
      "120/27:\n",
      "# Inspect data in slices\n",
      "# First 5 records\n",
      "wiki_movies_raw[:5]\n",
      "120/28:\n",
      "# Inspect data in slices\n",
      "# Last 5 records\n",
      "wiki_movies_raw[-5:]\n",
      "120/29:\n",
      "# Inspect data in slices\n",
      "# Some records in the middle\n",
      "wiki_movies_raw[3600:3605]\n",
      "120/30:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "121/14:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "kaggle_metadata = pd.read_csv('movies.csv', low_memory=False)\n",
      "121/15:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "121/16: kaggle_metadata = pd.read_csv('movies.csv', low_memory=False)\n",
      "121/17:\n",
      "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "121/18:\n",
      "kaggle_metadata = pd.read_csv(f'{ETL_classwork}movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "121/19:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "121/20:\n",
      "kaggle_metadata = pd.read_csv(f'{\"ETL_classwork\"}movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "121/21:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "121/22:\n",
      "kaggle_metadata = pd.read_csv(f'\"ETL_classwork\", movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "121/23:\n",
      "# Extract Movielens datasets\n",
      "\n",
      "# Movies Metadata\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "121/24: kaggle_metadata = pd.read_csv('movies.csv', low_memory=False)\n",
      "121/25:\n",
      "kaggle_metadata = pd.read_csv(f'\"ETL_classwork\", movies_metadata.csv', low_memory=False)\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "121/26:\n",
      "kaggle_metadata = pd.read_csv(f'\"ETL_classwork\", movies_metadata.csv', low_memory=False)\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "121/27:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"ETL_classwork\", \"ratings.csv\")\n",
      "121/28:\n",
      "# Assign variables for files to load via indirect path.\n",
      "city_data_to_load=os.path.join(\"Resources\", \"city_data.csv\")\n",
      "ride_data_to_load=os.path.join(\"Resources\", \"ride_data.csv\")\n",
      "121/29:\n",
      "# # Read data and store it in a Pandas DataFrame.\n",
      "kaggle_metadata_df = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings_df = pd.read_csv(ratings_csv)\n",
      "121/30: ratings_df.sample(5)\n",
      "121/31: kaggle_metadata_df.sample(5)\n",
      "121/32:\n",
      "# # Read data and store it in Pandas\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "121/33: kaggle_metadata.sample(5)\n",
      "121/34: ratings.sample(5)\n",
      "120/31: wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
      "120/32:\n",
      "# View _df\n",
      "wiki_movies_df.head()\n",
      "120/33:\n",
      "# View list of columns\n",
      "wiki_movies_df.columns.tolist()\n",
      "120/34:\n",
      "# Use List Comprehensions to Filter Data\n",
      "# Expected outcome: resulting list will only have elements where filter expressions are True.\n",
      "# List comprenhension with filter expression\n",
      "# Intermediate variable: wiki_movies\n",
      "wiki_movies=[movie for movie in wiki_movies_raw\n",
      "             if ('Director' in movie or 'Directed by' in movie)\n",
      "             and 'imdb_link' in movie]\n",
      "len(wiki_movies)\n",
      "120/35:\n",
      "# Create _df from wiki_movies\n",
      "director_df = pd.DataFrame(wiki_movies)\n",
      "director_df.head()\n",
      "120/36:\n",
      "# Use List Comprehensions to Filter Data\n",
      "# Expected outcome: resulting list will only have elements where filter expressions are True.\n",
      "# List comprenhension with filter expression\n",
      "wiki_movies=[movie for movie in wiki_movies_raw\n",
      "             if ('Director' in movie or 'Directed by' in movie)\n",
      "             and 'imdb_link' in movie\n",
      "             and 'No. of episodes' not in movie]\n",
      "len(wiki_movies)\n",
      "# Intermediate variable: wiki_movies\n",
      "120/37:\n",
      "# Create _df from wiki_movies\n",
      "director_df = pd.DataFrame(wiki_movies)\n",
      "director_df.head()\n",
      "120/38:\n",
      "# Create _df from wiki_movies\n",
      "director_df = pd.DataFrame(wiki_movies)\n",
      "director_df.head()\n",
      "120/39:\n",
      "# Create _df from wiki_movies\n",
      "only_movies_df = pd.DataFrame(wiki_movies)\n",
      "only_movies_df.head()\n",
      "120/40:\n",
      "# \"scope\" of the variables:\n",
      "    # Variables created outside the function are called global variables.\n",
      "    # New variables created inside the function are local variables.\n",
      "    # The hierarchy of variables is called the scope.\n",
      "    # Local variables only work inside the function in which they are created.\n",
      "    # ^ifelse NameError\n",
      "120/41:\n",
      "# Part 1\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy\n",
      "    movie_copy = dict(movie)\n",
      "    return movie_copy\n",
      "120/42:\n",
      "# Part 1\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy\n",
      "    movie_copy = dict(movie)\n",
      "    \n",
      "    return movie_copy\n",
      "120/43:\n",
      "def clean_movie(movie):\n",
      "    movie = dict(movie) #create a non-destructive copy\n",
      "    return movie\n",
      "120/44: wiki_movies_df[wiki_movies_df['Arabic'].notnull()]\n",
      "120/45:\n",
      "# Retrieve value from a column (i.e. languages)\n",
      "wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']\n",
      "120/46:\n",
      "# Display columns in alphabetical order\n",
      "sorted(wiki_movies_df.columns.tolist())\n",
      "120/47:\n",
      "# Make a list of cleaned movies with list comprehension:\n",
      "clean_movies = [clean_movie(movie_copy) for movie in wiki_movies]\n",
      "120/48:\n",
      "# Part 1\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie_copy = dict(movie)\n",
      "    # add in code to handle alternative titles\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:Keys_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:Keys_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie_copy\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie_copy[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie_copy.pop(key)\n",
      "            # 3rd After looping through every key\n",
      "            if len(alt_titles) > 0:\n",
      "                # 3rd Add the alternative titles dict to the movie object\n",
      "                movie_copy['alt_titles'] = alt_titles\n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    return movie_copy\n",
      "120/49:\n",
      "# Make a list of cleaned movies with list comprehension:\n",
      "clean_movies = [clean_movie(movie_copy) for movie in wiki_movies]\n",
      "120/50:\n",
      "# Retrieve amovie by searching through a column (i.e. languages)\n",
      "# Inclue ['url'] in output\n",
      "wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']\n",
      "120/51:\n",
      "# Part 1\n",
      "\n",
      "# create a non-destructive copy of original movie object\n",
      "movie_copy = dict(movie)\n",
      "\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie_copy = dict(movie)\n",
      "    # add in code to handle alternative titles\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:Keys_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:Keys_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie_copy\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie_copy[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie_copy.pop(key)\n",
      "            # 3rd After looping through every key\n",
      "            if len(alt_titles) > 0:\n",
      "                # 3rd Add the alternative titles dict to the movie object\n",
      "                movie_copy['alt_titles'] = alt_titles\n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    return movie_copy\n",
      "120/52:\n",
      "# Make a list of cleaned movies with list comprehension:\n",
      "clean_movies = [clean_movie(movie_copy) for movie in wiki_movies]\n",
      "120/53:\n",
      "# Part 1\n",
      "\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # add in code to handle alternative titles\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:Keys_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:Keys_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "            # 3rd After looping through every key\n",
      "            if len(alt_titles) > 0:\n",
      "                # 3rd Add the alternative titles dict to the movie object\n",
      "                movie['alt_titles'] = alt_titles\n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    return movie\n",
      "120/54:\n",
      "# Make a list of cleaned movies with list comprehension:\n",
      "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
      "120/55:\n",
      "# Set wiki_movies_df to be the DataFrame created from clean_movies, print out a list of the columns.\n",
      "wiki_movies_df = pd.DataFrame(clean_movies)\n",
      "sorted(wiki_movies_df.columns.tolist())\n",
      "120/56:\n",
      "# Retrieve amovie by searching through a column (i.e. languages)\n",
      "# Inclue ['url'] in output\n",
      "#wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']\n",
      "120/57:\n",
      "# Display columns in alphabetical order\n",
      "#sorted(wiki_movies_df.columns.tolist())\n",
      "120/58: # Part 2\n",
      "122/1:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name('Directed by', 'Director'):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "122/2:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name('Directed by' , 'Director'):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "122/3:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name('old_name' , 'new_name'):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "122/4:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name('old_name' , 'new_name'):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "122/5:\n",
      "# Use List Comprehensions to Filter Data\n",
      "# Expected outcome: resulting list will only have elements where filter expressions are True.\n",
      "# List comprenhension with filter expression\n",
      "wiki_movies=[movie for movie in wiki_movies_raw\n",
      "             if ('Director' in movie or 'Directed by' in movie)\n",
      "             and 'imdb_link' in movie\n",
      "             # add additional elements as needed\n",
      "             and 'No. of episodes' not in movie]\n",
      "             # ^Exludes TV shows\n",
      "len(wiki_movies)\n",
      "# Intermediate variable used: wiki_movies\n",
      "122/6:\n",
      "# Import dependencies\n",
      "import json\n",
      "import os\n",
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "122/7:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"ETL_classwork\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/8:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/9: f'{file_dir}filename'\n",
      "122/10:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/11:\n",
      "# Import dependencies\n",
      "import json\n",
      "import os\n",
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "122/12:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"ETL_classwork\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/13: f'{file_dir}filename'\n",
      "122/14:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/15:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/16: f'{file_dir}filename'\n",
      "122/17:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/18:\n",
      "# Import dependencies\n",
      "import json\n",
      "import os\n",
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "122/19:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/20: f'{file_dir}filename'\n",
      "122/21:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/22:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"ETL_Classwork\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/23: f'{file_dir}filename'\n",
      "122/24:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/25:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"ETL_Classwork\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/26: # f'{file_dir}filename'\n",
      "122/27:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/28:\n",
      "# Records length\n",
      "len(wiki_movies_raw)\n",
      "122/29:\n",
      "# f'{file_dir}filename'\n",
      "\n",
      "with open ('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "122/30:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/31:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/32:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "122/33:\n",
      "# f'{file_dir}filename'\n",
      "\n",
      "with open ('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "122/34:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/35:\n",
      "# Records length\n",
      "len(wiki_movies_raw)\n",
      "122/36:\n",
      "f'{file_dir}filename'\n",
      "\n",
      "#with open ('wikipedia-movies.json', mode='r') as file:\n",
      " #   wiki_movies_raw = json.load(file)\n",
      "122/37:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/38:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open ('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "122/39:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open(file_dir) as jsonfile:\n",
      "    wiki_movies_raw = json.load(jsonfile)\n",
      "122/40:\n",
      "# Reasonability check, 7311 movies over 30 yrs.\n",
      "# Rount 7300/30=240/52=4\n",
      "# 4 movies per week is reasonable considering indie films\n",
      "122/41:\n",
      "# Inspect data in slices\n",
      "# First 5 records\n",
      "wiki_movies_raw[:5]\n",
      "122/42:\n",
      "# Inspect data in slices\n",
      "# Last 5 records\n",
      "wiki_movies_raw[-5:]\n",
      "122/43:\n",
      "# Inspect data in slices\n",
      "# Some records in the middle\n",
      "wiki_movies_raw[3600:3605]\n",
      "122/44:\n",
      "# Turn wiki_movies_raw into a DataFrame\n",
      "wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
      "122/45:\n",
      "# View _df\n",
      "wiki_movies_df.head()\n",
      "122/46:\n",
      "# View list of columns\n",
      "wiki_movies_df.columns.tolist()\n",
      "122/47:\n",
      "# Use List Comprehensions to Filter Data\n",
      "# Expected outcome: resulting list will only have elements where filter expressions are True.\n",
      "# List comprenhension with filter expression\n",
      "wiki_movies=[movie for movie in wiki_movies_raw\n",
      "             if ('Director' in movie or 'Directed by' in movie)\n",
      "             and 'imdb_link' in movie\n",
      "             # add additional elements as needed\n",
      "             and 'No. of episodes' not in movie]\n",
      "             # ^Exludes TV shows\n",
      "len(wiki_movies)\n",
      "# Intermediate variable used: wiki_movies\n",
      "122/48: # Nondestructive edits: keep raw data intact, create new variable for new data.\n",
      "122/49:\n",
      "# Create _df from wiki_movies\n",
      "only_movies_df = pd.DataFrame(wiki_movies)\n",
      "only_movies_df.head()\n",
      "122/50: # Cleaning function\n",
      "122/51:\n",
      "# \"scope\" of variables:\n",
      "    # Variables created outside the function are called global variables.\n",
      "    # New variables created inside the function are local variables.\n",
      "    # The hierarchy of variables is called the scope.\n",
      "    # Local variables only work inside the function in which they are created.\n",
      "    # ^ifelse NameError\n",
      "# Do not mutate objects without creating new variables for new objects\n",
      "122/52:\n",
      "# Lambda Functions: most stripped-down \n",
      "    # also known as \"anonymous functions\"\n",
      "    # can be used as one-time-use functions\n",
      "    # Syntax: lambda arguments: expression\n",
      "    # Ex: lambda x: x * x\n",
      "    # square = lambda x: x * x\n",
      "    # square(5)   \n",
      "    # output: 25\n",
      "122/53:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name('old_name' , 'new_name'):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "122/54:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name('old_name', 'new_name'):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "122/55:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name(old_name, new_name):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "122/56:\n",
      "# pop() returns the value from the removed key-value pair\n",
      "# Therefore, check if the key exists in a given object first\n",
      "# i.e.        #C heck if the current keys exist in the movie\n",
      "#             if key in movie:\n",
      "#                 alt_titles[key] = movie[key]\n",
      "#                 # Remove the key-value pair/bond, Syntax: .pop()\n",
      "#                 movie.pop(key)\n",
      "122/57:\n",
      "# Make a list of cleaned movies with list comprehension:\n",
      "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
      "122/58:\n",
      "# Set wiki_movies_df to be the DataFrame created from clean_movies, print out a list of the columns.\n",
      "wiki_movies_df = pd.DataFrame(clean_movies)\n",
      "sorted(wiki_movies_df.columns.tolist())\n",
      "122/59:\n",
      "# Remove Duplicate Rows with .str.extract() and regex\n",
      "\n",
      "# Regular expressions, also known as regex, are strings of characters that define a search pattern\n",
      "# ^A more formal way of defining these kinds of patterns so that our code can find them\n",
      "# Regex are easily recognizable because they follow well-defined patterns\n",
      "\n",
      "# In this case we're searching for the IMDb id, ex: tt1234567\n",
      "# Regex for the IMDb ID object is: start with \"tt\" and has seven digits\n",
      "# When searching for the object use syntax: \"(tt\\d{7})\"\n",
      "# \"()\": look for one group of text.\n",
      "# \"tt\": match two lowercase Ts.\n",
      "# \"\\d\":match a numerical digit.\n",
      "# \"{7}\":match the last thing (numerical digits) exactly seven times.\n",
      "\n",
      "\n",
      "# Remove Duplicate Rows\n",
      "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
      "122/60:\n",
      "# Extract the IMDb ID\n",
      "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
      "print(len(wiki_movies_df))\n",
      "122/61:\n",
      "# Drop duplicates of IMDb IDs by using drop_duplicates(), subset=, and inplace=\n",
      "# To specify that we only want the IMDb ID, use the subset argument, set inplace equal to True so that the operation is performed on the selected dataframe.\n",
      "wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
      "print(len(wiki_movies_df))\n",
      "122/62: wiki_movies_df.head()\n",
      "122/63:\n",
      "# Remove Mostly Null Columns with list comprehension \n",
      "# Make a list of columns that have less than 90% null values, use those to trim down our dataset.\n",
      "# Use the list comprehension to produce only the wanted columns\n",
      "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
      "# Make the results into a _df\n",
      "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
      "122/64:\n",
      "# Remove Mostly Null Columns with list comprehension \n",
      "# Make a list of columns that have less than 90% null values, use those to trim down our dataset.\n",
      "# Use the list comprehension to produce only the wanted columns\n",
      "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
      "# Update  _df\n",
      "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
      "122/65: wiki_movies_df.head()\n",
      "122/66:\n",
      "# Make a Plan to Convert and Parse the Data\n",
      "\n",
      "# 1st Identify which columns need to be converted.\n",
      "wiki_movies_df.dtypes\n",
      "122/67:\n",
      "# Make a data series that drops missing values\n",
      "box_office = wiki_movies_df['Box office'].dropna()\n",
      "122/68:\n",
      "# Make a function to be able to filter out non string values.\n",
      "# ^This needs to be done because regex only work on strings\n",
      "# SyntaX is_not_a_string() \n",
      "def is_not_a_string(x):\n",
      "    return type(x) != str\n",
      "# Show values that are not strings\n",
      "box_office[box_office.map(is_not_a_string)]\n",
      "122/69:\n",
      "# Use lambda to make a stripped-down, one-line function which won't be used ever again outside of map()\n",
      "box_office[box_office.map(lambda x: type(x) != str)]\n",
      "122/70:\n",
      "# ^The out put shows values which need not be excluded\n",
      "# Import re for regex\n",
      "import re\n",
      "# Use\n",
      "122/71:\n",
      "# ^The out put shows data points stored as lists\n",
      "# Import re for regex\n",
      "import re\n",
      "# Use ' ' as the joining character and apply the join() function only when data points are lists\n",
      "# Use join() method to concatenate list items into one string\n",
      "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "122/72:\n",
      "# ^The out put shows data points stored as lists\n",
      "# Import re for regex\n",
      "import re\n",
      "122/73:\n",
      "# Use ' ' as the joining character and apply the join() function only when data points are lists\n",
      "# Use join() method to concatenate list items into one string\n",
      "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "122/74:\n",
      "# Use ' ' as the joining character and apply the join() function only when data points are lists\n",
      "# Use join() method to concatenate list items into one string\n",
      "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "box_office\n",
      "124/1:\n",
      "# Import dependencies\n",
      "import json\n",
      "import os\n",
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "124/2:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "124/3:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open ('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "124/4:\n",
      "# Reasonability check, 7311 movies over 30 yrs.\n",
      "# Rount 7300/30=240/52=4\n",
      "# 4 movies per week is reasonable considering indie films\n",
      "124/5:\n",
      "# Inspect data in slices\n",
      "# First 5 records\n",
      "wiki_movies_raw[:5]\n",
      "124/6:\n",
      "# Inspect data in slices\n",
      "# Last 5 records\n",
      "wiki_movies_raw[-5:]\n",
      "124/7:\n",
      "# Inspect data in slices\n",
      "# Some records in the middle\n",
      "wiki_movies_raw[3600:3605]\n",
      "124/8:\n",
      "# Turn wiki_movies_raw into a DataFrame\n",
      "wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
      "124/9:\n",
      "# View _df\n",
      "wiki_movies_df.head()\n",
      "124/10:\n",
      "# View list of columns\n",
      "wiki_movies_df.columns.tolist()\n",
      "124/11:\n",
      "# Use List Comprehensions to Filter Data\n",
      "# Expected outcome: resulting list will only have elements where filter expressions are True.\n",
      "# List comprenhension with filter expression\n",
      "wiki_movies=[movie for movie in wiki_movies_raw\n",
      "             if ('Director' in movie or 'Directed by' in movie)\n",
      "             and 'imdb_link' in movie\n",
      "             # add additional elements as needed\n",
      "             and 'No. of episodes' not in movie]\n",
      "             # ^Exludes TV shows\n",
      "len(wiki_movies)\n",
      "# Intermediate variable used: wiki_movies\n",
      "124/12: # Nondestructive edits: keep raw data intact, create new variable for new data.\n",
      "124/13:\n",
      "# Create _df from wiki_movies\n",
      "only_movies_df = pd.DataFrame(wiki_movies)\n",
      "only_movies_df.head()\n",
      "124/14: # Cleaning function\n",
      "124/15:\n",
      "# \"scope\" of variables:\n",
      "    # Variables created outside the function are called global variables.\n",
      "    # New variables created inside the function are local variables.\n",
      "    # The hierarchy of variables is called the scope.\n",
      "    # Local variables only work inside the function in which they are created.\n",
      "    # ^ifelse NameError\n",
      "# Do not mutate objects without creating new variables for new objects\n",
      "124/16:\n",
      "# Lambda Functions: most stripped-down \n",
      "    # also known as \"anonymous functions\"\n",
      "    # can be used as one-time-use functions\n",
      "    # Syntax: lambda arguments: expression\n",
      "    # Ex: lambda x: x * x\n",
      "    # square = lambda x: x * x\n",
      "    # square(5)   \n",
      "    # output: 25\n",
      "124/17:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name(old_name, new_name):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "124/18:\n",
      "# pop() returns the value from the removed key-value pair\n",
      "# Therefore, check if the key exists in a given object first\n",
      "# i.e.        #C heck if the current keys exist in the movie\n",
      "#             if key in movie:\n",
      "#                 alt_titles[key] = movie[key]\n",
      "#                 # Remove the key-value pair/bond, Syntax: .pop()\n",
      "#                 movie.pop(key)\n",
      "124/19:\n",
      "# Make a list of cleaned movies with list comprehension:\n",
      "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
      "124/20:\n",
      "# Set wiki_movies_df to be the DataFrame created from clean_movies \n",
      "wiki_movies_df = pd.DataFrame(clean_movies)\n",
      "# print out list of the columns in alphabetical order\n",
      "sorted(wiki_movies_df.columns.tolist())\n",
      "124/21:\n",
      "# Retrieve a movie by searching through a column (i.e. languages)\n",
      "# Inclue ['url'] in output\n",
      "#wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']\n",
      "124/22:\n",
      "# Remove Duplicate Rows with .str.extract() and regex\n",
      "\n",
      "# Regular expressions, also known as regex, are strings of characters that define a search pattern\n",
      "# ^A more formal way of defining these kinds of patterns so that our code can find them\n",
      "# Regex are easily recognizable because they follow well-defined patterns\n",
      "\n",
      "# In this case we're searching for the IMDb id, ex: tt1234567\n",
      "# Regex for the IMDb ID object is: start with \"tt\" and has seven digits\n",
      "# When searching for the object use syntax: \"(tt\\d{7})\"\n",
      "# \"()\": look for one group of text.\n",
      "# \"tt\": match two lowercase Ts.\n",
      "# \"\\d\":match a numerical digit.\n",
      "# \"{7}\":match the last thing (numerical digits) exactly seven times.\n",
      "124/23:\n",
      "# Extract the IMDb ID\n",
      "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
      "print(len(wiki_movies_df))\n",
      "124/24:\n",
      "# Drop duplicates of IMDb IDs by using drop_duplicates(), subset=, and inplace=\n",
      "# To specify that we only want the IMDb ID, use the subset argument, set inplace equal to True so that the operation is performed on the selected dataframe.\n",
      "wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
      "print(len(wiki_movies_df))\n",
      "124/25: wiki_movies_df.head()\n",
      "124/26:\n",
      "# Remove Mostly Null Columns with list comprehension \n",
      "# Make a list of columns that have less than 90% null values, use those to trim down our dataset.\n",
      "# Use the list comprehension to produce only the wanted columns\n",
      "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
      "# Update  _df\n",
      "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
      "124/27: wiki_movies_df.head()\n",
      "124/28:\n",
      "# Make a Plan to Convert and Parse the Data\n",
      "\n",
      "# 1st Identify which columns need to be converted.\n",
      "wiki_movies_df.dtypes\n",
      "124/29:\n",
      "# Make a data series that drops missing values\n",
      "box_office = wiki_movies_df['Box office'].dropna()\n",
      "124/30:\n",
      "# Make a function to be able to filter out non string values.\n",
      "# ^This needs to be done because regex only work on strings\n",
      "# SyntaX is_not_a_string() \n",
      "def is_not_a_string(x):\n",
      "    return type(x) != str\n",
      "# Show values that are not strings\n",
      "box_office[box_office.map(is_not_a_string)]\n",
      "124/31:\n",
      "# Use lambda to make a stripped-down, one-line function which won't be used ever again outside of map()\n",
      "box_office[box_office.map(lambda x: type(x) != str)]\n",
      "124/32:\n",
      "# ^The out put shows data points stored as lists\n",
      "# Import re for regex\n",
      "import re\n",
      "124/33:\n",
      "# Use ' ' as the joining character and apply the join() function only when data points are lists\n",
      "# Use join() method to concatenate list items into one string\n",
      "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "box_office\n",
      "124/34: # Parse the Box Office Data\n",
      "124/35:\n",
      "# Parse the Box Office Data\n",
      "\n",
      "# Build regex for each form the data is written in\n",
      "124/36:\n",
      "# Regex for form $123.4 million/billion\n",
      "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
      "124/37:\n",
      "# Count entires for form $123.4 million/billion\n",
      "box_office.str.contains(form_one, flags=re.IGNORECASE).sum()\n",
      "124/38:\n",
      "# Regex for form $123,456,789 \n",
      "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
      "124/39:\n",
      "# Count entires for form $123,456,789\n",
      "box_office.str.contains(form_two, flags=re.IGNORECASE).sum()\n",
      "124/40:\n",
      "# Regex for form $123.4 million/billion\n",
      "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
      "# ^Assign variable\n",
      "124/41:\n",
      "# Count entires for form $123.4 million/billion\n",
      "box_office.str.contains(form_one, flags=re.IGNORECASE).sum()\n",
      "124/42:\n",
      "# Regex for form $123,456,789 \n",
      "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
      "# ^Assign variable\n",
      "124/43:\n",
      "# Count entires for form $123,456,789\n",
      "box_office.str.contains(form_two, flags=re.IGNORECASE).sum()\n",
      "124/44:\n",
      "# Create Boolean Series for each form to find values not defined by either one.\n",
      "matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
      "matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
      "124/45:\n",
      "# Find values not defined by forms 1 and 2\n",
      "box_office[~matches_form_one & ~matches_form_two]\n",
      "124/46:\n",
      "# Fix Pattern Matches\n",
      "\n",
      "# Correct ranges with spaces between $ and the number\n",
      "# Add \\s* after the dollar signs\n",
      "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
      "124/47:\n",
      "# Fix Pattern Matches\n",
      "\n",
      "# Correct values with spaces between $ and the number\n",
      "# Add \\s* after the dollar signs\n",
      "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
      "124/48:\n",
      "# Correct values that use a period as a thousands separator, not a comma\n",
      "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
      "124/49:\n",
      "# Fix Pattern Matches\n",
      "\n",
      "# Correct values with spaces between $ and the number\n",
      "# ^Add \\s* after the dollar sign\n",
      "# Correct mispelled \"millon\", make i optional i?\n",
      "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
      "124/50:\n",
      "# Correct values that use a period as a thousands separator, not a comma\n",
      "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
      "124/51:\n",
      "# Fix Pattern Matches\n",
      "\n",
      "# Correct values with spaces between $ and the number\n",
      "# ^Add \\s* after the dollar sign\n",
      "# Correct mispelled \"millon\", make i optional i?\n",
      "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
      "124/52:\n",
      "# Correct values that use a period as a thousands separator, not a comma\n",
      "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
      "124/53:\n",
      "# Correct values that are given as a range\n",
      "box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
      "124/54:\n",
      "# Extract and Convert the Box Office Values\n",
      "# Create/define function\n",
      "def parse_dollars(s):\n",
      "    # if s is not a string, return NaN\n",
      "    if type(s) != str:\n",
      "        return np.nan\n",
      "\n",
      "    # if input is of the form $###.# million\n",
      "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
      "\n",
      "        # remove dollar sign and \" million\"\n",
      "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
      "\n",
      "        # convert to float and multiply by a million\n",
      "        value = float(s) * 10**6\n",
      "\n",
      "        # return value\n",
      "        return value\n",
      "\n",
      "    # if input is of the form $###.# billion\n",
      "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
      "\n",
      "        # remove dollar sign and \" billion\"\n",
      "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
      "\n",
      "        # convert to float and multiply by a billion\n",
      "        value = float(s) * 10**9\n",
      "\n",
      "        # return value\n",
      "        return value\n",
      "\n",
      "    # if input is of the form $###,###,###\n",
      "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
      "\n",
      "        # remove dollar sign and commas\n",
      "        s = re.sub('\\$|,','', s)\n",
      "\n",
      "        # convert to float\n",
      "        value = float(s)\n",
      "\n",
      "        # return value\n",
      "        return value\n",
      "\n",
      "    # otherwise, return NaN\n",
      "    else:\n",
      "        return np.nan\n",
      "124/55:\n",
      "# Find/Extract the values from box_office and parse\n",
      "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
      "124/56:\n",
      "# Find/Extract the values from box_office and parse\n",
      "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
      "wiki_movies_df[‘box_office’]\n",
      "124/57:\n",
      "# Find/Extract the values from box_office and parse\n",
      "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
      "wiki_movies_df[box_office]\n",
      "124/58:\n",
      "# Find/Extract the values from box_office and parse\n",
      "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
      "wiki_movies_df['box_office']\n",
      "124/59:\n",
      "# Drop Box Office column since it's no longer needed\n",
      "wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
      "124/60:\n",
      "# Parse Budget Data\n",
      "\n",
      "# Create a budget variable with the following code:\n",
      "budget = wiki_movies_df['Budget'].dropna()\n",
      "124/61:\n",
      "# Convert lists to strings:\n",
      "budget = budget.map(lambda x: ' '.join(x) if type(x) == lis\n",
      "124/62:\n",
      "# Convert lists to strings:\n",
      "budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "124/63:\n",
      "# Remove values between a dollar sign and a hyphen (for budgets given in ranges)\n",
      "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
      "124/64:\n",
      "# Create Boolean Series for each form to find values not defined by either one\n",
      "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
      "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
      "# Find the values from budget\n",
      "budget[~matches_form_one & ~matches_form_two]\n",
      "124/65:\n",
      "# Remove citation references\n",
      "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
      "budget[~matches_form_one & ~matches_form_two]\n",
      "124/66:\n",
      "# Create Boolean Series for each form to find values not defined by either one\n",
      "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
      "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
      "# Find the values from budget\n",
      "budget[~matches_form_one & ~matches_form_two].count()\n",
      "124/67:\n",
      "# Create Boolean Series for each form to find values not defined by either one\n",
      "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
      "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
      "# Find the values from budget\n",
      "budget[~matches_form_one & ~matches_form_two]\n",
      "124/68:\n",
      "# Remove citation references\n",
      "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
      "budget[~matches_form_one & ~matches_form_two].count()\n",
      "124/69:\n",
      "# Find the values from budget\n",
      "wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
      "124/70:\n",
      "# Drop the original Budget column\n",
      "wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
      "124/71:\n",
      "# Parse Release Date\n",
      "\n",
      "\n",
      "# Assign variable for Release date column's non-null values in the DataFrame, convert lists to strings\n",
      "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "124/72:\n",
      "# Extract Dates\n",
      "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)\n",
      "124/73:\n",
      "# Parse Release Date\n",
      "\n",
      "\n",
      "# Assign variable for Release date column's non-null values in the DataFrame, convert lists to strings\n",
      "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "124/74:\n",
      "# Extract Dates\n",
      "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)\n",
      "124/75:\n",
      "# Forms to extract\n",
      "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]?\\d,\\s\\d{4}'\n",
      "date_form_two = r'\\d{4}.[01]\\d.[0123]\\d'\n",
      "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
      "date_form_four = r'\\d{4}'\n",
      "124/76:\n",
      "# Extract Dates\n",
      "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)\n",
      "124/77:\n",
      "# Parse dates\n",
      "wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
      "124/78:\n",
      "# Assign variable for Running time column's non-null values in the DataFrame, convert lists to strings\n",
      "running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "124/79:\n",
      "# Assign variable for Running time column's non-null values in the DataFrame, convert lists to strings\n",
      "running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "running_time\n",
      "124/80:\n",
      "# Look for  \"100 minutes\" forms\n",
      "running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False).sum()\n",
      "124/81:\n",
      "# Create Boolean Series to find values not defined by \"100 minutes\" form\n",
      "running_time[running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False) != True]\n",
      "124/82:\n",
      "# Find all values with other abbreviations of \"minutes\"\n",
      "running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False).sum()\n",
      "124/83:\n",
      "# Find remaining 17 values\n",
      "running_time[running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False) != True]\n",
      "124/84:\n",
      "# Extract only values with digits with both patterns\n",
      "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
      "124/85:\n",
      "# Extract only values with digits with both patterns\n",
      "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
      "running_time_extract\n",
      "124/86:\n",
      "# Convert strings to numeric values\n",
      "running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
      "running_time_extract\n",
      "124/87:\n",
      "# Convert hour capture groups and minute capture groups to minutes IF pure minutes capture group is zero, save the output to wiki_movies_df\n",
      "wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
      "124/88:\n",
      "# Drop Running time from dataset \n",
      "wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
      "124/89:\n",
      "# Clean Kaggle Data\n",
      "kaggle_metadata.dtypes\n",
      "124/90:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "124/91:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "124/92:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "124/93:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "124/94:\n",
      "# Clean Kaggle Data\n",
      "kaggle_metadata.dtypes\n",
      "124/95:\n",
      "# Load Kaggle and Ratings data\n",
      "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv')\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "124/96:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "print(file_dir)\n",
      "124/97:\n",
      "# Load Kaggle and Ratings data\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/98:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "print(file_dir)\n",
      "124/99:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "124/100:\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/101:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path \n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/102:\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/103:\n",
      "\n",
      "\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_metadata.csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/104:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path \n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/105:\n",
      "\n",
      "\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_metadata.csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/106:\n",
      "\n",
      "\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/107:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path \n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/108:\n",
      "\n",
      "\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/109:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path \n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/110:\n",
      "\n",
      "\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/111:\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/112:\n",
      "# load kaggle and ratings data\n",
      "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv')\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "124/113:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path \n",
      "movies_csv_to_load = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv_to_load = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/114:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path \n",
      "movies_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/115:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
      "kaggle_metadata_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/116:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
      "kaggle_metadata_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/117: kaggle_metadata.dtypes\n",
      "124/118:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
      "kaggle_metadata= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/119: kaggle_metadata.dtypes\n",
      "124/120:\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "125/1:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"ETL_classwork\", \"ratings.csv\")\n",
      "125/2:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "125/3:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"ETL_classwork\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"ETL_classwork\", \"ratings.csv\")\n",
      "125/4:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/121:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "124/122:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
      "movies_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "rating_csvs= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "124/123:\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "124/124:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "   1:\n",
      "# Import dependencies\n",
      "import json\n",
      "import os\n",
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "   2:\n",
      "# Retreive JSON file\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"wikipedia-movies.json\")\n",
      "print(file_dir)\n",
      "   3:\n",
      "# Open JSON file, save data as file: wiki_movies_raw\n",
      "with open ('wikipedia-movies.json', mode='r') as file:\n",
      "    wiki_movies_raw = json.load(file)\n",
      "   4:\n",
      "# Reasonability check, 7311 movies over 30 yrs.\n",
      "# Rount 7300/30=240/52=4\n",
      "# 4 movies per week is reasonable considering indie films\n",
      "   5:\n",
      "# Inspect data in slices\n",
      "# First 5 records\n",
      "wiki_movies_raw[:5]\n",
      "   6:\n",
      "# Inspect data in slices\n",
      "# Last 5 records\n",
      "wiki_movies_raw[-5:]\n",
      "   7:\n",
      "# Inspect data in slices\n",
      "# Some records in the middle\n",
      "wiki_movies_raw[3600:3605]\n",
      "   8:\n",
      "# Turn wiki_movies_raw into a DataFrame\n",
      "wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
      "   9:\n",
      "# View _df\n",
      "wiki_movies_df.head()\n",
      "  10:\n",
      "# View list of columns\n",
      "wiki_movies_df.columns.tolist()\n",
      "  11:\n",
      "# Use List Comprehensions to Filter Data\n",
      "# Expected outcome: resulting list will only have elements where filter expressions are True.\n",
      "# List comprenhension with filter expression\n",
      "wiki_movies=[movie for movie in wiki_movies_raw\n",
      "             if ('Director' in movie or 'Directed by' in movie)\n",
      "             and 'imdb_link' in movie\n",
      "             # add additional elements as needed\n",
      "             and 'No. of episodes' not in movie]\n",
      "             # ^Exludes TV shows\n",
      "len(wiki_movies)\n",
      "# Intermediate variable used: wiki_movies\n",
      "  12: # Nondestructive edits: keep raw data intact, create new variable for new data.\n",
      "  13:\n",
      "# Create _df from wiki_movies\n",
      "only_movies_df = pd.DataFrame(wiki_movies)\n",
      "only_movies_df.head()\n",
      "  14: # Cleaning function\n",
      "  15:\n",
      "# \"scope\" of variables:\n",
      "    # Variables created outside the function are called global variables.\n",
      "    # New variables created inside the function are local variables.\n",
      "    # The hierarchy of variables is called the scope.\n",
      "    # Local variables only work inside the function in which they are created.\n",
      "    # ^ifelse NameError\n",
      "# Do not mutate objects without creating new variables for new objects\n",
      "  16:\n",
      "# Lambda Functions: most stripped-down \n",
      "    # also known as \"anonymous functions\"\n",
      "    # can be used as one-time-use functions\n",
      "    # Syntax: lambda arguments: expression\n",
      "    # Ex: lambda x: x * x\n",
      "    # square = lambda x: x * x\n",
      "    # square(5)   \n",
      "    # output: 25\n",
      "  17:\n",
      "# Part 1\n",
      "\n",
      "# Create and define the function\n",
      "# Assign variable: clean_movie, parameter: movie\n",
      "def clean_movie(movie):\n",
      "    # create a non-destructive copy of original movie object\n",
      "    movie = dict(movie)\n",
      "    # Add in code to combine alternate titles into one list\n",
      "    # 1st Make empty dict{} to hold alternative titles\n",
      "    #-----------{key:value}----->{alt_titles:values_listed_below}\n",
      "    alt_titles = {}\n",
      "    # 2nd Loop through list of alternative title keys\n",
      "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
      "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
      "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
      "                'Revised Romanization','Romanized','Russian',\n",
      "                'Simplified','Traditional','Yiddish']:\n",
      "            #-----------{key:value}----->{alt_titles:values_listed_above}\n",
      "            # 2nd.a Check if the current keys exist in the movie\n",
      "            if key in movie:\n",
      "                alt_titles[key] = movie[key]\n",
      "                # 2nd.b remove the key-value pair/bond, Syntax: .pop()\n",
      "                movie.pop(key)\n",
      "    # 3rd After looping through every key\n",
      "    if len(alt_titles) > 0:\n",
      "            # 3rd Add the alternative titles dict to the movie object\n",
      "            movie['alt_titles'] = alt_titles\n",
      "# Part 2\n",
      "    # Make an inner function to find and change irregularities\n",
      "    # ^In this case merge column names\n",
      "    def change_column_name(old_name, new_name):\n",
      "            if old_name in movie:\n",
      "                movie[new_name] = movie.pop(old_name)\n",
      "    # Go through each column name and decide if there's a better name for it\n",
      "    change_column_name('Adaptation by', 'Writer(s)')\n",
      "    change_column_name('Country of origin', 'Country')\n",
      "    change_column_name('Directed by', 'Director')\n",
      "    change_column_name('Distributed by', 'Distributor')\n",
      "    change_column_name('Edited by', 'Editor(s)')\n",
      "    change_column_name('Length', 'Running time')\n",
      "    change_column_name('Original release', 'Release date')\n",
      "    change_column_name('Music by', 'Composer(s)')\n",
      "    change_column_name('Produced by', 'Producer(s)')\n",
      "    change_column_name('Producer', 'Producer(s)')\n",
      "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
      "    change_column_name('Productioncompany ', 'Production company(s)')\n",
      "    change_column_name('Released', 'Release Date')\n",
      "    change_column_name('Release Date', 'Release date')\n",
      "    change_column_name('Screen story by', 'Writer(s)')\n",
      "    change_column_name('Screenplay by', 'Writer(s)')\n",
      "    change_column_name('Story by', 'Writer(s)')\n",
      "    change_column_name('Theme music composer', 'Composer(s)')\n",
      "    change_column_name('Written by', 'Writer(s)')\n",
      "    \n",
      "    return movie\n",
      "  18:\n",
      "# pop() returns the value from the removed key-value pair\n",
      "# Therefore, check if the key exists in a given object first\n",
      "# i.e.        #C heck if the current keys exist in the movie\n",
      "#             if key in movie:\n",
      "#                 alt_titles[key] = movie[key]\n",
      "#                 # Remove the key-value pair/bond, Syntax: .pop()\n",
      "#                 movie.pop(key)\n",
      "  19:\n",
      "# Make a list of cleaned movies with list comprehension:\n",
      "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
      "  20:\n",
      "# Set wiki_movies_df to be the DataFrame created from clean_movies \n",
      "wiki_movies_df = pd.DataFrame(clean_movies)\n",
      "# print out list of the columns in alphabetical order\n",
      "sorted(wiki_movies_df.columns.tolist())\n",
      "  21:\n",
      "# Retrieve a movie by searching through a column (i.e. languages)\n",
      "# Inclue ['url'] in output\n",
      "#wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']\n",
      "  22:\n",
      "# Remove Duplicate Rows with .str.extract() and regex\n",
      "\n",
      "# Regular expressions, also known as regex, are strings of characters that define a search pattern\n",
      "# ^A more formal way of defining these kinds of patterns so that our code can find them\n",
      "# Regex are easily recognizable because they follow well-defined patterns\n",
      "\n",
      "# In this case we're searching for the IMDb id, ex: tt1234567\n",
      "# Regex for the IMDb ID object is: start with \"tt\" and has seven digits\n",
      "# When searching for the object use syntax: \"(tt\\d{7})\"\n",
      "# \"()\": look for one group of text.\n",
      "# \"tt\": match two lowercase Ts.\n",
      "# \"\\d\":match a numerical digit.\n",
      "# \"{7}\":match the last thing (numerical digits) exactly seven times.\n",
      "  23:\n",
      "# Extract the IMDb ID\n",
      "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
      "print(len(wiki_movies_df))\n",
      "  24:\n",
      "# Drop duplicates of IMDb IDs by using drop_duplicates(), subset=, and inplace=\n",
      "# To specify that we only want the IMDb ID, use the subset argument, set inplace equal to True so that the operation is performed on the selected dataframe.\n",
      "wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
      "print(len(wiki_movies_df))\n",
      "  25: wiki_movies_df.head()\n",
      "  26:\n",
      "# Remove Mostly Null Columns with list comprehension \n",
      "# Make a list of columns that have less than 90% null values, use those to trim down our dataset.\n",
      "# Use the list comprehension to produce only the wanted columns\n",
      "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
      "# Update  _df\n",
      "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
      "  27: wiki_movies_df.head()\n",
      "  28:\n",
      "# Make a Plan to Convert and Parse the Data\n",
      "\n",
      "# 1st Identify which columns need to be converted.\n",
      "wiki_movies_df.dtypes\n",
      "  29:\n",
      "# Make a data series that drops missing values\n",
      "box_office = wiki_movies_df['Box office'].dropna()\n",
      "  30:\n",
      "# Make a function to be able to filter out non string values.\n",
      "# ^This needs to be done because regex only work on strings\n",
      "# SyntaX is_not_a_string() \n",
      "def is_not_a_string(x):\n",
      "    return type(x) != str\n",
      "# Show values that are not strings\n",
      "box_office[box_office.map(is_not_a_string)]\n",
      "  31:\n",
      "# Use lambda to make a stripped-down, one-line function which won't be used ever again outside of map()\n",
      "box_office[box_office.map(lambda x: type(x) != str)]\n",
      "  32:\n",
      "# ^The out put shows data points stored as lists\n",
      "# Import re for regex\n",
      "import re\n",
      "  33:\n",
      "# Use ' ' as the joining character and apply the join() function only when data points are lists\n",
      "# Use join() method to concatenate list items into one string\n",
      "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "box_office\n",
      "  34:\n",
      "# Parse the Box Office Data\n",
      "\n",
      "# Build regex for each form the data is written in\n",
      "  35:\n",
      "# Regex for form $123.4 million/billion\n",
      "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
      "# ^Assign variable\n",
      "  36:\n",
      "# Count entires for form $123.4 million/billion\n",
      "box_office.str.contains(form_one, flags=re.IGNORECASE).sum()\n",
      "  37:\n",
      "# Regex for form $123,456,789 \n",
      "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
      "# ^Assign variable\n",
      "  38:\n",
      "# Count entires for form $123,456,789\n",
      "box_office.str.contains(form_two, flags=re.IGNORECASE).sum()\n",
      "  39:\n",
      "# Create Boolean Series for each form to find values not defined by either one.\n",
      "matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
      "matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
      "  40:\n",
      "# Find values not defined by forms 1 and 2\n",
      "box_office[~matches_form_one & ~matches_form_two]\n",
      "  41:\n",
      "# Fix Pattern Matches\n",
      "\n",
      "# Correct values with spaces between $ and the number\n",
      "# ^Add \\s* after the dollar sign\n",
      "# Correct mispelled \"millon\", make i optional i?\n",
      "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
      "  42:\n",
      "# Correct values that use a period as a thousands separator, not a comma\n",
      "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
      "  43:\n",
      "# Correct values that are given as a range\n",
      "box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
      "  44:\n",
      "# Extract and Convert the Box Office Values\n",
      "# Create/define function\n",
      "def parse_dollars(s):\n",
      "    # if s is not a string, return NaN\n",
      "    if type(s) != str:\n",
      "        return np.nan\n",
      "\n",
      "    # if input is of the form $###.# million\n",
      "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
      "\n",
      "        # remove dollar sign and \" million\"\n",
      "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
      "\n",
      "        # convert to float and multiply by a million\n",
      "        value = float(s) * 10**6\n",
      "\n",
      "        # return value\n",
      "        return value\n",
      "\n",
      "    # if input is of the form $###.# billion\n",
      "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
      "\n",
      "        # remove dollar sign and \" billion\"\n",
      "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
      "\n",
      "        # convert to float and multiply by a billion\n",
      "        value = float(s) * 10**9\n",
      "\n",
      "        # return value\n",
      "        return value\n",
      "\n",
      "    # if input is of the form $###,###,###\n",
      "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
      "\n",
      "        # remove dollar sign and commas\n",
      "        s = re.sub('\\$|,','', s)\n",
      "\n",
      "        # convert to float\n",
      "        value = float(s)\n",
      "\n",
      "        # return value\n",
      "        return value\n",
      "\n",
      "    # otherwise, return NaN\n",
      "    else:\n",
      "        return np.nan\n",
      "  45:\n",
      "# Find the values from box_office\n",
      "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
      "wiki_movies_df['box_office']\n",
      "  46:\n",
      "# Drop Box Office column since it's no longer needed\n",
      "wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
      "  47:\n",
      "# Parse Budget Data\n",
      "\n",
      "# Create a budget variable with the following code\n",
      "budget = wiki_movies_df['Budget'].dropna()\n",
      "  48:\n",
      "# Convert lists to strings\n",
      "budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "  49:\n",
      "# Remove values between a dollar sign and a hyphen (for budgets given in ranges)\n",
      "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
      "  50:\n",
      "# Create Boolean Series for each form to find values not defined by either one\n",
      "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE, na=False)\n",
      "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE, na=False)\n",
      "# Find the values from budget\n",
      "budget[~matches_form_one & ~matches_form_two]\n",
      "  51:\n",
      "# Remove citation references\n",
      "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
      "budget[~matches_form_one & ~matches_form_two].count()\n",
      "  52:\n",
      "# Find the values from budget\n",
      "wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
      "  53:\n",
      "# Drop the original Budget column\n",
      "wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
      "  54:\n",
      "# Parse Release Date\n",
      "\n",
      "\n",
      "# Assign variable for Release date column's non-null values in the DataFrame, convert lists to strings\n",
      "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "  55:\n",
      "# Forms to extract\n",
      "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]?\\d,\\s\\d{4}'\n",
      "date_form_two = r'\\d{4}.[01]\\d.[0123]\\d'\n",
      "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
      "date_form_four = r'\\d{4}'\n",
      "  56:\n",
      "# Extract Dates\n",
      "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)\n",
      "  57:\n",
      "# Parse dates\n",
      "wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
      "  58:\n",
      "# Assign variable for Running time column's non-null values in the DataFrame, convert lists to strings\n",
      "running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
      "running_time\n",
      "  59:\n",
      "# Look for all \"100 minutes\" form\n",
      "running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False).sum()\n",
      "  60:\n",
      "# Find values not defined by \"100 minutes\" form\n",
      "running_time[running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE, na=False) != True]\n",
      "  61:\n",
      "# Find all values with other abbreviations of \"minutes\"\n",
      "running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False).sum()\n",
      "  62:\n",
      "# Find remaining 17 values\n",
      "running_time[running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE, na=False) != True]\n",
      "  63:\n",
      "# Extract only values with digits with both patterns\n",
      "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
      "running_time_extract\n",
      "  64:\n",
      "# Convert strings to numeric values\n",
      "running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
      "running_time_extract\n",
      "  65:\n",
      "# Convert hour capture groups and minute capture groups to minutes IF pure minutes capture group is zero, save the output to wiki_movies_df\n",
      "wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
      "  66:\n",
      "# Drop Running time from dataset \n",
      "wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
      "  67:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "  68:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
      "movies_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "rating_csvs= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "  69:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "125/5:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "125/6:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "125/7:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "125/8:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "#kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "125/9: kaggle_metadata.sample(5)\n",
      "125/10:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "#kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "125/11:\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "print(file_dir)\n",
      "125/12:\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "print(file_dir)\n",
      "125/13:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "125/14: file_dir=\"C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class\\Movies_ETL\"\n",
      "125/15: file_dir=\"C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class\"\n",
      "125/16: file_dir = \"C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class\"\n",
      "125/17:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "125/18: file_dir = 'C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class'\n",
      "125/19:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "125/20:\n",
      "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "125/21: #file_dir = 'C:\\Users\\joshua toussaint&FAM\\Desktop\\Data Class'\n",
      "125/22:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "125/23:\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "125/24:\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "125/25:\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "print(file_dir)\n",
      "125/26:\n",
      "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
      "125/27:\n",
      "# Read data and store it in Pandas\n",
      "# No _df variable until data is satisfactory, then store in DataFrame\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "125/28: kaggle_metadata.sample(5)\n",
      "125/29: ratings.sample(5)\n",
      "125/30:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "125/31:\n",
      "# Assign variables for files to load via indirect path.\n",
      "movies_csv = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csv = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "125/32:\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "125/33:\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "print(file_dir)\n",
      "125/34:\n",
      "file_dir = os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "print(file_dir)\n",
      "125/35: kaggle_metadata.sample(5)\n",
      "125/36: ratings.sample(5)\n",
      "  70:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
      "movies_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csvs= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "  71:\n",
      "# Import dependencies\n",
      "import pandas as pd\n",
      "import os\n",
      "  72:\n",
      "# Assign variables for Kaggle and Ratings data files to load via indirect path\n",
      "movies_csv= os.path.join(\"Movies_ETL\", \"movies_metadata.csv\")\n",
      "ratings_csvs= os.path.join(\"Movies_ETL\", \"ratings.csv\")\n",
      "  73:\n",
      "kaggle_metadata = pd.read_csv(movies_csv, low_memory=False)\n",
      "ratings = pd.read_csv(ratings_csv)\n",
      "  74:\n",
      "kaggle_metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
      "ratings = pd.read_csv('ratings.csv')\n",
      "  75: kaggle_metadata.dtypes\n",
      "  76: kaggle_metadata['adult'].value_counts()\n",
      "  77:\n",
      "# Remove Bad Data\n",
      "kaggle_metadata[~kaggle_metadata['adult'].isin(['True','False'])]\n",
      "  78:\n",
      "# ^SColumns are scrambled for these movies\n",
      "# Keep rows where adult column is False and drop the adult column\n",
      "kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n",
      "kaggle_metadata['video'].value_counts()\n",
      "  79:\n",
      "# Convert Data Types\n",
      "kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
      "  80:\n",
      "kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
      "kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
      "kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')\n",
      "  81: kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
      "  82: ratings.info(null_counts=True)\n",
      "  83: pd.to_datetime(ratings['timestamp'], unit='s')\n",
      "  84: ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
      "  85:\n",
      "pd.options.display.float_format = '{:20,.2f}'.format\n",
      "ratings['rating'].plot(kind='hist')\n",
      "ratings['rating'].describe()\n",
      "  86: %history -g\n"
     ]
    }
   ],
   "source": [
    "%history -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "634ff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%notebook -e myhistory.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e8035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb946f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
